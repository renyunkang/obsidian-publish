<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>rykenのgarden on</title><link>https://www.ryken.cloud/</link><description>Recent content in rykenのgarden on</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sat, 20 Jan 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://www.ryken.cloud/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://www.ryken.cloud/Cilium-1.19-BGP/</link><pubDate>Sat, 28 Feb 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Cilium-1.19-BGP/</guid><description>Cilium BGP 控制平面由一组自定义资源管理，这些资源提供了一种灵活的方式来配置 BGP 对等体、策略和通告。
CiliumBGPClusterConfig：定义应用于多个节点的 BGP 实例和对等配置。设置对等端点，并且可以引用一个或多个 CiliumBGPPeerConfig 资源（使用资源名称） ， CiliumBGPPeerConfig：一套通用的BGP对等连接配置。它可以用于多个对等体之间。 配置对等互连的行为方式，并且可以引用一个或多个 CiliumBGPAdvertisement 资源（使用选择器） CiliumBGPAdvertisement：指定应通过 BGP 通告哪些 CIDR。定义要注入到 BGP 路由表中的前缀。 CiliumBGPNodeConfigOverride：定义节点特定的 BGP 配置，以提供更精细的控制。 CiliumBGPPeeringPolicy 和 CiliumBGPClusterConfig 不应同时使用。如果这两个资源都存在，并且 Cilium 代理根据节点选择器与两者都匹配，则 CiliumBGPPeeringPolicy 将优先使用。</description></item><item><title/><link>https://www.ryken.cloud/NetworkPolicy-%E6%80%BB%E8%A7%88/</link><pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/NetworkPolicy-%E6%80%BB%E8%A7%88/</guid><description>网页编辑 networkpolicy： https://editor.networkpolicy.io/ Cilium Networkpolicy CRD：
NetworkPolicy CiliumNetworkPolicy CiliumClusterwideNetworkPolicy 设置网络策略时的建议：一步一步进行设置 https://veducate.co.uk/cilium-network-policies-from-first-principles-to-production/#Safe_rollout_plan
https://docs.cilium.io/en/stable/network/kubernetes/policy/#k8s-policy https://docs.cilium.io/en/stable/security/policy/ https://veducate.co.uk/cilium-network-policies-from-first-principles-to-production/</description></item><item><title/><link>https://www.ryken.cloud/%E5%8F%AF%E7%94%A8%E5%91%BD%E4%BB%A4/</link><pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%8F%AF%E7%94%A8%E5%91%BD%E4%BB%A4/</guid><description>hubble observe -n tenant-jobs &amp;ndash;verdict DROPPED -f
1 2 3 4 5 6 7 8 9 10 # follow recent flows with policy verdicts from this namespacehubble observe --namespace tenant-jobs --last 50 -t policy-verdict# show only dropshubble observe --namespace tenant-jobs --verdict DROPPED# output as JSON for jq exploration or use in another systemhubble observe --namespace tenant-jobs --since 5m -o jsonhubble observe --from-pod tenant-jobs/crawler --to-pod kube-system/coredns --protocol DNS -o JSON</description></item><item><title/><link>https://www.ryken.cloud/Cilium-1.19/</link><pubDate>Thu, 26 Feb 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Cilium-1.19/</guid><description>预计 2026 年 2 月初发布
https://isovalent.com/blog/post/cilium-119-ztunnel-transparent-encryption-multi-pool-ipam-goes-stable-ipv6-progress-and-more/</description></item><item><title/><link>https://www.ryken.cloud/Overlay-Underlay%E6%AF%94%E8%BE%83/</link><pubDate>Wed, 25 Feb 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Overlay-Underlay%E6%AF%94%E8%BE%83/</guid><description>Overlay 安装 overlay 的安装可以满足大部分容器网络需求，建议首选。
默认安装所选，其对底层网络基础设施的要求最低。 在此模式下，所有集群节点使用基于 UDP 的封装协议 VXLAN 或 Geneve 形成隧道网。Cilium 节点之间的所有流量都会被封装。
VXLAN (Default) 8472/UDP Geneve 6081/UDP 简洁性 连接集群节点的网络无需感知 PodCIDR。集群节点可以生成多个路由或链路层域。只要集群节点能够通过 IP/UDP 相互通信，底层网络的拓扑结构就无关紧要。</description></item><item><title>multi-pool更新 ippool</title><link>https://www.ryken.cloud/multi-pool%E6%9B%B4%E6%96%B0-ippool/</link><pubDate>Wed, 25 Feb 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/multi-pool%E6%9B%B4%E6%96%B0-ippool/</guid><description>https://docs.cilium.io/en/stable/network/concepts/ipam/multi-pool/#update-existing-ciliumpodippools
更新现有的 CiliumPodIPPools 会受到一些限制。虽然可以通过添加新的 IPv4 或 IPv6 CIDR 来扩展地址池，但无法删除或更新已使用的 CIDR。此限制会阻止 Pod 从新的地址范围获取 IP 地址，同时某些 Pod 仍在同一节点上使用旧的 IP 地址池。但是，如果您别无选择，只能更新现有 CiliumPodIPPools 中正在使用的 CIDR，请参考以下步骤。</description></item><item><title>Cilium 1.16 - BGP v2</title><link>https://www.ryken.cloud/Cilium-1.16-BGP-v2/</link><pubDate>Tue, 24 Feb 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Cilium-1.16-BGP-v2/</guid><description>之前使用 CiliumBGPPeeringPolicy，有一些缺点，不够灵活；为了提供更高的灵活性，cilium 1.16 引入了新的 API - BGPv2
通过 Cilium 1.16.0 中引入的 Cilium BGP v2 控制平面，可以使用三个 Kubernetes CRD 的组合来配置对等策略：
CiliumBGPClusterConfig 设置对等端点，并且可以引用一个或多个 CiliumBGPPeerConfig 资源（使用资源名称） CiliumBGPPeerConfig 配置对等互连的行为方式，并且可以引用一个或多个 CiliumBGPAdvertisement 资源（使用选择器） CiliumBGPAdvertisement 指定应通过 BGP 通告哪些 CIDR。 用途 使用 Cilium，您可以选择宣告：</description></item><item><title/><link>https://www.ryken.cloud/cilium-dbg/</link><pubDate>Fri, 13 Feb 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/cilium-dbg/</guid><description>cilium bgp 内部集成了 gobgp peers routes route-policies bpf auth config bandwidth ct egress endpoint fs ipcache ipmasq lb metrics vtep - beta frag - beta tunnel multicast nat node nodeid policy recorder sha srv6 build-config cgroups 新节点 cleanup - post-uninstall-cleanup 新节点 completion config debuginfo encrypt endpoint fqdn identity ip kvstore lrp map metrics monitor node 只有 node list 返回节点的一些信息 nodeid 只有 nodeid list 返回节点 id 的一些信息 policy prefilter preflight recorder service statedb status troubleshoot</description></item><item><title/><link>https://www.ryken.cloud/L2-Announcements/</link><pubDate>Fri, 13 Feb 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/L2-Announcements/</guid><description>安装指定参数：
l2announcements.enabled=true 依赖：
kube-proxy-replacement 为什么 net0 的 type 为 veth 以及 eth0 也为 veth 可能是使用 clab 搭建的，所获取的网卡为 veth 实现</description></item><item><title/><link>https://www.ryken.cloud/%E9%AB%98%E7%BA%A7%E4%BD%BF%E7%94%A8/</link><pubDate>Fri, 13 Feb 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E9%AB%98%E7%BA%A7%E4%BD%BF%E7%94%A8/</guid><description>绑定 namespace 绑定负载 固定 ip
ipam.cilium.io/ip-pool
保留 IP - 暂不支持
文档：
https://docs.cilium.io/en/stable/network/concepts/ipam/multi-pool/ https://docs.cilium.io/en/stable/network/kubernetes/ipam-multi-pool/ 安装：
--set ipam.</description></item><item><title>BGP 环境搭建</title><link>https://www.ryken.cloud/BGP-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</link><pubDate>Fri, 13 Feb 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/BGP-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</guid><description>安装工具 安装网桥工具 apt install -y bridge-utils 安装 bird apt-get install -y bird 修改配置文件 修改网络配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 source /etc/network/interfaces.</description></item><item><title>cilium-agent 分析</title><link>https://www.ryken.cloud/cilium-agent-%E5%88%86%E6%9E%90/</link><pubDate>Fri, 13 Feb 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/cilium-agent-%E5%88%86%E6%9E%90/</guid><description>6 个 init container config cilium-dbg build-config 根据配置文件创建对应的配置目录 - /tmp/cilium/config-map；（解析配置并应用到节点上） config-map - config-map:&amp;lt;namespace&amp;gt;/name or config-map:name node - node:&amp;lt;NODENAME&amp;gt; cilium-node-config - cilium-node-config:&amp;lt;NAMESPACE&amp;gt; orcilium-node-config:&amp;lt;NAMESPACE&amp;gt;/name 分别对应：</description></item><item><title>H3C 0519x64</title><link>https://www.ryken.cloud/H3C-0519x64/</link><pubDate>Fri, 13 Feb 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/H3C-0519x64/</guid><description>文档链接：
H3C VSR系列虚拟路由器 配置指导-E0518-5W101_三层技术-IP路由配置指导_BGP配置-新华三集团-H3C [[交换机使用]] 1. 连外网 连接公网ip 配置基础网络网卡ip 1 2 3 interface ge3/0 ip address 10.</description></item><item><title>Hive 和 cell</title><link>https://www.ryken.cloud/Hive-%E5%92%8C-cell/</link><pubDate>Fri, 13 Feb 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Hive-%E5%92%8C-cell/</guid><description>Cilium 使用依赖注入（通过 pkg/hive）来连接其组件的初始化、启动和停止。 依赖注入 (DI) 是一种将对象的使用与其创建和初始化分开的技术。本质上，依赖注入是关于自动化依赖关系的手动管理。对象构造函数只需将其依赖项声明为函数参数，其余部分由库处理。这有助于构建松散耦合的模块化架构，因为它消除了集中初始化和配置的需要。它还减少了使用全局变量而不是显式传递对象的倾向，这通常是错误的根源（由于意外的初始化顺序）并且在测试中难以处理（因为需要为下一个测试恢复状态）。通过依赖注入，组件被描述为纯值（我们的 DI 风格中的 Cell），从而实现组件间依赖关系的可视化并开放内部架构以供检查。
这里描述的依赖注入和机制只是帮助我们实现真正目标的工具：一个模块化的软件架构，可以由一大群开发人员轻松理解、扩展、重新调整用途、测试和重构，并且模块之间的重叠最小化。为了实现这一目标，我们在设计架构和 API 时还需要考虑模块化。
蜂巢和细胞
Cilium 应用程序是使用运行时依赖注入从一组称为单元的模块化组件组成的，这些组件组合在一起形成一个蜂巢（如蜂巢）。然后可以为配置单元提供配置并执行。
创建一个 pod，cilium agent 有以下 subsys 协作</description></item><item><title>StateDB - Cilium 内存数据的存储</title><link>https://www.ryken.cloud/StateDB-Cilium-%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AD%98%E5%82%A8/</link><pubDate>Fri, 13 Feb 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/StateDB-Cilium-%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AD%98%E5%82%A8/</guid><description>项目地址： https://github.com/cilium/statedb 目前使用 statedb 存储的有
ipset devices l2_announce route lb &amp;hellip; &amp;hellip; 使用命令可以查询
kubectl -n kube-system exec ds/cilium -- cilium-dbg shell -- db/show l2-announce</description></item><item><title>多集群编排方案</title><link>https://www.ryken.cloud/%E5%A4%9A%E9%9B%86%E7%BE%A4%E7%BC%96%E6%8E%92%E6%96%B9%E6%A1%88/</link><pubDate>Fri, 13 Feb 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%A4%9A%E9%9B%86%E7%BE%A4%E7%BC%96%E6%8E%92%E6%96%B9%E6%A1%88/</guid><description>DaoCloud
https://karmada.io/zh/docs/casestudies/daocloud/#%E9%9D%A2%E5%90%91%E4%BC%81%E4%B8%9A%E7%94%A8%E6%88%B7%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5 DaoCloud 结合 Karmada，打造了企业级的多云平台 Kairship，助力用户把业务从云下走向云上，单云丝滑切换到多云，使用户无需关注底层基础设施的差异，不用过多接受 Kubernetes 之外的新概念。 Aliyun
https://help.aliyun.com/zh/ack/distributed-cloud-container-platform-for-kubernetes/use-cases/disaster-recovery-architecture-and-scheme-based-on-kubernetes-container-cluster Google
https://docs.</description></item><item><title>未命名</title><link>https://www.ryken.cloud/BGP-%E6%BC%94%E8%BF%9B%E8%BF%87%E7%A8%8B/</link><pubDate>Fri, 13 Feb 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/BGP-%E6%BC%94%E8%BF%9B%E8%BF%87%E7%A8%8B/</guid><description>BGP 支持的演进过程 支持 bird、kube-router
BGP 支持最初在 Cilium 1.10 中引入，此后进行了后续改进。
在 Cilium 1.12 中引入了 IPv6 支持，
在 Cilium 1.</description></item><item><title>网络工具包</title><link>https://www.ryken.cloud/%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7%E5%8C%85/</link><pubDate>Fri, 13 Feb 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7%E5%8C%85/</guid><description>相关网络工具包：
ping包：apt-get install inetutils-ping. apt install -y iputils-ping ifconfig/netstat：apt-get install net-tools ip 命令：apt-get install iproute2 抓包：sudo apt-get install wireshark + sudo usermod -a -G wireshark $USER</description></item><item><title>Cilium 1.18</title><link>https://www.ryken.cloud/Cilium-1.18/</link><pubDate>Wed, 11 Feb 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Cilium-1.18/</guid><description>版本发布时间
发布版本 发布时间 cilium v1.18.0-pre.0 2025/3/4 cilium v1.18.0-pre.1 2025/4/1 cilium v1.</description></item><item><title/><link>https://www.ryken.cloud/LB-IPAM/</link><pubDate>Wed, 21 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/LB-IPAM/</guid><description>https://docs.cilium.io/en/stable/network/lb-ipam/
LB IPAM为 Loadbalancer 类型的 Service 分配 IP 地址。此功能通常由云提供商提供，但在私有云环境中部署时，这些功能并非总是可用。
目前 LB IPAM 可以和 cilium BGP、L2 Announcements 协同工作，LB IPAM 负责给 service 分配 ip，cilium BGP、L2 Announcements负责负载均衡或者宣告这些 ip。</description></item><item><title/><link>https://www.ryken.cloud/multus-+-macvlan/</link><pubDate>Wed, 21 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/multus-+-macvlan/</guid><description>环境准备：
交换机连接节点口配置为 trunk，并放行指定的 vlan，外部配置所需要网段的网关，并在所有节点上手动创建 vlan 子接口 - 后续如果需要新建新的 vlan、ip 段，也需要手动创建 vlan 子接口 使用 calicoctl node status 查看内部 bgp 连接是否都 Established。当节点上有多个网卡时，可以使用使用 IP_AUTODETECTION_METHOD 环境变量指定 calico 使用哪一张网卡来交换集群容器路由信息 https://docs.</description></item><item><title/><link>https://www.ryken.cloud/multus-cni-%E9%85%8D%E7%BD%AE%E9%A1%B9/</link><pubDate>Wed, 21 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/multus-cni-%E9%85%8D%E7%BD%AE%E9%A1%B9/</guid><description>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 {&amp;#34;cniVersion&amp;#34;: &amp;#34;0.</description></item><item><title>4. 安装测试</title><link>https://www.ryken.cloud/4.-%E5%AE%89%E8%A3%85%E6%B5%8B%E8%AF%95/</link><pubDate>Wed, 21 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/4.-%E5%AE%89%E8%A3%85%E6%B5%8B%E8%AF%95/</guid><description>setup_singleCni_macvlan - kind 主机与本机 pod 不通 pod 与 service 不通 setup_dualCni_calico setup_dualCni_cilium chart 参数： overlay 安装使用</description></item><item><title>calico 自动清理定时任务</title><link>https://www.ryken.cloud/calico-%E8%87%AA%E5%8A%A8%E6%B8%85%E7%90%86%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/</link><pubDate>Wed, 21 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/calico-%E8%87%AA%E5%8A%A8%E6%B8%85%E7%90%86%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/</guid><description>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 apiVersion:v1kind:ServiceAccountmetadata:name:calico-cleanernamespace:kube-system---apiVersion:rbac.</description></item><item><title>Cilium 1.16</title><link>https://www.ryken.cloud/Cilium-1.16/</link><pubDate>Wed, 21 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Cilium-1.16/</guid><description>版本发布时间
cilium 1.16 之后 envoy 被拆分为一个独立的 deamonset
发布版本 发布时间 cilium v1.16.0 2024/7/24 cilium v1.</description></item><item><title>Cilium 1.17</title><link>https://www.ryken.cloud/Cilium-1.17/</link><pubDate>Wed, 21 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Cilium-1.17/</guid><description>版本发布时间
发布版本 发布时间 cilium v1.17.0-pre.0 2024/9/5 cilium v1.17.0-pre.1 2024/10/1 cilium v1.</description></item><item><title>cilium ipam</title><link>https://www.ryken.cloud/cilium-ipam/</link><pubDate>Wed, 21 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/cilium-ipam/</guid><description>1 2 3 kubectl get cm -n kube-system cilium-config -o yaml| grep tunnel routing-mode: tunnel tunnel-protocol: vxlan 容器的网络数据路径</description></item><item><title>client rate limter</title><link>https://www.ryken.cloud/client-rate-limter/</link><pubDate>Wed, 21 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/client-rate-limter/</guid><description>光大使用 blocksize 为 32 的 ippool，导致同一个节点上有很多 pod 同时启动时，消耗时间很长
限速队列实现原理：
QPS：生成令牌的速率 Burst：令牌桶的容量 apiserver 限速：
max-request-inflight max-mutating-request-inflight</description></item><item><title>macvlan</title><link>https://www.ryken.cloud/macvlan/</link><pubDate>Wed, 21 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/macvlan/</guid><description>macvlan 介绍 一块物理网卡虚拟成多块虚拟网卡
macvlan可以看做是物理接口 eth（父接口）的子接口，每个macvlan都拥有独立的 mac 地址，可以被绑定 IP 作为正常的网卡接口使用。
通过这个特性，可以实现在一个物理网络设备绑定多个IP，每个IP拥有独立的mac地址。该特性经常被应用在容器虚拟化中。
macvlan 这种技术听起来有点像 VLAN，但它们的实现机制是完全不一样的。macvlan 子接口和原来的主接口是完全独立的，可以单独配置 MAC 地址和 IP 地址，而 VLAN 子接口和主接口共用相同的 MAC 地址。VLAN 用来划分广播域，而 macvlan 共享同一个广播域。</description></item><item><title>SR-IOV 实验性</title><link>https://www.ryken.cloud/SR-IOV-%E5%AE%9E%E9%AA%8C%E6%80%A7/</link><pubDate>Wed, 21 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/SR-IOV-%E5%AE%9E%E9%AA%8C%E6%80%A7/</guid><description>官方文档： https://docs.rancher.cn/docs/rke2/install/network_options/#%E4%BD%BF%E7%94%A8-multus-%E4%B8%8E-sr-iov-%E5%AE%9E%E9%AA%8C%E6%80%A7、、
将 SR-IOV CNI 与 Multus 一起使用可以帮助解决数据平面加速的用例，在 Pod 中提供一个额外的接口，可以实现非常高的吞吐量。SR-IOV 并非在所有环境中都有效，并且必须满足一些要求才能将节点视为具有 SR-IOV 功能的节点：
物理网卡必须支持 SR-IOV（例如通过检查/sys/class/net/$NIC/device/sriov_totalvfs） 主机操作系统必须激活 IOMMU 虚拟化 主机操作系统包括能够进行 SR-IOV 的驱动程序（如 i40e，vfio-pci 等）</description></item><item><title>whereabouts</title><link>https://www.ryken.cloud/whereabouts/</link><pubDate>Wed, 21 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/whereabouts/</guid><description>一个用于集群范围分配 IP 地址的 CNI IPAM 插件，为了改进 host-local 而实现的，但是功能依旧单一
内部 CRD - namespace 级别(默认在 kube-system 下)：
ippools.whereabouts.cni.cncf.io ippool 由 cni 配置解析为 whereabouts ippool，内部存储分配记录 nodeslicepools.</description></item><item><title>未命名</title><link>https://www.ryken.cloud/Cilium-%E5%87%BA%E5%8F%A3%E7%BD%91%E5%85%B3/</link><pubDate>Wed, 21 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Cilium-%E5%87%BA%E5%8F%A3%E7%BD%91%E5%85%B3/</guid><description>在许多企业环境中，托管在 Kubernetes 上的应用程序需要与 Kubernetes 集群外部的工作负载进行通信，而这些工作负载会受到连接限制和安全强制的影响。由于这些网络的性质，传统防火墙通常依赖于静态 IP 地址（或至少是 IP 范围）。这使得将 Kubernetes 集群集成到这样的网络中变得困难，因为该集群的节点数量是变化的（有时是动态的）。
Cilium 的 Egress Gateway 允许指定 pod 使用哪些节点才能到达外部世界。来自这些 Pod 的流量将被源 NAT 到节点的 IP 地址，并将通过可预测的 IP 到达外部防火墙，从而使防火墙能够在 Pod 上实施正确的策略。</description></item><item><title>版本支持矩阵</title><link>https://www.ryken.cloud/%E7%89%88%E6%9C%AC%E6%94%AF%E6%8C%81%E7%9F%A9%E9%98%B5/</link><pubDate>Wed, 21 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E7%89%88%E6%9C%AC%E6%94%AF%E6%8C%81%E7%9F%A9%E9%98%B5/</guid><description>运行的系统硬性要求：
https://docs.cilium.io/en/stable/operations/system_requirements/ 需要放行的防火墙： https://docs.cilium.io/en/stable/operations/system_requirements/#firewall-rules kind 搭建的集群共享的是节点的内核
优化点/特性点 cilium 版本支持情况 内核版本支持情况 备注 kube-proxy Replacement cilium 1.</description></item><item><title>自行编译 calico-ipam</title><link>https://www.ryken.cloud/%E8%87%AA%E8%A1%8C%E7%BC%96%E8%AF%91-calico-ipam/</link><pubDate>Wed, 21 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E8%87%AA%E8%A1%8C%E7%BC%96%E8%AF%91-calico-ipam/</guid><description>修改 configmap kube-system/calico-config，在 ipam 下添加 qos 和 brust 配置（注意逗号）
1 2 3 4 5 &amp;#34;ipam&amp;#34;: {&amp;#34;type&amp;#34;: &amp;#34;calico-ipam&amp;#34;,&amp;#34;qos&amp;#34;: 5,&amp;#34;burst&amp;#34;: 100}, 修改完之后重启 calico-node，会在每个节点的 /etc/cni/net.</description></item><item><title/><link>https://www.ryken.cloud/cilium-%E5%8F%91%E7%89%88%E8%8A%82%E5%A5%8F/</link><pubDate>Thu, 08 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/cilium-%E5%8F%91%E7%89%88%E8%8A%82%E5%A5%8F/</guid><description>一年两个版本，年初1月底2月初一个奇数版本，年中7月底8月初一个偶数版本。即每个版本开发 4个月时间，测试2个月时间，同时会维护4个版本
每个版本的周期大约是2年，6个的开发测试，以及 18 个月的 bugfix 维护，一般情况小版本的数字最后为 v.x.xx.18</description></item><item><title/><link>https://www.ryken.cloud/kube-ovn-overlay-vpc/</link><pubDate>Thu, 08 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/kube-ovn-overlay-vpc/</guid><description>#cni #kube-ovn #overlay
overlay 模式路由网络打通 Overlay 下路由方式网络打通 - Kube-OVN 文档
网关类型 仅在默认 vpc 下支持，子网管理
分布式网关 子网的默认类型网关，每个 node 会作为当前 node 上 pod 访问外部网络的网关。数据包会通过本机的 ovn0 网卡流入主机网络栈，再根据主机的路由规则进行出网。 当 natOutgoing 为 true 时，Pod 访问外部网络将会使用当前所在宿主机的 IP。</description></item><item><title/><link>https://www.ryken.cloud/multus-cni-%E6%94%AF%E6%8C%81%E7%9A%84%E9%85%8D%E7%BD%AE/</link><pubDate>Thu, 08 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/multus-cni-%E6%94%AF%E6%8C%81%E7%9A%84%E9%85%8D%E7%BD%AE/</guid><description>生成的配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 root@macvlan1:~# cat /etc/cni/net.</description></item><item><title/><link>https://www.ryken.cloud/%E6%94%AF%E6%8C%81%E7%9A%84%E5%BC%80%E5%85%B3%E9%A1%B9/</link><pubDate>Thu, 08 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E6%94%AF%E6%8C%81%E7%9A%84%E5%BC%80%E5%85%B3%E9%A1%B9/</guid><description>cilium 1.16.0
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 agent-not-ready-taint-key: node.</description></item><item><title>cilium kube-proxy 替换</title><link>https://www.ryken.cloud/cilium-kube-proxy-%E6%9B%BF%E6%8D%A2/</link><pubDate>Thu, 08 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/cilium-kube-proxy-%E6%9B%BF%E6%8D%A2/</guid><description>使用 kubekey 安装集群时，设置不安装 kube-proxy；集群安装完成之后使用 cilium cli 安装 cilium 会自动替换 kube-proxy
1 cilium install 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 root@node1:/home/cilium# cilium status --verbose KubeProxyReplacement: True [eth0 172.</description></item><item><title>cilium 部署最佳实践</title><link>https://www.ryken.cloud/cilium-%E9%83%A8%E7%BD%B2%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link><pubDate>Thu, 08 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/cilium-%E9%83%A8%E7%BD%B2%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid><description>交付物：kk安装方法，常用功能配置和使用方法(cli), 最佳实践
默认的配置项：
overlay vxlan 需要暴露的配置项：
tunnel Overlay 部署 默认安装，对底层网络基础设施的要求最低。cilium 支持基于 udp 封装的 vxlan 和 geneve 隧道。所有 cilium 节点间的流量都会被封装</description></item><item><title>hubble</title><link>https://www.ryken.cloud/hubble/</link><pubDate>Thu, 08 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/hubble/</guid><description>安装： clium 1.12.1 安装：
cilium hubble enable &amp;ndash;ui or helm upgrade cilium cilium/cilium &amp;ndash;version 1.16.2 &amp;ndash;namespace kube-system &amp;ndash;reuse-values &amp;ndash;set hubble.</description></item><item><title>kube-proxy replacement</title><link>https://www.ryken.cloud/kube-proxy-replacement/</link><pubDate>Thu, 08 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/kube-proxy-replacement/</guid><description>Kube-proxy Kube-proxy 是 Kubernetes 中的网络组件，作为 daemonset 安装在集群中的每个节点上，负责 Service 和 Pod 之间的通信。其主要作用是维护 service-to-pod map的网络规则，包括必要时的NAT转换，以确保数据包到达预期目的地。Kube-proxy 利用 iptables 或 IPVS 充当 L3/L4 网络代理和负载均衡器，其中 iptables 作为开箱即用的默认设置。</description></item><item><title>之前的版本</title><link>https://www.ryken.cloud/%E4%B9%8B%E5%89%8D%E7%9A%84%E7%89%88%E6%9C%AC/</link><pubDate>Thu, 08 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E4%B9%8B%E5%89%8D%E7%9A%84%E7%89%88%E6%9C%AC/</guid><description>Cilium 1.0: Bringing the BPF Revolution to Kubernetes Networking and Security https://cilium.io/blog/2018/04/24/cilium-10/
Cilium 1.1: Istio sidecar mode, cri-o/containerd support, improved efficiency &amp;amp; scale, init policies https://cilium.</description></item><item><title>Cilium 1.15</title><link>https://www.ryken.cloud/Cilium-1.15/</link><pubDate>Wed, 07 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Cilium-1.15/</guid><description>版本发布时间
发布版本 发布时间 cilium v1.15.0 2024/2/1 cilium v1.15.1 2024/2/15 cilium v1.</description></item><item><title>multus-cni</title><link>https://www.ryken.cloud/multus-cni/</link><pubDate>Wed, 07 Jan 2026 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/multus-cni/</guid><description>仓库地址： k8snetworkplumbingwg/multus-cni: A CNI meta-plugin for multi-homed pods in Kubernetes (github.com)
安装 kubectl apply -f https://raw.githubusercontent.com/k8snetworkplumbingwg/multus-cni/v3.9.2/deployments/multus-daemonset-thick-plugin.yml
使用 创建 NetworkAttachmentDefinition 资源 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 cat &amp;lt;&amp;lt;EOF | kubectl create -f - apiVersion: &amp;#34;k8s.</description></item><item><title/><link>https://www.ryken.cloud/calico-bgpfilter/</link><pubDate>Mon, 15 Dec 2025 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/calico-bgpfilter/</guid><description>添加/验证脚本 行中的配置 bgpfilter 目前仅适用了 action、cidr、matchOperator 三个字段，并且目前只考虑增加和验证操作，基于此需求提供一个简单的 shell 脚本辅助用户进行 bgpfilter 资源的变更操作
此脚本需要 yq 和 grepcidr。
在运行此脚本前，请确保您的环境中已安装以下工具：
kubectl: 用于与您的 Kubernetes 集群进行交互。 yq (v4+): 一个功能强大的命令行 YAML 处理器。 macOS (使用 Homebrew): 1 brew install yq Linux (下载二进制文件): 1 sudo wget https://github.</description></item><item><title/><link>https://www.ryken.cloud/%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 15 Dec 2025 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%91%BD%E4%BB%A4/</guid><description>bpftool net show dev lxcxxx - 查看挂载的 bpf 代码 cilium monitor -t drop -vvv cilium-dbg bpf endpoint list cilium-dbg bpf ipcache list pwru - 看包在哪里</description></item><item><title/><link>https://www.ryken.cloud/%E6%89%8B%E5%8A%A8%E5%88%9B%E5%BB%BA-netns-+-%E8%B7%A8%E4%B8%BB%E6%9C%BA%E9%80%9A%E4%BF%A1/</link><pubDate>Mon, 15 Dec 2025 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E6%89%8B%E5%8A%A8%E5%88%9B%E5%BB%BA-netns-+-%E8%B7%A8%E4%B8%BB%E6%9C%BA%E9%80%9A%E4%BF%A1/</guid><description>#network #netns
使用 arp-proxy，并在主机上添加对应的路由联通 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # echo 1 &amp;gt; /proc/sys/net/ipv4/ip_forward echo &amp;#39;net.</description></item><item><title/><link>https://www.ryken.cloud/%E9%85%8D%E7%BD%AE-route-reflector/</link><pubDate>Mon, 15 Dec 2025 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E9%85%8D%E7%BD%AE-route-reflector/</guid><description>#calico #rr
Configuring Route Reflectors in Calico (tigera.io)
选择一个节点作为 RR，设置 lable 以及 routeReflectorClusterID 1 2 3 4 5 6 7 kubectl label node node3 routeReflector=&amp;#34;&amp;#34; # 3.</description></item><item><title>vscode + golang 环境</title><link>https://www.ryken.cloud/vscode-+-golang-%E7%8E%AF%E5%A2%83/</link><pubDate>Tue, 26 Aug 2025 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/vscode-+-golang-%E7%8E%AF%E5%A2%83/</guid><description>环境配置 安装 golang vscode 连接上远程主机并安装 vscode server vscode 中安装 go 插件 安装 go 插件依赖的工具： ctrl+shift+p 调出命令面板，输入go install tools 选Go: Install/Update Tool 全选进行安装 使用 CGO 时，vscode 报错 1 go list failed to return CompiledGoFiles.</description></item><item><title>排查工具</title><link>https://www.ryken.cloud/%E6%8E%92%E6%9F%A5%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 21 Jul 2025 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E6%8E%92%E6%9F%A5%E5%B7%A5%E5%85%B7/</guid><description>查看本机的默认的 dns 服务器地址
cat /etc/resolv.conf systemd-resolve &amp;ndash;status nslookup
nslookup ryken.eu.org 10.233.0.3 dig
dig ryken.eu.org @10.233.0.3 dig ryken.</description></item><item><title>calico 由 IPIP 模式修改为 BGP 模式</title><link>https://www.ryken.cloud/calico-%E7%94%B1-IPIP-%E6%A8%A1%E5%BC%8F%E4%BF%AE%E6%94%B9%E4%B8%BA-BGP-%E6%A8%A1%E5%BC%8F/</link><pubDate>Fri, 18 Apr 2025 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/calico-%E7%94%B1-IPIP-%E6%A8%A1%E5%BC%8F%E4%BF%AE%E6%94%B9%E4%B8%BA-BGP-%E6%A8%A1%E5%BC%8F/</guid><description>前提： 客户 kubernetes 集群的节点在同一网段
简单解释： IPIP 可用于 kubernetes 集群的节点不在同一网段的情况，通过 ipip 封装使得 pod 网络打通 bgp 也可以说是 underlayer 模式，将主机作为网关，利用主机上的路由进行转发，因此为了保证 pod-pod 跨主机的联通性，需要主机在同一网段中
修改方案： 修改 calico ippool - 关闭 ipip 和 vxlan 模式</description></item><item><title>devops casc 参数</title><link>https://www.ryken.cloud/devops-casc-%E5%8F%82%E6%95%B0/</link><pubDate>Wed, 22 Jan 2025 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/devops-casc-%E5%8F%82%E6%95%B0/</guid><description>客户： 泉峰国际 版本：kse v4.1.2 问题：前端停止流水线后，agent pod 仍在运行（预计 6 min后清理）
issue： https://github.com/kubesphere/project/issues/5302 工单: https://tenant.quanxiangyun.com/qingcloud/manage/tickets/261228 jira： https://track.yunify.com/browse/ENTTICKET-4079
在jenkins console 中快速的运行和停止流水线也可复现这一问题，所以本质上是jenkins的bug，与ks-devops 的代码无关。 jenkins 内包含众多插件，且插件之间有很多依赖，所以不能单纯的升级jenkins 或某一个插件，这可能会造成兼容性问题或引起更多问题。</description></item><item><title>ssh</title><link>https://www.ryken.cloud/ssh/</link><pubDate>Thu, 02 Jan 2025 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/ssh/</guid><description>1 2 3 4 5 WARNING: UNPROTECTED PRIVATE KEY FILE! Permissions 0777 for &amp;#39;/root/.ssh/id_rsa&amp;#39; are too open. It is recommended that your private key files are NOT accessible by others.</description></item><item><title/><link>https://www.ryken.cloud/IPV6/</link><pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/IPV6/</guid><description>#ipv6 #calico
参考文档：
IPv4/IPv6 双协议栈 | Kubernetes Configure dual stack or IPv6 only | Calico Documentation (tigera.io) 配置 kubernetes kube-apiserver: --service-cluster-ip-range=&amp;lt;IPv4 CIDR&amp;gt;,&amp;lt;IPv6 CIDR&amp;gt; kube-controller-manager: --cluster-cidr=&amp;lt;IPv4 CIDR&amp;gt;,&amp;lt;IPv6 CIDR&amp;gt; --service-cluster-ip-range=&amp;lt;IPv4 CIDR&amp;gt;,&amp;lt;IPv6 CIDR&amp;gt; --node-cidr-mask-size-ipv4|--node-cidr-mask-size-ipv6 对于 IPv4 默认为 /24， 对于 IPv6 默认为 /64 kube-proxy: --cluster-cidr=&amp;lt;IPv4 CIDR&amp;gt;,&amp;lt;IPv6 CIDR&amp;gt; kubelet: 当没有 --cloud-provider 时，管理员可以通过 --node-ip 来传递逗号分隔的 IP 地址， 为该节点手动配置双栈 .</description></item><item><title>2. controller-runtime</title><link>https://www.ryken.cloud/2.-controller-runtime/</link><pubDate>Thu, 26 Dec 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/2.-controller-runtime/</guid><description>controller-runtime 是对 client-go 的高级封装
controller-runtime 是一个用于开发 Kubernetes controller 的库，包含了 controller 常用的模块，兼顾灵活性和模块化。
之前使用 client-go 开发 Kubernetes controller 时，中间会有很多和业务无关的重复工作，后来社区社区推出了 kubebuilder 和 operatorSDK 这种脚手架，它可以方便的渲染出 Controller 的整个框架，让开发者只用专注 Controller 本身的业务逻辑，特别是在开发 CRD 时，极为方便，这两个脚手架就是基于 controller-runtime。</description></item><item><title>1. client-go</title><link>https://www.ryken.cloud/1.-client-go/</link><pubDate>Wed, 25 Dec 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/1.-client-go/</guid><description>client-go 中的客户端 RestClient ClientSet DynamicClient DiscoveryClient 其中 ClientSet，DynamicClient，DiscoveryClient 都 RestClient 上的封装
client-go 中的三个队列 去重队列 延时队列 限频队列 其中延时队列是基于去重队列实现，限频队列是基于延时队列实现。</description></item><item><title>calico ebpf 支持情况</title><link>https://www.ryken.cloud/calico-ebpf-%E6%94%AF%E6%8C%81%E6%83%85%E5%86%B5/</link><pubDate>Tue, 17 Dec 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/calico-ebpf-%E6%94%AF%E6%8C%81%E6%83%85%E5%86%B5/</guid><description>calico 从 3.13 开始引入 ebpf，3.16 正式 GA，后续版本持续完善。所以 calico ebpf 已经比较成熟，calico 官方也提供了一些相关的文档和技术博客：
calico ebpf 模式 GA - Announcing eBPF Mode GA 介绍 calico ebpf 数据面 - Introducing the Calico eBPF dataplane 如何开启 ebpf 数据面 - Enable the eBPF dataplane 如何 troubleshoot ebpf 模式 - Troubleshoot eBPF mode 监控 calico ebpf 数据面 - How to Monitor Calico&amp;rsquo;s eBPF Data Plane for Proactive Cluster Management 根据以上文档，看出 Calico eBPF 数据面的优势：</description></item><item><title>calico ipv6 相关的系统参数优化</title><link>https://www.ryken.cloud/calico-ipv6-%E7%9B%B8%E5%85%B3%E7%9A%84%E7%B3%BB%E7%BB%9F%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/</link><pubDate>Tue, 17 Dec 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/calico-ipv6-%E7%9B%B8%E5%85%B3%E7%9A%84%E7%B3%BB%E7%BB%9F%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/</guid><description>1. 禁用 DAD（重复地址检测） echo 0 &amp;gt; /proc/sys/net/ipv6/conf/default/accept_dad net.ipv6.conf.default.accept_dad=0
2. ipv6 的路由缓存，可以提高路由查找的效率 net.ipv6.route.max_size=65536 net.ipv6.route.max_size 该内核参数的作用是设置目的地条目的缓存。当 Linux 内核解析到目的地的路由时，它会将其放入缓存中以备将来使用。
net.ipv6.route.max_size 默认为 4096。可以将该值调足够大，比如 65536、2147483647</description></item><item><title>calico 交换机配置静态路由</title><link>https://www.ryken.cloud/calico-%E4%BA%A4%E6%8D%A2%E6%9C%BA%E9%85%8D%E7%BD%AE%E9%9D%99%E6%80%81%E8%B7%AF%E7%94%B1/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/calico-%E4%BA%A4%E6%8D%A2%E6%9C%BA%E9%85%8D%E7%BD%AE%E9%9D%99%E6%80%81%E8%B7%AF%E7%94%B1/</guid><description>背景 在一些客户部署 kse 时，明确要求 pod id 可路由到，换言之需要使用 underlay 网络，与底层网络打通。现有的一些 underlay 网络方案可以选用基于 vlan 的技术实现也可以选用基于 bgp 的技术实现。两种技术实现均需要交换机侧做一些额外配置来符合网络需求：
bgp 技术实现需要：配置交换机 bgp 连接 或者 配置静态路由； vlan 技术实现需要：配置 trunk 模式、配置 vlan 网关 kse 中默认交付的是 calico，所以我们就 calico bgp 展开讨论：</description></item><item><title>policy 管理</title><link>https://www.ryken.cloud/policy-%E7%AE%A1%E7%90%86/</link><pubDate>Thu, 28 Nov 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/policy-%E7%AE%A1%E7%90%86/</guid><description>policyRepository
policyK8s
policyDirectory
1 2 3 4 5 6 7 8 9 10 11 12 13 14 apiVersion:cilium.io/v2kind:CiliumClusterwideNetworkPolicymetadata:name:default-denyspec:endpointSelector:matchExpressions:- key:&amp;#34;io.kubernetes.pod.namespace&amp;#34;operator:&amp;#34;NotIn&amp;#34;values:- &amp;#34;kube-system&amp;#34;enableDefaultDeny:egress:trueingress:true 使用 1.</description></item><item><title>2. CoreDNS 解析过程</title><link>https://www.ryken.cloud/2.-Coredns-%E8%A7%A3%E6%9E%90%E8%BF%87%E7%A8%8B/</link><pubDate>Mon, 18 Nov 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/2.-Coredns-%E8%A7%A3%E6%9E%90%E8%BF%87%E7%A8%8B/</guid><description>抛出问题 coredns 是个啥 coredns 记录了些啥 coredns 如何解析请求 pod 如何给 coredns 发送 dns 查询请求 存在哪些问题 Coredns 是个啥 项目地址： coredns/coredns: CoreDNS is a DNS server that chains plugins</description></item><item><title>debug vscode config</title><link>https://www.ryken.cloud/debug-vscode-config/</link><pubDate>Tue, 12 Nov 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/debug-vscode-config/</guid><description>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 { &amp;#34;name&amp;#34;: &amp;#34;debug install&amp;#34;, &amp;#34;type&amp;#34;: &amp;#34;go&amp;#34;, &amp;#34;debugAdapter&amp;#34;: &amp;#34;dlv-dap&amp;#34;, // the default &amp;#34;request&amp;#34;: &amp;#34;launch&amp;#34;, &amp;#34;mode&amp;#34;: &amp;#34;debug&amp;#34;, &amp;#34;host&amp;#34;: &amp;#34;127.</description></item><item><title>双栈</title><link>https://www.ryken.cloud/%E5%8F%8C%E6%A0%88/</link><pubDate>Tue, 12 Nov 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%8F%8C%E6%A0%88/</guid><description>kubekey 开发需求 检测主机是否支持 ipv6 修正 ipv6 相关的内核参数 支持开启 ipv6 以及 ipv6 的配置项（编辑 cni 配置文件） 安装 calico 并开启 ipv6 （添加 calico-node daemonset 的 ipv6 相关的环境变量） 配置 ipv6 (添加默认的 ipv6 ippool) 初始化 kubernetes 需要开启 ipv6 (使用 kubeadm 配置 kube-apiserver、kube-controller-manager、kube-proxy、kubelet 来开启 ipv6) ks 内部组件开发需求 ks 内部组件 ippool 支持 ipv6</description></item><item><title>双栈测试用例</title><link>https://www.ryken.cloud/%E5%8F%8C%E6%A0%88%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B/</link><pubDate>Tue, 12 Nov 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%8F%8C%E6%A0%88%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B/</guid><description>1. POD双栈IP： 已创建默认的 ipv4、ipv6 ippool
直接创建负载，查看负载 ip 未创建默认 ipv6 ippool
创建自定义 ipv4、ipv6 ippool 创建负载，查看负载 ip 示例 yaml：</description></item><item><title/><link>https://www.ryken.cloud/Arista-%E9%94%90%E6%8D%B7%E4%BA%A4%E6%8D%A2%E6%9C%BA%E9%85%8D%E7%BD%AE/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Arista-%E9%94%90%E6%8D%B7%E4%BA%A4%E6%8D%A2%E6%9C%BA%E9%85%8D%E7%BD%AE/</guid><description>#交换机 #arista
参考文档链接：
https://www.osslab.com.tw/wp-content/uploads/2018/03/Arista%E9%85%8D%E7%BD%AE%E6%89%8B%E5%86%8C.pdf https://www.arista.com/zh/um-eos/eos-ethernet-ports 登录：admin → enable → configure → zerotouch disable → write 先关闭zerotouch，否则会出现配置无法保存的情况 显示当前配置 show run</description></item><item><title/><link>https://www.ryken.cloud/calico-ebpf-dataplane/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/calico-ebpf-dataplane/</guid><description>#calico #ebpf
介绍calico ebpf Introducing the Calico eBPF dataplane (tigera.io)
开启 calico ebpf Enable the eBPF dataplane (tigera.io)</description></item><item><title/><link>https://www.ryken.cloud/cilium-%E8%83%BD%E5%8A%9B/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/cilium-%E8%83%BD%E5%8A%9B/</guid><description/></item><item><title/><link>https://www.ryken.cloud/containerlab/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/containerlab/</guid><description>#containerlab #network #tools
安装 bash -c &amp;ldquo;$(curl -sL https://get.containerlab.dev)&amp;rdquo;
配置 vyos
网络模式
主机网络 容器网络 配置 spine + leaf 安装 docker、kubectl</description></item><item><title/><link>https://www.ryken.cloud/envoy/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/envoy/</guid><description>Envoy 是一个强大且灵活的第 7 层开源代理。 它是一个 CNCF 毕业项目，用于各种服务网格解决方案。特别是，Envoy 为 Istio 服务网格提供支持，用作 sidecar 代理。
Cilium 已经使用 Envoy 来实现某些协议的 L7 策略和可观察性。 Cilium Service Mesh 使用无 sidecar 配置中利用 Envoy。</description></item><item><title/><link>https://www.ryken.cloud/fortio-%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/fortio-%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/</guid><description/></item><item><title/><link>https://www.ryken.cloud/hybirdnet-%E4%BD%BF%E7%94%A8/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/hybirdnet-%E4%BD%BF%E7%94%A8/</guid><description>#hybridnet #cni
[[hybirdnet.svg]] 给节点打 label
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 apiVersion:networking.</description></item><item><title/><link>https://www.ryken.cloud/hybirdnet-%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/hybirdnet-%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</guid><description>#hybridnet
crd 资源定义解释 [[hybridnet 自定义资源解释]] 整个流程：kubelet -&amp;gt; cni -&amp;gt; 打通网络 ipam 如何处理 环境的搭建 overlay 模式实现原理 封装的网卡 路由 创建的资源</description></item><item><title/><link>https://www.ryken.cloud/ingressAPI/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/ingressAPI/</guid><description>安装 以及 验证
1 --set ingressController.enabled=true 1 cilium config view | grep ingress-controller Kubernetes 提供了标准的 Ingress 资源类型来配置 L7 负载均衡和流量管理。在大多数集群中，应用 Ingress 资源需要安装 Ingress Controller，例如使用Nginx、Traefik 或 Contour。</description></item><item><title/><link>https://www.ryken.cloud/kube-ovn-underlay/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/kube-ovn-underlay/</guid><description>#kube-ovn #underlay
功能限制 由于该模式下容器网络直接使用物理网络进行二层包转发，Overlay 模式下的 SNAT/EIP， 分布式网关/集中式网关等 L3 功能无法使用。
使用 underlay 模式主要涉及的资源有：
资源 说明 provider-networks underlay 网卡提供者 vlans vlan 信息 subnets 子网/ippool 地址池 ips ip 分配记录 provider-networks 资源 ProviderNetwork 提供了主机网卡到物理网络映射的抽象，将同属一个网络的网卡进行统一管理， 并解决在复杂环境下同机器多网卡、网卡名不一致、对应 Underlay 网络不一致等情况下的配置问题。</description></item><item><title/><link>https://www.ryken.cloud/RSS-RPS/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/RSS-RPS/</guid><description>单队列没有问题，多队列有问题 ebpf
网卡多队列 多核 多CPU RSS RPS RFS
由于这块内存区域是有限的，如果数据包的速率非常快，单个 CPU 来不及取走这些包，新来的包就会被丢弃。这时候，Receive Side Scaling（RSS，接收端扩展）或者多队列（multiqueue）一类的技术可能就会排上用场。
可以把软中断系统想象成一系列内核线程（每个 CPU 一个），这些线程执行针对不同事件注册的处理函数（handler）。如果你执行过 top 命令，可能会注意到ksoftirqd/0 这个内核线程，其表示这个软中断线程跑在 CPU 0 上。</description></item><item><title/><link>https://www.ryken.cloud/wireshark-%E6%8A%93%E5%8C%85/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/wireshark-%E6%8A%93%E5%8C%85/</guid><description>#wireshark #抓包
wireshark 抓远程 ubuntu 的包 安装 rpcapd rpcapd 是一个为 Windows 版本的Wireshark协议分析器提供远程流量捕获的守护进程。它随Windows 的 WinPcap 网络捕获库一起提供，之前 Linux 中的没有 libpcap ,后来添加了。 使用 rpcapd-linux 使用 the-tcpdump-group/libpcap 【推荐】没有大的报错问题 1 2 3 4 5 6 apt-get build-dep libpcap -y git clone https://github.</description></item><item><title/><link>https://www.ryken.cloud/%E5%BC%80%E6%9C%BA%E8%87%AA%E5%90%AF/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%BC%80%E6%9C%BA%E8%87%AA%E5%90%AF/</guid><description>#开机自启 #linux
最简单的方法是使用 rc.local 实现开机自启，不过由于系统版本更替，很多新版本都没有 rc.local 文件了，需要手动设置 添加 /etc/rc.local 文件
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 cat &amp;lt;&amp;lt;EOF &amp;gt;/etc/rc.</description></item><item><title/><link>https://www.ryken.cloud/%E6%A8%A1%E5%9D%97%E4%BB%A5%E5%8F%8A%E9%85%8D%E7%BD%AE/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E6%A8%A1%E5%9D%97%E4%BB%A5%E5%8F%8A%E9%85%8D%E7%BD%AE/</guid><description>#blockbox #exporter #prometheus
简单介绍 Blackbox Exporter 是 Prometheus 社区提供的 官方黑盒监控解决方案,其允许用户通过: http\HTTPS\DNS\TCP\ICMP\gRPC的方式对网络进行探测.
支持的协议：HTTP, HTTPS, DNS, TCP, ICMP, gRPC.
各个模块的配置： blackbox_exporter/CONFIGURATION.md at master · prometheus/blackbox_exporter (github.</description></item><item><title/><link>https://www.ryken.cloud/%E6%B5%81%E9%87%8F%E8%B5%B0%E5%90%91/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E6%B5%81%E9%87%8F%E8%B5%B0%E5%90%91/</guid><description> 容器到主机的流量走向</description></item><item><title/><link>https://www.ryken.cloud/%E7%BD%91%E5%8D%A1%E5%A4%9A%E9%98%9F%E5%88%97-+-%E4%B8%AD%E6%96%AD%E7%BB%91%E5%AE%9A/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E7%BD%91%E5%8D%A1%E5%A4%9A%E9%98%9F%E5%88%97-+-%E4%B8%AD%E6%96%AD%E7%BB%91%E5%AE%9A/</guid><description>#网卡多队列 #network #irqbalance
单CPU处理网络IO存在瓶颈, 目前经常使用网卡多队列提高性能.
通常情况下, 每张网卡有一个队列(queue), 所有收到的包从这个队列入, 内核从这个队列里取数据处理. 该队列其实是ring buffer(环形队列), 内核如果取数据不及时, 则会存在丢包的情况.
一个CPU处理一个队列的数据, 这个叫中断. 默认是cpu0(第一个CPU)处理. 一旦流量特别大, 这个CPU负载很高, 性能存在瓶颈. 所以网卡开发了多队列功能, 即一个网卡有多个队列, 收到的包根据TCP四元组信息hash后放入其中一个队列, 后面该链接的所有包都放入该队列.</description></item><item><title>1. OFN Overview</title><link>https://www.ryken.cloud/1.-OFN-Overview/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/1.-OFN-Overview/</guid><description>1 2 list from &amp;#34;CloudNative/Faas-ofn&amp;#34; sort file.name 架构图</description></item><item><title>1. spiderpool 介绍</title><link>https://www.ryken.cloud/1.-spiderpool-%E4%BB%8B%E7%BB%8D/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/1.-spiderpool-%E4%BB%8B%E7%BB%8D/</guid><description>介绍 一个主要运用于 underlay ipam 的一个 cni 插件
Spiderpool 提供了一个 Kubernetes 的 underlay 和 RDMA 网络解决方案, 它能运行在裸金属、虚拟机和公有云上。
组件 - 架构图 CNI 列表 cni 有三类 plugin CNI：</description></item><item><title>1. 网络 datapath + ebpf(xdp、tc)</title><link>https://www.ryken.cloud/1.-%E7%BD%91%E7%BB%9C-datapath-+-ebpfxdptc/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/1.-%E7%BD%91%E7%BB%9C-datapath-+-ebpfxdptc/</guid><description>网络包 Data Path XDP hook作用于到Ingress流量，也就是RX流向。不会作用到 Egress 流量。 TC hook作用于Egress流量，也就是TX流向。
在没有引入XDP之前，原来的网络数据包传输路径是这样的： 启用XDP后，网络包传输路径是这样的： cilium 中关于 xdp 三种模式的解释：
Native： 这是默认模式，其中XDP BPF程序直接从网络驱动程序的早期接收路径运行。大多数用于10G及以上的广泛使用的NIC已经支持原生XDP。</description></item><item><title>2. OFN Install</title><link>https://www.ryken.cloud/2.-OFN-Install/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/2.-OFN-Install/</guid><description>安装 helm repo add openfunction https://openfunction.github.io/charts/ helm repo update kubectl create namespace openfunction helm install openfunction openfunction/openfunction -n openfunction 安装前后对比图： v1.</description></item><item><title>2. 初始化 - 组件</title><link>https://www.ryken.cloud/2.-%E5%88%9D%E5%A7%8B%E5%8C%96-%E7%BB%84%E4%BB%B6/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/2.-%E5%88%9D%E5%A7%8B%E5%8C%96-%E7%BB%84%E4%BB%B6/</guid><description>部署后组件总览 daemonset：spiderpool-agent deployment：spiderpool-controller pod：spiderpool-init spiderpoolInit pod：/usr/bin/spiderpool-init 根据环境变量初始化 spiderpoolCoordinator、subnet、ippool、多集群资源，初始化完成之后退出。
daemonset - agent(hostnetwork) init container install plugins multus-cni containers spiderpool-agent daemon &amp;ndash;config-path=/tmp/spiderpool/config-map/conf.</description></item><item><title>3. OFN QuickStart</title><link>https://www.ryken.cloud/3.-OFN-QuickStart/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/3.-OFN-QuickStart/</guid><description>环境要求 镜像仓库 secret 构建 funcation 会构建一个 funcation 镜像，此时需要你将构造的镜像 push 到 dockerhub 或者Quary.io 因此需要提供一个 secret
1 2 3 4 5 REGISTRY_SERVER=https://index.</description></item><item><title>3. TC 介绍</title><link>https://www.ryken.cloud/3.-TC-%E4%BB%8B%E7%BB%8D/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/3.-TC-%E4%BB%8B%E7%BB%8D/</guid><description>TC - Traffic Control 流量控制器TC（Traffic Control）用于Linux内核的流量控制，它利用队列规定建立处理数据包的队列，并定义队列中的数据包被发送的方式， 从而实现对流量的控制(调度网络包的延迟、丢失、传输顺序和速度控制，例如修改包（mangle，给 skb 打标记）、重路由（reroute）、丢弃包（drop）)
TC主要包括三个基本要素：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 1: qdisc：队列规则，TC的核心，用于确定数据包的发送方式。如下命令实现了指定的eth0网卡上所有的包固定加了200ms延时 # tc qdisc add dev eth0 root netem delay 200ms 2: class和filter：类和过滤器。类即是数据流量的类别，各种应用和终端的流量通过filter进行分类，进入到队列规则里排队进行发送。如下命令行所示即通过class和filter实现了对指定ip的限速，其它弱网类似： # tc class add dev eth0 parent 1:1 classid 1:2 htb rate 500kbit # tc filter add dev eth0 protocol ip parent 1:0 prio 3 u32 match 192.</description></item><item><title>4. CoreDNS 疑难杂症</title><link>https://www.ryken.cloud/4.-Coredns-%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/4.-Coredns-%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/</guid><description>1. coredns &amp;ldquo;no nameservers found&amp;rdquo; error coredns CrashLoopBackOff
1 kubectl edit configmap coredns -n kube-system 原 coredns configmap 配置如下：</description></item><item><title>bandwidth 带宽限制</title><link>https://www.ryken.cloud/bandwidth-%E5%B8%A6%E5%AE%BD%E9%99%90%E5%88%B6/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/bandwidth-%E5%B8%A6%E5%AE%BD%E9%99%90%E5%88%B6/</guid><description>bandwidth 插件 CNI-bandwidth
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 { &amp;#34;cniVersion&amp;#34;: &amp;#34;0.</description></item><item><title>Big TCP</title><link>https://www.ryken.cloud/Big-TCP/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Big-TCP/</guid><description>使用 ipv4 &amp;amp; ipv6 的 big TCP 需要 6.3 及以上的内核
实验使用的内核版本为：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 root@server:~# cat /etc/os-release PRETTY_NAME=&amp;#34;Ubuntu 22.</description></item><item><title>build record</title><link>https://www.ryken.cloud/build-record/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/build-record/</guid><description>build 工具包 go 安装包下载地址：
wget https://studygolang.com/dl/golang/go1.17.6.linux-amd64.tar.gz 1 2 3 4 5 6 7 8 # 配置环境 cat &amp;lt;&amp;lt;EOF &amp;gt; /etc/profile.</description></item><item><title>cilium gateway api</title><link>https://www.ryken.cloud/cilium-gateway-api/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/cilium-gateway-api/</guid><description>介绍 大多数微服务架构都需要将一些服务暴露给集群外部并将流量安全地路由到集群中。Kubernetes Ingress API 传统上是平台运营商将流量路由到集群的方式，但它也有许多的限制。
Gateway API 解决了这些限制，同时 Cilium 已经支持 Gateway API。
如果你问一百个人什么是服务网格，你可能会得到一百个不同的答案。每个人对服务网格的作用及其解决的问题都有不同的解释。 在 Cilium Service Mesh 测试期间，当被问到“您最感兴趣 Service Mesh 的哪些功能”时，绝大多数人认为可见性和流量加密是关键功能。 但同样值得注意的是，一半的参与者回答“Kubernetes Ingress”，尽管事实上有些人可能不认为它是服务网格的关键组件。无论您是否认为 Ingress 是 Service Mesh 功能，它仍然是 Kubernetes 流量工程的一个重要方面。</description></item><item><title>cilium ingress controller</title><link>https://www.ryken.cloud/cilium-ingress-controller/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/cilium-ingress-controller/</guid><description>How to deploy Cilium Service Mesh Traffic Management &amp;amp; Load-Balancing with Ingress Enable L7 Observability Configuration Kubernetes 提供了标准的 Ingress 资源类型来配置 L7 负载均衡和流量管理。 Cilium 自动在集群中实现 Ingress 并执行已配置的负载均衡配置。 在大多数集群中，应用 Ingress 资源需要安装 Ingress Controller，例如使用Nginx、Traefik 或 Contour。 在本实验中，我们使用 Cilium 来管理 Ingress 资源，无需外部控制器，因此您无需选择 Ingress Controller 提供程序，也无需关心使其保持最新状态！</description></item><item><title>ciliumnodes</title><link>https://www.ryken.cloud/IPAM-ciliumnodes/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/IPAM-ciliumnodes/</guid><description>https://github.com/cilium/cilium/blob/186b84ec5ce362e6acf762ae5c907812a84f31f0/pkg/k8s/apis/cilium.io/v2/types.go#L313 AWS ENI — Cilium 1.15.7 documentation
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 // +genclient // +genclient:nonNamespaced // +k8s:deepcopy-gen:interfaces=k8s.</description></item><item><title>clustermesh</title><link>https://www.ryken.cloud/clustermesh/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/clustermesh/</guid><description>Cilium Cluster Mesh 允许链接多个 Kubernetes 集群，前提是：
所有集群都将 Cilium 作为 CNI 运行 所有工作节点都有唯一的IP地址并且能够相互连接 在 Cilium 集群上激活集群网格时，会部署一个新的控制平面来管理该集群的网格及其 etcd 键值存储。 然后，其他集群的代理可以以只读模式访问此集群网格控制平面，从而允许它们访问有关集群的元数据，例如服务名称和相应的 IP。 当两个或多个集群网格化时，Cilium 允许您通过向服务添加注释来将服务设置为一个或多个集群中的全局服务： service.</description></item><item><title>flannel 容器网络插件的设计实现原理</title><link>https://www.ryken.cloud/flannel-%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/flannel-%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</guid><description>flannel 容器网络插件的设计实现原理 本文基于 flannel v0.21.0 版本源码分析.
CNI, 它的全称是 Container Network Interface, 即容器网络的 API 接口. 平时比较常用的 CNI 实现有 Flannel、Calico 等.</description></item><item><title>GatewayAPI-Lab1</title><link>https://www.ryken.cloud/GatewayAPI-Lab1/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/GatewayAPI-Lab1/</guid><description>介绍 实验地址： https://isovalent.com/labs/cilium-gateway-api/
实验总览
Cilium Installation with Gateway API Gateway API - HTTP Traffic Management Gateway API - HTTPS Traffic Management Gateway API - TLS Passthrough Gateway API - HTTP Load Balancing 嵌入式 Envoy 代理 Cilium 已经使用 Envoy 实现了某些协议的 L7 策略和可观察性。</description></item><item><title>GatewayAPI-Lab2</title><link>https://www.ryken.cloud/GatewayAPI-Lab2/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/GatewayAPI-Lab2/</guid><description>https://isovalent.com/labs/cilium-gateway-api-advanced/ https://isovalent.com/blog/post/tutorial-redirect-rewrite-and-mirror-http-requests-with-cilium-gateway-api/
Gateway API — Deploy Sample App HTTP Request and Response Header Modifier Gateway API — HTTP Mirroring、HTTP Rewrite、HTTP Redirect Cross-namespace &amp;amp; Shared Gateway API Gateway API — gRPC routing Example Gateway API — Gamma Example 1 2 3 4 5 6 7 kubectl get crd \ gatewayclasses.</description></item><item><title>grafana 可视化</title><link>https://www.ryken.cloud/grafana-%E5%8F%AF%E8%A7%86%E5%8C%96/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/grafana-%E5%8F%AF%E8%A7%86%E5%8C%96/</guid><description>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 kubectl apply -f - &amp;lt;&amp;lt;EOF apiVersion: v1 kind: ConfigMap metadata: name: grafana-config namespace: calico-monitoring data: prometheus.</description></item><item><title>hybridnet 网络插件</title><link>https://www.ryken.cloud/hybridnet-%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/hybridnet-%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6/</guid><description>[[vlan 配置]]
一键安装 1 2 3 helm repo add hybridnet https://alibaba.github.io/hybridnet/ helm repo update helm install hybridnet hybridnet/hybridnet -n kube-system --set init.</description></item><item><title>ingress api - gateway api</title><link>https://www.ryken.cloud/ingress-api-gateway-api/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/ingress-api-gateway-api/</guid><description> https://kubernetes.io/docs/reference/kubernetes-api/service-resources/ingress-v1/ https://kubernetes.io/docs/reference/kubernetes-api/service-resources/ingress-class-v1/
https://kubernetes.io/docs/concepts/services-networking/ingress/ https://kubernetes.io/docs/concepts/services-networking/gateway/ https://gateway-api.sigs.k8s.io/
https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/api/networking/v1/types.go https://github.com/kubernetes-sigs/gateway-api/blob/main/apis/v1/gateway_types.go</description></item><item><title>iptables</title><link>https://www.ryken.cloud/iptables/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/iptables/</guid><description>Calico 使用 iptables 数据面时会创建多个 iptables 规则来实现网络策略和流量控制。这些规则用于实现诸如流量隔离、流量转发、负载均衡和访问控制等功能。 Calico 会根据定义的网络策略自动生成 iptables 规则。此外，Calico 还会创建一些基础规则来实现其核心功能，例如路由和网络隔离。所以说，即使您没有定义任何网络策略，Calico 仍然会在主机上创建一些 iptables 规则。
calico 使用 iptables
与 service 有什么关系？</description></item><item><title>iptables mark</title><link>https://www.ryken.cloud/iptables-mark/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/iptables-mark/</guid><description>&amp;ndash;set-mark 用于设置数据包的 32 位标记值 &amp;ndash;set-xmark 用于设置数据包的 128 位标记值
fff00000 -m mark
mark connmark
calico mark raw 表 主要用来决定是否对数据包进行状态跟踪。存在于PREROUTING 和 OUTPUT 链，对收到的数据包在连接跟踪前进行处理</description></item><item><title>iptables 查看流向</title><link>https://www.ryken.cloud/iptables-%E6%9F%A5%E7%9C%8B%E6%B5%81%E5%90%91/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/iptables-%E6%9F%A5%E7%9C%8B%E6%B5%81%E5%90%91/</guid><description>可以使用 iptables 提供的 LOG target 或 mark set&amp;amp;match 方式来跟踪 iptables 中的数据流，需要针对特定流程插入LOG target或match在入口包设定好的mark，对iptables规则的侵入较大，调试和观察也较为复杂； iptables自身提供了TRACE功能，一旦设定，当数据包匹配到任意chain上任意table的处理规则时，iptables会在系统日志(/var/log/syslog)中自动输出此时的数据包状态日志。 TRACE target 只能在 iptables 的 raw 表中添加，raw 表中有两条 iptables built-in chain: PREROUTING 和 OUTPUT，分别代表网卡数据入口和本地进程下推数据的出口。TRACE target 就添加在这两条 chain 上。</description></item><item><title>k3s 多节点安装</title><link>https://www.ryken.cloud/k3s-%E5%A4%9A%E8%8A%82%E7%82%B9%E5%AE%89%E8%A3%85/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/k3s-%E5%A4%9A%E8%8A%82%E7%82%B9%E5%AE%89%E8%A3%85/</guid><description>项目地址： https://github.com/k3s-io/k3s/releases 文档地址： https://docs.k3s.io/zh/
k3s 架构 多节点安装 安装 server 节点 如果不要多节点部署实现高可用，可以禁用 servicelb 组件。traefik 虽然是 K3s 自带的网络组件，但是其默认会占用 80 和 443 端口，也可以禁用。</description></item><item><title>kubeadm install k8s</title><link>https://www.ryken.cloud/kubeadm-install-k8s/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/kubeadm-install-k8s/</guid><description>ubuntu 安装 kubernetes 1. 安装 docker 安装docker：
curl -sSL https://get.daocloud.io/docker | sh curl -fsSL https://get.docker.com | bash -s docker &amp;ndash;mirror Aliyun 2.</description></item><item><title>kubernetes nodeipam 实现原理</title><link>https://www.ryken.cloud/nodeIPAM-%E6%BA%90%E7%A0%81/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/nodeIPAM-%E6%BA%90%E7%A0%81/</guid><description>kubernetes nodeipam 实现原理 原文档链接： notes/kubernetes_nodeipam_controller_code.md at main · rfyiamcool/notes (github.com)
基于 kubernetes v1.27.0 版本对 nodeipam controller 源码分析</description></item><item><title>nodeIPAM</title><link>https://www.ryken.cloud/nodeIPAM/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/nodeIPAM/</guid><description>下面为 kube-controller-manager 1.25.3 的启动命令，可以看出 cluster-cidr 指定了 podCIDRs，node-cidr-mask-size 用于指定 cluster-cidr 的分块大小，service-cluster-ip-range 用于指定 serviceCIDR
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 - kube-controller-manager- --allocate-node-cidrs=true- --authentication-kubeconfig=/etc/kubernetes/controller-manager.</description></item><item><title>Nodelocaldns 原理</title><link>https://www.ryken.cloud/3.-Nodelocaldns-%E5%8E%9F%E7%90%86/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/3.-Nodelocaldns-%E5%8E%9F%E7%90%86/</guid><description>NodeLocal DNS 是什么？ 通过在集群节点上运行一个 DaemonSet 来提高 clusterDNS 性能和可靠性。
处于 ClusterFirst 的 DNS 模式下的 Pod 可以连接到 kube-dns 的 serviceIP 进行 DNS 查询。通过 kube-proxy 组件添加的 iptables 规则将其转换为 CoreDNS 端点。通过在每个集群节点上运行 DNS 缓存，NodeLocal DNSCache 可以缩短 DNS 查找的延迟时间、使 DNS 查找时间更加一致，以及减少发送到 kube-dns 的 DNS 查询次数。</description></item><item><title>perf 性能分析</title><link>https://www.ryken.cloud/perf-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/perf-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/</guid><description>[[网卡多队列 + 中断绑定]]
Wiki - Linux 效能分析工具: Perf (ncku.edu.tw) 网络测试工具 一、iperf iperf是一个网络性能测试工具。iperf可以测试TCP和UDP带宽质量。iperf可以测量最大TCP带宽，具有多种参数和UDP特性。iperf可以报告带宽，延迟抖动和数据包丢失。利用iperf这一特性，可以用来测试一些网络设备如路由器，防火墙，交换机等的性能。
服务端10.74.148.74启动iperf3，监听端口12345，请求间断时间1s ~# iperf3 -s -p 12345 -i 1 客户端向10.</description></item><item><title>Pod</title><link>https://www.ryken.cloud/Pod/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Pod/</guid><description>Pod是Kubernetes最重要的基本概念，每个Pod都有一个特殊的被称为“根容器”的Pause容器。除了Pause容器，每个Pod还包含一个或多个紧密相关的用户业务容器。 pause 容器： 引入业务无关并且不易死亡的Pause容器作为Pod的根容器，以它的状态代表整个容器组的状态。 Pod里的多个业务容器共享Pause容器的IP，共享Pause容器挂接的Volume，这样既简化了密切关联的业务容器之间的通信问题，也很好地解决了它们之间的文件共享问题。 Pod的网络： Kubernetes为每个Pod都分配了唯一的IP地址，称之为Pod IP。
Pod内网络：一个Pod里的多个容器共享Pod IP地址。 Pod间网络：一个Pod里的容器与另外主机上的Pod容器能够直接通信。因为Kubernetes要求底层网络支持集群内任意两个Pod之间的TCP/IP直接通信，这通常采用虚拟二层网络技术来实现，例如Flannel、Open vSwitch等。 Pod类型 静态Pod：并没被存放在Kubernetes的etcd存储里，而是被存放在某个具体的Node上的一个具体文件中，并且只在此Node上启动、运行。 普通Pod：一旦被创建，就会被放入etcd中存储，随后会被Kubernetes Master调度到某个具体的Node上并进行绑定，随后该Pod被对应的Node上的kubelet进程实例化成一组相关的Docker容器并启动。在默认情况下，当Pod里的某个容器停止时，Kubernetes会自动检测到这个问题并且重新启动这个Pod（重启Pod里的所有容器），如果Pod所在的Node宕机，就会将这个Node上的所有Pod重新调度到其他节点上。 图Pod、容器与Node的关系</description></item><item><title>Q&amp;A 探索</title><link>https://www.ryken.cloud/QA-%E6%8E%A2%E7%B4%A2/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/QA-%E6%8E%A2%E7%B4%A2/</guid><description>ipam + 数据流向 如何配置 container network overlay - native route bgp - CiliumBGPPeeringPolicy
kube-proxy 替换 1.13 版本
https://docs.cilium.io/en/stable/network/kubernetes/kubeproxy-free/ 1.14 版本</description></item><item><title>SDN 网络</title><link>https://www.ryken.cloud/SDN-%E7%BD%91%E7%BB%9C/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/SDN-%E7%BD%91%E7%BB%9C/</guid><description>ASW （接入层交换机）数据交换模块接入交换机，接入云服务器，上行互联核心交换机DSW。 DSW （分布层交换机）：核心交换机，用于连接各个ASW接入交换机。 CSW （内网接入交换机）：接入用户内网骨干，实现云网络内外部的路由分发交互，包括VPC专线接入。CSW可以实现专线侧到XGW的VxLAN封装。 LSW （综合接入交换机）综合接入模块,云产品服务接入交换机，主要提供VPC和SLB等服务。各类云产品服务器（XGW/SLB/OPS）分别与两台LSW互联，通过OSPF交换路由信息；两台LSW之间通过iBGP交互路由信息；LSW与DSW、CSW之间通过eBGP交换路由信息。 云计算网络 ASW DSW CSW LSW - zzzzy09 - 博客园 (cnblogs.</description></item><item><title>servicemesh</title><link>https://www.ryken.cloud/servicemesh/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/servicemesh/</guid><description>https://isovalent.com/blog/post/cilium-service-mesh/ What is Cilium Service Mesh? - Interview with Thomas Graf on eCHO Livestream (youtube.com)
随着分布式应用程序的引入，额外的可见性、连接性和安全性要求也随之浮现。 应用程序组件通过不受信任的网络跨云和本地边界进行通信，需要负载平衡来理解应用程序协议，弹性变得至关重要，并且安全性必须发展到发送者和接收者可以验证彼此身份的模型。在分布式应用程序的早期，这些需求是通过将所需的逻辑直接嵌入到应用程序中来解决的。 服务网格从应用程序中提取这些功能，并将它们作为基础设施的一部分提供给所有应用程序使用，因此不再需要更改每个应用程序。
弹性连接 服务间通信必须能够跨越云、集群和场所等边界。通信必须具有弹性和容错能力</description></item><item><title>Submariner</title><link>https://www.ryken.cloud/Submariner/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Submariner/</guid><description>Submariner (rancher.cn)
安装：
subctl： curl -Ls https://get.submariner.io | bash 自定义 crd 以及作用
部署 broker
加入集群</description></item><item><title>tc</title><link>https://www.ryken.cloud/tc/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/tc/</guid><description>tc ebpf 的 direct-action (da) 模式：( https://arthurchiao.art/blog/understanding-tc-da-mode-zh/)
用作 action 时，eBPF 程序的返回值 提示系统接下来对这个包执行什么动作，下面的内容来自 tc-bpf(8)：
TC_ACT_OK (0)：结束处理过程，放行（allows the packet to proceed）。 TC_ACT_SHOT (2)：==丢弃包==。 TC_ACT_UNSPEC (-1)：使用 tc 的默认 action（与 classifier/filter 返回 -1 时类似）。 TC_ACT_PIPE (3)：如果有下一个 action，执行之。 TC_ACT_RECLASSIFY (1)：从头开始，重新执行分类过程。 其他值：定义在 include/uapi/linux/pkt_cls.</description></item><item><title>TCP三次握手和四次挥手</title><link>https://www.ryken.cloud/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%92%8C%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%92%8C%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/</guid><description>TCP三次握手和四次挥手 大量的 TIME_WAIT 状态 TCP 连接存在，其本质原因是什么？ 大量的短连接存在 特别是 HTTP 请求中，如果 connection 头部取值被设置为 close 时，基本都由「服务端」发起主动关闭连接 而，TCP 四次挥手关闭连接机制中，为了保证 ACK 重发和丢弃延迟数据，设置 time_wait 为 2 倍的 MSL（报文最大存活时间） TIME_WAIT 状态：</description></item><item><title>webhook</title><link>https://www.ryken.cloud/webhook/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/webhook/</guid><description>动态准入控制插件
MutatingWebhookConfiguration ValidatingWebhookConfiguration k8s webhook准入控制插件源码级别理解-注入sidecar - 知乎 (zhihu.com)
openelb webhook 使用 kube-webhook-certgen port-allocator webhook 使用 cert-manager
ks使用 helm</description></item><item><title>一个简单的例子</title><link>https://www.ryken.cloud/%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BE%8B%E5%AD%90/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BE%8B%E5%AD%90/</guid><description>一个运行在Tomcat里的Web App，JSP页面通过JDBC直接访问MySQL数据库并展示数据。该例子只要程序正确连接到了数据库，就会自动完成对应的表的创建与初始化数据的准备工作。所以，当我们通过浏览器访问此应用时，就会显示一个表格的页面，数据则来自数据库。 启动两个容器：Web App容器和MySQL容器，并且Web App容器需要访问MySQL容器。在Docker时代，假设我们在一个宿主机上启动了这两个容器，就需要把MySQL容器的IP地址通过环境变量注入Web App容器里；同时，需要将Web App容器的8080端口映射到宿主机的8080端口，以便在外部访问。
创建mysql服务： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 apiVersion:v1kind:ReplicationControllermetadata:name:mysqlspec:replicas:1selector:app:mysqltemplate:metadata:labels:app:mysqlspec:containers:- name:mysqlimage:mysql:5.</description></item><item><title>优化总览</title><link>https://www.ryken.cloud/%E4%BC%98%E5%8C%96%E6%80%BB%E8%A7%88/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E4%BC%98%E5%8C%96%E6%80%BB%E8%A7%88/</guid><description>虚拟化带来了灵活性和可扩展性，但同时也伴随着一些性能上的损失；特别是在网络性能上，让容器网络性能相比主机网络性能大幅下降了 35%。
回顾一下标准 Kubernetes 网络数据路径架构带来的一些限制以及 Cilium 如何解决这些限制
Kube-proxy 替换 Kube-Proxy 将通过 iptables 或 ipvs 系统处理 NAT 和 services 负载平衡
限制</description></item><item><title>使用 containerlab + kind 搭建 calico-tor</title><link>https://www.ryken.cloud/%E4%BD%BF%E7%94%A8-containerlab-+-kind-%E6%90%AD%E5%BB%BA-calico-tor/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E4%BD%BF%E7%94%A8-containerlab-+-kind-%E6%90%AD%E5%BB%BA-calico-tor/</guid><description>1. 使用 kind 创建 node 节点 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 kind:Clustername:clusterapiVersion:kind.</description></item><item><title>光大监控需求整理</title><link>https://www.ryken.cloud/%E5%85%89%E5%A4%A7%E7%9B%91%E6%8E%A7%E9%9C%80%E6%B1%82%E6%95%B4%E7%90%86/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%85%89%E5%A4%A7%E7%9B%91%E6%8E%A7%E9%9C%80%E6%B1%82%E6%95%B4%E7%90%86/</guid><description>需求整理 网络监控的自证，从监控和日志上给证据。(带宽、吞吐率、延迟、抖动、错误的监控) 网络错误后、业务的快速恢复。方案上可以切换集群、网络自修复等。(快速恢复环境的最佳实践文档) 文档细化 文档 word 化，脑图 + 分析步骤 脑图中一些说明补充为命令的指导(如四层的网络检测怎么做，nc命令的简要说明) 数据的采集、日志的采集(一键收集日志的脚本) [长期] 云上网络监控的整体规划，不依赖具体cni。 KSE 4.</description></item><item><title>共享Pod级 volume</title><link>https://www.ryken.cloud/%E5%85%B1%E4%BA%ABPod%E7%BA%A7-volume/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%85%B1%E4%BA%ABPod%E7%BA%A7-volume/</guid><description>在Pod内包含两个容器：tomcat和busybox，在Pod级别设置Volume“app-logs”，用于tomcat向其中写日志文件，busybox读日志文件。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 apiVersion:v1kind:Podmetadata:name:volume-podspec:containers:- name:tomcatimage:kubeguide/tomcat-app:v1ports:- containerPort:8080volumeMounts:- name:app-logsmountPath:/usr/local/tomcat/logs- name:Ubuntuimage:Ubuntu:latestcommand:[&amp;#34;sh&amp;#34;,&amp;#34;-c&amp;#34;,&amp;#34;tail -f /logs/catalina*.</description></item><item><title>内核参数</title><link>https://www.ryken.cloud/%E5%86%85%E6%A0%B8%E5%8F%82%E6%95%B0/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%86%85%E6%A0%B8%E5%8F%82%E6%95%B0/</guid><description>ipvs warn 关闭 - 当ipvs连不上后端时会打印相关的报错信息 sysctl -w net.ipv4.vs.ignore_no_rs_error=1 IPVS no destination available - Kubernetes 实践指南 (imroc.cc)</description></item><item><title>如何本机 debug Cilium</title><link>https://www.ryken.cloud/%E5%A6%82%E4%BD%95%E6%9C%AC%E6%9C%BA-debug-Cilium/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%A6%82%E4%BD%95%E6%9C%AC%E6%9C%BA-debug-Cilium/</guid><description>开发者文档： https://docs.cilium.io/en/stable/contributing/development/
使用 kind make kind：根据传递的参数创建一个 kind 集群 make kind-down：关闭并删除 kind 集群
make kind-image: 构建所有的 Cilium 镜像并将其加载到集群中 make kind-image-agent: 仅构建 Cilium Agent 镜像并将其加载到集群中 make kind-image-operator: 仅构建 Cilium Operator (generic) 镜像并将其加载到集群中 make kind-debug: 构建禁用优化并嵌入 dlv 以进行实时调试的所有 Cilium 镜像并将其加载到集群中 make kind-debug-agent: 像 kind-debug, 但只针对cilium agent.</description></item><item><title>官方示例</title><link>https://www.ryken.cloud/%E5%AE%98%E6%96%B9%E7%A4%BA%E4%BE%8B/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%AE%98%E6%96%B9%E7%A4%BA%E4%BE%8B/</guid><description>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 kubeProxyReplacement:truek8sServiceHost:kind-control-planek8sServicePort:6443operator:# only 1 replica needed on a single node setupreplicas:1prometheus:enabled:trueserviceMonitor:enabled:truehubble:relay:# enable relay in 02# enabled: trueservice:type:NodePortprometheus:enabled:trueserviceMonitor:enabled:truemetrics:serviceMonitor:enabled:trueenableOpenMetrics:trueenabled:- dns- drop- tcp- icmp- &amp;#34;flow:sourceContext=workload-name|reserved-identity;destinationContext=workload-name|reserved-identity&amp;#34;- &amp;#34;kafka:labelsContext=source_namespace,source_workload,destination_namespace,destination_workload,traffic_direction;sourceContext=workload-name|reserved-identity;destinationContext=workload-name|reserved-identity&amp;#34;- &amp;#34;httpV2:exemplars=true;labelsContext=source_ip,source_namespace,source_workload,destination_ip,destination_namespace,destination_workload,traffic_direction;sourceContext=workload-name|reserved-identity;destinationContext=workload-name|reserved-identity&amp;#34;dashboards:enabled:truenamespace:monitoringannotations:grafana_folder:&amp;#34;Hubble&amp;#34;ui:# enable UI in 02# enabled: trueservice:type:NodePortprometheus:enabled:trueserviceMonitor:enabled:true 四个环境信号</description></item><item><title>数字花园来历</title><link>https://www.ryken.cloud/%E6%88%91%E7%9A%84%E6%95%B0%E5%AD%97%E8%8A%B1%E5%9B%AD%E6%9D%A5%E5%8E%86/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E6%88%91%E7%9A%84%E6%95%B0%E5%AD%97%E8%8A%B1%E5%9B%AD%E6%9D%A5%E5%8E%86/</guid><description>仅为个人看法，不喜勿喷，谢谢！！！若有侵犯到你，纯属偶然，请联系我删除。
看了这篇 《语雀困住了多少人》有感，来讲讲我和语雀的交集。
之前我一直使用的笔记软件是OneNote，它的功能非常强大，一块画布可以无限放大，支持图片、文件、绘图、录音等各种内容的插入。但是同步和共享方面存在一些问题，速度也比较慢。后来了解到了语雀，并逐步将笔记增量记录到语雀上(不得不说语雀的知识库管理还是可以的)。直到2022年10月份左右，语雀推出了一个付费计划。当笔记数量超过100篇时就需要收费。当时有很多用户的笔记数量已经超过了这个数字，也不得不说语雀这波调整吃相难看。过了一段时间，语雀重新调整了收费标准，普通用户一个月可以创建100篇文章，知识库上限是10篇，且不能公开共享知识库。刚开始会通过一些活动免费赠送3个月或6个月的会员资格，等用户逐渐接受后开始正常收费来购买会员了。
语雀个人定价调整的致歉 语雀个人版新定价的细则和思考 不过在他第一次调整收费标准的时候，我就已经下定决心换用其他的软件了，因为我之前不知道从哪里了解到语雀会开源，但是语雀的行动告诉我他要收费了，这个落差有点大。⊙_⊙ 算了算了
确实公司也是要吃饭的，但是我还是喜欢白嫖，如于是乎就开始找一些容错率高、方便迁移、方便共享、风格类似的笔记软件以及发布平台。
其实我一直想搭建一个属于自己的笔记库，而不是博客那种形式。相较于博客检索不太方便，我更倾向于使用笔记库或数字花园来记录和管理笔记，因为它采用正反链的关系图、发散的方式进行管理。这种关系图更能符合我当初记录笔记时的初衷。并且在发布很久之后回头查看，可以很快地找到当初的那种感觉。另外笔记库也可以使用文件夹的方式来管理文档(类似归档)，使用 tag 进行分类。
对于数字花园，你可以去以下链接中了解更多信息：</description></item><item><title>日志</title><link>https://www.ryken.cloud/%E6%97%A5%E5%BF%97/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E6%97%A5%E5%BF%97/</guid><description>calico 日志 calico 主要运行组件为：calico-node 以及 calico-kube-controller-manager
calico-node 主要有 felix、bird、cni 对于 kube-controller-manager 日志没有特殊配置 node 实例的日志： kubectl logs -n kube-system calico-node-xxxx</description></item><item><title>未命名</title><link>https://www.ryken.cloud/mactap/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/mactap/</guid><description>mactap 和 macvlan 相似的技术还有一种是 mactap。和 macvlan 不同的是，mactap 收到包之后不是交给协议栈，而是交给一个 tapX 文件，然后通过这个文件，完成和用户态的直接通信。</description></item><item><title>测试环境搭建</title><link>https://www.ryken.cloud/%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</guid><description>ps：路由器可以使用 vxnet-xxx 并分配 172.30.10.6/24，同时配置 vpc 端口转发到 ssh 端口，在配置好 ssh 之后，可以方便操作
使用自管网络以及 vpc 网络按照以上的网络架构连接好。之后开始下面的操作：
通过配置 vpc 端口转发，将公网的不同端口转发到各个节点的 ssh 端口，并添加到安全组 配置节点的第二张网卡 ip，此时使用 dhcp 是无法正常获取到 ip 的，因此需要配置为静态 ip。 ubuntu 配置文件如下：cat /etc/network/interfaces 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # interfaces(5) file used by ifup(8) and ifdown(8) # Include files from /etc/network/interfaces.</description></item><item><title>物理网络架构</title><link>https://www.ryken.cloud/%E7%89%A9%E7%90%86%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E7%89%A9%E7%90%86%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/</guid><description>针对 L2/L3 的一些讨论
传统的数据中心网络结构 传统的数据中心网络结构是三层的，一般包括接入交换机、汇聚交换机和核心交换机。
核心层 核心层主要设备是核心交换机，可采用双核心交换机备份部署方式，核心交换机采用模块化框式交换机，配备双电源、双引擎及支持热插拔功能。
汇聚层 汇聚层千兆光交换机，每栋楼宇部署千兆汇聚交换机，进行高密度接入、高性能汇聚，采用双汇聚备份设计，汇聚交换机与核心侧交换机与采用双链路保障，实现网络完全链接。
接入层 前端设备通过IP网络接入楼宇弱电机房进行汇聚。
在这架构下又分为L3架构和大2层架构，区别就在于L2/L3的分隔层次。
L3架构 当L2/L3隔离在汇聚交换机时，是L3架构，每对汇聚交换机构成一个L2的广播域，跨汇聚层的流量需要通过核心交换机路由转发完成。
好处：
在一个L2的广播域中，有效的限制了BUM（Broadcase，Unknown Unicast，Multicast），如风暴等问题。 缺点： 由于L2广播域范围的限制，不利于服务的任意部署。如果要发生位置迁移，也就会导致相应二层网络的变化，包括网关等配置变化。 在业务流量上，主要适应于南北向流量的转发，对于横向流量，特别是跨2层流量，服务器之间无直接路由交换的路径，需要经历接入-汇聚-核心-汇聚-接入，共5层的转发，所以无论是带宽还是延时性都不会有很好的支持。 大2层网络架构 将L2/3向上移动一层，也就是在核心交换机的位置做分离，这也就是我们的大2层网络架构。</description></item><item><title>监控文档</title><link>https://www.ryken.cloud/%E7%9B%91%E6%8E%A7%E6%96%87%E6%A1%A3/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E7%9B%91%E6%8E%A7%E6%96%87%E6%A1%A3/</guid><description>calicoctl node 作用： calicoctl node run：运行 calico-node 镜像 calicoctl node status： calico-node 的一些状态信息 calicoctl node diags：为 Calico 节点收集诊断包 calicoctl node checksystem：检测该节点能否运行 calico-node 缺陷： 只能获取本节点的信息</description></item><item><title>端口关系</title><link>https://www.ryken.cloud/%E7%AB%AF%E5%8F%A3%E5%85%B3%E7%B3%BB/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E7%AB%AF%E5%8F%A3%E5%85%B3%E7%B3%BB/</guid><description> type=NodePort和nodePort=30001的两个属性表明此Service开启了NodePort方式的外网访问模式。</description></item><item><title>网络隔离的最小配置</title><link>https://www.ryken.cloud/%E7%BD%91%E7%BB%9C%E9%9A%94%E7%A6%BB%E7%9A%84%E6%9C%80%E5%B0%8F%E9%85%8D%E7%BD%AE/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E7%BD%91%E7%BB%9C%E9%9A%94%E7%A6%BB%E7%9A%84%E6%9C%80%E5%B0%8F%E9%85%8D%E7%BD%AE/</guid><description>客户的疑问：(项目下的网络隔离)
网络隔离的最小配置 1.这里的网络隔离是针对Pod的吗？ 2.网络隔离的最小配置是什么？ ①如果只通过ingress暴露服务，最小配置是什么？ ②如果只通过LB类型的Service，最小配置？ ③如果只通过NodePort类型的Service，最小配置？ ④上述最小配置后，哪些是可以访问的，哪些是不可访问的，有没有一个表格（类似数据库隔离级别那样的） ⑤上述暴露方式的流量的具体链路是什么样的，必须包含但不限于以下概念，SLB，Node节点，网关，Ingress，Service，Pod，有没有示意图片。
ks 中网络策略的实现思路 先介绍一下 ks 中网络策略的实现思路： kubesphere 对于 networkpolicy 的实现中主要包含： 集群网络策略管理：主要提供一个原生的 networkpolicy 资源的管理，当 ks 租户网络隔离无法满足用户的全部需求时，可以在此通过 yaml 管理原生的 network policy</description></item><item><title>语雀导出文档小工具</title><link>https://www.ryken.cloud/%E8%AF%AD%E9%9B%80%E5%AF%BC%E5%87%BA%E5%B0%8F%E5%B7%A5%E5%85%B7/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E8%AF%AD%E9%9B%80%E5%AF%BC%E5%87%BA%E5%B0%8F%E5%B7%A5%E5%85%B7/</guid><description>语雀导出文档小工具 功能： 模拟用户浏览器操作一篇一篇导出 markdown 文档 支持将同名的文档导出 支持导出失败重试 我的知识库与导出文件目录 说明： 这是一个基于puppeteer 来模拟用户在浏览器的操作一篇一篇的导出语雀文档的工具。 关于语雀的导出可以详情说明见官方的文档： 如何导入导出知识库
首先语雀支持导出文档为 markdown 格式。 单篇导出：支持导出为 markdown、word、pdf、lakebook等 批量导出：支持导出为 lakebook、pdf 格式。对于超级用户是可以通过创建 token 来使用 官方的 exporter 工具或者其他基于 api 的工具进行批量导出；超级用户的价格为 299/月。</description></item><item><title>问题排查</title><link>https://www.ryken.cloud/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</link><pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</guid><description>[[iptables 查看流向]]
在裸金属环境中搭建时，设置默认模式为 underlay，安装完成 kubernetes 后，coredns 一直 not ready，抓包后发现一直
将 local-pv 调度到本机后抓包，可以正常运行 再次定位问题 当容器使用主机网络时，且使用 iptables 作为kube-proxy 转发时，通过 svc 访问会收到 reset 包</description></item><item><title/><link>https://www.ryken.cloud/%E5%B7%A5%E5%85%B7%E5%88%97%E8%A1%A8/</link><pubDate>Tue, 15 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%B7%A5%E5%85%B7%E5%88%97%E8%A1%A8/</guid><description>#tool #linux #network
工具包 [[网络工具包]] ebpf 相关 [[ebpf 排查工具]] iptables 相关 [[iptables 转发]] conntrack/netstats/ss/lsof [[Network/Tools/conntrack]] 网卡多队列、中断绑定 [[网卡多队列 + 中断绑定]]</description></item><item><title>conntrack</title><link>https://www.ryken.cloud/conntrack/</link><pubDate>Tue, 15 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/conntrack/</guid><description>conntrack 状态
1 2 3 4 5 CT_NEW, CT_ESTABLISHED, CT_REPLY, CT_RELATED, CT_REOPENED, conntrack map 五元组 sip:sport-dip:dport-协议 -</description></item><item><title>kube-proxy</title><link>https://www.ryken.cloud/kube-proxy/</link><pubDate>Thu, 10 Oct 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/kube-proxy/</guid><description>使用模式：ipvs or iptables or nftables
切换方式
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 ~#: kubectl -n kube-system edit cm kube-proxy apiVersion: v1 data: config.</description></item><item><title/><link>https://www.ryken.cloud/sctp/</link><pubDate>Fri, 30 Aug 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/sctp/</guid><description>SCTP（流控制传输协议）是用于应用程序之间通信的传输层协议。它与 TCP 类似，但它提供了额外的功能，例如多宿主和消息分段。需要可靠、有序的数据传输，同时还需要能够同时处理多个数据流的应用程序可以使用 SCTP。 SCTP 主要由服务提供商和移动运营商使用。 使用 SCTP 的应用程序示例包括：
4G 和 5G 移动网络中的信令传输 VoIP（IP 语音） 系统中的 SIP（​​会话发起协议）信令 虽然 Kubernetes 1.</description></item><item><title>host-firewall</title><link>https://www.ryken.cloud/host-firewall/</link><pubDate>Fri, 30 Aug 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/host-firewall/</guid><description>自成立以来，Cilium 一直支持 Kubernetes 网络策略，以在 L3/L4 上强制执行进出 pod 的流量控制。 但 Cilium 网络策略甚至更进一步：通过利用 eBPF，它可以提供对数据包的更大可见性并在 L7 上实施流量策略，并且可以根据 FQDN、协议（例如 kafka、grpc）等标准过滤流量&amp;hellip;&amp;hellip;</description></item><item><title>todo</title><link>https://www.ryken.cloud/todo/</link><pubDate>Wed, 07 Aug 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/todo/</guid><description>1. 编译 ebpf - 调试 遇到的问题&amp;amp;解决 问题： make build 编译各个二进制，编译 bpf 会报错，相关类型转换的错误 同时运行 daemon cilium-agent 失败，无法编译 bpf 程序
1 error: implicit conversion loses integer precision: &amp;#39;const __u64&amp;#39; (aka &amp;#39;const unsigned long long&amp;#39;) to &amp;#39;__u32&amp;#39; (aka &amp;#39;unsigned int&amp;#39;) [-Werror,-Wshorten-64-to-32]， 去掉编译中的参数 -Werror 后，编译成功，使用 tc filter add 到网卡上时提示：</description></item><item><title>1. ebpf map 类型</title><link>https://www.ryken.cloud/1.-ebpf-map-%E7%B1%BB%E5%9E%8B/</link><pubDate>Tue, 06 Aug 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/1.-ebpf-map-%E7%B1%BB%E5%9E%8B/</guid><description>内核目前支持 30 来种 BPF map 类型。v5.10 内核版本所有的 bpf map 类型如下：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 // https://github.</description></item><item><title>cilium 安装使用</title><link>https://www.ryken.cloud/cilium-%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/</link><pubDate>Wed, 31 Jul 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/cilium-%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/</guid><description>工具 cilium client
1 2 3 4 5 6 7 CILIUM_CLI_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt) CLI_ARCH=amd64 if [ &amp;#34;$(uname -m)&amp;#34; = &amp;#34;aarch64&amp;#34; ]; then CLI_ARCH=arm64; fi curl -L --fail --remote-name-all https://github.</description></item><item><title>git sync</title><link>https://www.ryken.cloud/git-sync/</link><pubDate>Wed, 24 Jul 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/git-sync/</guid><description>由于新的需求在仓库(upstream)新建了一个分支new，然而我fork的origin(远程个人仓库，非电脑中的本地仓库)中没有这个分支，我需要在new分支上进行开发并与upstream追踪，如何将新分支new插入origin中了，步骤如下: 1：创建并切换到新的上游分支的本地版本 git checkout -b new upstream/new； 2：将新的分支推送到个人远程仓库 git push -u origin new,-u跟踪指定的远程；
同步其他提交
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 git remote add upstream https://github.</description></item><item><title>cnitool</title><link>https://www.ryken.cloud/cnitool/</link><pubDate>Tue, 23 Jul 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/cnitool/</guid><description>官方文档链接：
https://www.cni.dev/docs/cnitool/ https://github.com/containernetworking/cni/tree/main/cnitool cnitool 是一个执行cni 配置的简易程序，可以在已经创建的网络命名空间内添加、删除 interface
环境变量 NETCONFPATH：配置文件路径目录，默认为 /etc/cni/net.d。cnitool 在给定目录中搜索扩展名为 *.conf 或 *.json 的 CNI 配置文件。它加载此目录中的所有 CNI 配置文件，如果找到具有给 cnitool 的网络名称的 CNI 配置，则返回相应的 CNI 配置，否则返回 nil CNI_PATH：检索 cni 可执行文件路径 安装 1 2 go get github.</description></item><item><title>cni-chaining mode</title><link>https://www.ryken.cloud/cni-chaining-mode/</link><pubDate>Mon, 22 Jul 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/cni-chaining-mode/</guid><description>How to Use Cilium Hubble for Observability in CNI Chaining Mode https://isovalent.com/blog/post/cilium-hubble-observability-cni-chaining-mode/
Kube-OVN 文档中也有类似的集成： https://kube-ovn.readthedocs.io/zh-cn/latest/advance/with-cilium/ https://kube-ovn.readthedocs.io/zh-cn/latest/advance/cilium-hubble-observe/
Cilium 自身 Monitoring &amp;amp; Metrics https://docs.</description></item><item><title>cilium-operator 分析</title><link>https://www.ryken.cloud/cilium-operator-%E5%88%86%E6%9E%90/</link><pubDate>Tue, 16 Jul 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/cilium-operator-%E5%88%86%E6%9E%90/</guid><description>组件的功能： crd 注册 ipam lb-ipam kv 操作 Identity 垃圾回收 ciliumEndpoint 垃圾回收 衍生的网络策略创建 ingress、gateway api 支持 相互认证支持 CRD 注册 CiliumBGPAdvertisement CiliumBGPClusterConfig CiliumBGPNodeConfig CiliumBGPNodeConfigOverride CiliumBGPPeerConfig CiliumBGPPeeringPolicy IPAM 相关的 crd &amp;ndash;set enableCiliumEndpointSlice=true</description></item><item><title>CiliumCIDRGroup</title><link>https://www.ryken.cloud/NetworkPolicy-CiliumCIDRGroup/</link><pubDate>Tue, 16 Jul 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/NetworkPolicy-CiliumCIDRGroup/</guid><description>https://github.com/cilium/cilium/pull/24638
CiliumCIDRGroup 是外部 CIDR 的列表（即选择集群外部对等点的 CIDR），可以作为 CiliumNetworkPolicies 中的单个实体引用。</description></item><item><title>ciliumpodippool</title><link>https://www.ryken.cloud/IPAM-ciliumpodippool/</link><pubDate>Tue, 16 Jul 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/IPAM-ciliumpodippool/</guid><description>如何启用由 CiliumPodIPPool CRD 支持的多池 IPAM
https://docs.cilium.io/en/stable/network/bgp-control-plane/#ciliumpodippool-announcements https://docs.cilium.io/en/stable/network/kubernetes/ipam-multi-pool/#validate-installation https://docs.cilium.io/en/stable/network/concepts/ipam/multi-pool/#ipam-crd-multi-pool</description></item><item><title>ClusterMesh - ciliumexternalworkloads</title><link>https://www.ryken.cloud/ClusterMesh-ciliumexternalworkloads/</link><pubDate>Tue, 16 Jul 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/ClusterMesh-ciliumexternalworkloads/</guid><description>要允许外部工作负载加入已经创建好的集群，必须向集群通报每个此类工作负载。通过为每个外部工作负载创建 CiliumExternalWorkload (CEW) 资源来完成。
CEW 资源指定工作负载的名称和身份标签（包括命名空间）。该名称必须是外部工作负载的主机名。
https://docs.cilium.io/en/stable/network/external-workloads/</description></item><item><title>IPAM - Ciliumendpoints</title><link>https://www.ryken.cloud/IPAM-ciliumendpoints/</link><pubDate>Tue, 16 Jul 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/IPAM-ciliumendpoints/</guid><description>CiliumEndpoint 对象由 cilium-agent 为集群中的每个 Pod 创建。</description></item><item><title>IPAM - ciliumendpointslice</title><link>https://www.ryken.cloud/IPAM-ciliumendpointslice/</link><pubDate>Tue, 16 Jul 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/IPAM-ciliumendpointslice/</guid><description>CiliumEndpoint 的扩展。支持对集群中的 CiliumEndpoint (CEP) 对象进行批处理，以实现更好的可扩展性。
启用后，Cilium operator 会监视 CEP 对象并将其分组/批量精简版本放入 CES 对象中。 Cilium agent 在此模式下监视 CES 对象以了解远程端点。在这种情况下，应减少由于远程端点信息传播而导致的 API 服务器压力，从而实现更好的可扩展性，但代价是在整个集群中识别新端点的身份之前可能会出现更长的延迟。</description></item><item><title>IPAM - ciliumnodeconfigs</title><link>https://www.ryken.cloud/IPAM-ciliumnodeconfigs/</link><pubDate>Tue, 16 Jul 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/IPAM-ciliumnodeconfigs/</guid><description>CiliumNodeConfig 对象允许覆盖 ConfigMap / Agent 参数。
它由一组字段和一个 labelSelector 组成。labelSelector 定义配置适用于哪些节点。空的 LabelSelector 会选择所有节点。
创建或修改 CiliumNodeConfig 不会导致更改生效，需要删除 Pod 并重新创建。</description></item><item><title>LBIPAM -</title><link>https://www.ryken.cloud/LBIPAM-CiliumL2AnnouncementPolicy/</link><pubDate>Tue, 16 Jul 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/LBIPAM-CiliumL2AnnouncementPolicy/</guid><description>https://docs.cilium.io/en/stable/network/l2-announcements/#l2-announcements</description></item><item><title>LBIPAM - Ciliumloadbalancerippools</title><link>https://www.ryken.cloud/LBIPAM-Ciliumloadbalancerippools/</link><pubDate>Tue, 16 Jul 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/LBIPAM-Ciliumloadbalancerippools/</guid><description>支持 Loadbalancer 类型的 service，同时使用 CiliumL2Announcement 或者 bgp 进行宣告 service ip。
https://docs.cilium.io/en/stable/network/lb-ipam/</description></item><item><title>NetworkPolicy - CiliumNetworkPolicies</title><link>https://www.ryken.cloud/NetworkPolicy-CiliumNetworkPolicies/</link><pubDate>Tue, 16 Jul 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/NetworkPolicy-CiliumNetworkPolicies/</guid><description>CiliumNetworkPolicy 与标准 NetworkPolicy 非常相似。目的是提供 NetworkPolicy 尚不支持的功能。
https://docs.cilium.io/en/stable/network/kubernetes/policy/#ciliumnetworkpolicy</description></item><item><title>Security - CiliumIdentity</title><link>https://www.ryken.cloud/Security-CiliumIdentity/</link><pubDate>Tue, 16 Jul 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Security-CiliumIdentity/</guid><description>CRD 身份分配使用 Kubernetes 自定义资源 CiliumIdentity 来表示安全身份。
Security identities是从标签生成的。值为 uint32 即 1 ~ 2^32 - 1，0 不是有效值。
Security identities 用于以下用途：
Cluster-local ClusterMesh CIDR-based policies remote nodes (optional) 1 2 3 4 5 6 0x00000001 - 0x000000FF (1 to 2^8 - 1 ) =&amp;gt; reserved identities 0x00000100 - 0x0000FFFF (2^8 to 2^16 - 1 ) =&amp;gt; cluster-local identities 0x00010000 - 0x00FFFFFF (2^16 to 2^24 - 1 ) =&amp;gt; identities for remote clusters 0x01000000 - 0x01FFFFFF (2^24 to 2^25 - 1 ) =&amp;gt; identities for CIDRs (node-local) 0x02000000 - 0x02FFFFFF (2^25 to 2^25 + 2^24 - 1) =&amp;gt; identities for remote nodes (local) 0x01010000 - 0xFFFFFFFF (2^25 + 2^24 to 2^32 - 1 ) =&amp;gt; reserved for future use https://docs.</description></item><item><title>配置 - 动态配置 cilium</title><link>https://www.ryken.cloud/%E9%85%8D%E7%BD%AE-%E5%8A%A8%E6%80%81%E9%85%8D%E7%BD%AE-cilium/</link><pubDate>Tue, 16 Jul 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E9%85%8D%E7%BD%AE-%E5%8A%A8%E6%80%81%E9%85%8D%E7%BD%AE-cilium/</guid><description>https://docs.cilium.io/en/stable/helm-reference/#helm-reference
上述为 cilium 安装时，helm 可配置的 values 值，这些 helm values 最终会转换为 cilium agent 和 cilium operator 等组件的配置并存储在 configmap 中
你可以运行 kubectl -n kube-system get configmap cilium-config -o yaml 来查看具体的配置。</description></item><item><title>bash</title><link>https://www.ryken.cloud/bash/</link><pubDate>Tue, 09 Jul 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/bash/</guid><description>1 2 3 4 5 6 7 8 9 10 11 # 1. 安装 zsh apt-get -y install zsh # 2.</description></item><item><title>其他相关</title><link>https://www.ryken.cloud/%E5%85%B6%E4%BB%96%E7%9B%B8%E5%85%B3/</link><pubDate>Tue, 09 Jul 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%85%B6%E4%BB%96%E7%9B%B8%E5%85%B3/</guid><description>cilium 相关网卡
lxcxxxxx - 总长为 8 ??? - 之前的 cilium ？ 拥有 cilium_ 前缀 tc maps : /sys/fs/bpf/tc/globals cilium map 名称包含 cilium_； tunnel map 名称 cilium_tunnel_map</description></item><item><title>kube-proxy 替换</title><link>https://www.ryken.cloud/kube-proxy-%E6%9B%BF%E6%8D%A2/</link><pubDate>Tue, 02 Jul 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/kube-proxy-%E6%9B%BF%E6%8D%A2/</guid><description>将 ipvs 规则放入了 ebpf 数据面，转发过程可以通过 ebpf 来完成，但是还是需要有 kube-proxy 组件存在
1 2 3 4 5 6 7 8 curl -sfL https://get.</description></item><item><title>组件+实现原理</title><link>https://www.ryken.cloud/%E7%BB%84%E4%BB%B6+%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</link><pubDate>Tue, 02 Jul 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E7%BB%84%E4%BB%B6+%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</guid><description>loxilb 起初是一个旨在简化边缘云原生/Kubernetes工作负载部署的项目。当我们在 AWS/GCP 等公共云中部署服务时，这些服务变得容易被外界访问或导出。公共云提供商通常默认会为这些服务分配负载均衡器实例，以确保一切运行顺畅。
然而，对于本地和边缘部署，默认情况下并没有提供外部负载均衡器类型的服务。长期以来，源自谷歌的 MetalLB 是唯一的选择。但边缘服务完全是另一回事，因为存在许多不同的协议，如 GTP、SCTP、SRv6 等，将所有这些集成到一个无缝工作的解决方案中一直非常困难。
loxilb 开发团队接到了许多希望解决此问题的人的请求。解决问题的第一步显而易见：虽然 Linux 内核提供的网络堆栈非常稳固，但在快速支持各种协议和状态负载均衡的多种组合方面，开发过程的敏捷性却显得不足。我们的搜索引导我们发现了由 Linux 社区开发的优秀技术——eBPF。将新功能引入操作系统内核作为安全沙箱程序的灵活性完全符合我们的设计理念。它也不需要任何专用的 CPU 核心，非常适合设计节能的边缘架构。
loxilb 是什么 loxilb 是一个基于 GoLang/eBPF 的开源云原生负载均衡器，旨在实现跨本地、公有云或混合 K8s 环境的广泛兼容性。</description></item><item><title>部署在集群内</title><link>https://www.ryken.cloud/%E9%83%A8%E7%BD%B2%E5%9C%A8%E9%9B%86%E7%BE%A4%E5%86%85/</link><pubDate>Fri, 28 Jun 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E9%83%A8%E7%BD%B2%E5%9C%A8%E9%9B%86%E7%BE%A4%E5%86%85/</guid><description>&amp;ndash;kubelet-arg=&amp;ldquo;cgroup-driver=systemd&amp;rdquo;
1 2 3 4 5 6 7 curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC=&amp;#34;server --write-kubeconfig ~/.kube/config --disable traefik --disable servicelb --disable-cloud-controller --kube-proxy-arg metrics-bind-address=0.</description></item><item><title>流量转发路径</title><link>https://www.ryken.cloud/%E6%B5%81%E9%87%8F%E8%BD%AC%E5%8F%91%E8%B7%AF%E5%BE%84/</link><pubDate>Wed, 26 Jun 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E6%B5%81%E9%87%8F%E8%BD%AC%E5%8F%91%E8%B7%AF%E5%BE%84/</guid><description/></item><item><title>部署在集群外</title><link>https://www.ryken.cloud/%E9%83%A8%E7%BD%B2%E5%9C%A8%E9%9B%86%E7%BE%A4%E5%A4%96/</link><pubDate>Wed, 26 Jun 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E9%83%A8%E7%BD%B2%E5%9C%A8%E9%9B%86%E7%BE%A4%E5%A4%96/</guid><description>前置条件 节点多网卡；默认路由网卡 eth0 用于安装集群；额外 eth1 用于运行 macvlan 部署 架构图 loxilb 作为 docker 运行，并将使用 macvlan 来处理传入流量。
节点实际网卡 eth1 ip 为：172.</description></item><item><title>3. cni 容器网络处理过程</title><link>https://www.ryken.cloud/3.-cni-%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B/</link><pubDate>Mon, 24 Jun 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/3.-cni-%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B/</guid><description>cni 配置文件 cat /etc/cni/net.d/00-multus.conf
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 {&amp;#34;cniVersion&amp;#34;: &amp;#34;0.</description></item><item><title>ipvlan</title><link>https://www.ryken.cloud/ipvlan/</link><pubDate>Mon, 24 Jun 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/ipvlan/</guid><description>介绍 允许你在同一物理设备上创建多个虚拟网络接口，这些接口可以共享同一个 MAC 地址。
当本地交换机对它可管理的 MAC 地址的总数施加约束时，IPVLAN 是一个很好的选择。
ipvlan 三种模式 L2 L3 L3s L2 模式 在 IPVLAN L2 模式 中，虚拟设备接收并响应地址解析协议(ARP)请求。netfilter 框架仅在拥有虚拟设备的容器中运行。容器化流量的默认命名空间中不会执行 netfilter 链。使用L2 模式会提供良好的性能，但对网络流量的控制要小。</description></item><item><title>IPAM</title><link>https://www.ryken.cloud/5.-IPAM-%E5%8E%9F%E7%90%86/</link><pubDate>Fri, 21 Jun 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/5.-IPAM-%E5%8E%9F%E7%90%86/</guid><description>IPAM Underlay 网络和 Overlay 网络的 IPAM 云原生网络中出现了两种技术类别：&amp;ldquo;Overlay 网络方案&amp;rdquo; 和 &amp;ldquo;Underlay 网络方案&amp;rdquo;。 云原生网络对于它们没有严格的定义，我们可以从很多 CNI 项目的实现原理中，简单抽象出这两种技术流派的特点，它们可以满足不同场景下的需求。
Spiderpool 是为 Underlay 网络特点而设计，以下对两种方案进行比较，能够更好说明 Spiderpool 的特点和使用场景。</description></item><item><title>kube-proxy strictARP</title><link>https://www.ryken.cloud/kube-proxy-strictARP/</link><pubDate>Thu, 20 Jun 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/kube-proxy-strictARP/</guid><description>ipvs 模式下的 strictARP 作用于下面两个 arp 参数：[[arp 相关内核参数]]
net/ipv4/conf/all/arp_ignore net/ipv4/conf/all/arp_announce</description></item><item><title>ringbuffer 对带宽的影响</title><link>https://www.ryken.cloud/ringbuffer-%E5%AF%B9%E5%B8%A6%E5%AE%BD%E7%9A%84%E5%BD%B1%E5%93%8D/</link><pubDate>Thu, 20 Jun 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/ringbuffer-%E5%AF%B9%E5%B8%A6%E5%AE%BD%E7%9A%84%E5%BD%B1%E5%93%8D/</guid><description>ringbuffer是网卡收发报文的缓冲区。ring的意思就是环形，数据往环里可以不停写入，如果到了头，就会再写一圈，把老的数据覆盖了。
报文到达这个缓冲区后，如果没有及时被cpu处理，就会积累，超过buffer大小后，就会覆盖之前的数据，导致丢包。
ringbuffer越大越不容易写满，丢包概率就越低，但是cpu处理到报文的响应时间就越长，所以网络延时就会变高。
理解ringbuffer的作用，可以类比到机场的行李传送带。这个传送带是个环， 其中一边有行李被不断送到传送带上，另一边有很多旅客把行李取走。当传送带不够长，并且旅客少的时候，就会出现新的行李没地方放，只能把老行李扔了，腾出位置放新行李，这就是丢包的情况。
把传送带加长可以缓解丢行李的问题，带来的问题是旅客要等待更多时间才能取到行李，这就是网络延时会变高的原因。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 root@pekt3dr01n08:~# ethtool -g enp66s0f0 Ring parameters for enp66s0f0: Pre-set maximums: RX: 8192 RX Mini: 0 RX Jumbo: 0 TX: 8192 Current hardware settings: RX: 1024 RX Mini: 0 RX Jumbo: 0 TX: 1024 root@pekt3dr01n07:~# iperf -c pekt3dr01n08 -i 1 -t 3 -P 1 ------------------------------------------------------------ Client connecting to pekt3dr01n08, TCP port 5001 TCP window size: 85.</description></item><item><title>rust 项目上手</title><link>https://www.ryken.cloud/rust-%E9%A1%B9%E7%9B%AE%E4%B8%8A%E6%89%8B/</link><pubDate>Thu, 20 Jun 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/rust-%E9%A1%B9%E7%9B%AE%E4%B8%8A%E6%89%8B/</guid><description>openelb 修改为 rust 语言 kube-rs/controller-rs: A kubernetes reference controller (github.com) kube-rs/kube: Rust Kubernetes client and controller runtime (github.</description></item><item><title>1. Kubernetes DNS</title><link>https://www.ryken.cloud/1.-Kubernetes-DNS/</link><pubDate>Wed, 19 Jun 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/1.-Kubernetes-DNS/</guid><description>Kubernetes DNS 规范 Records for a Service with ClusterIP A/AAAA records  kubernetes.default.svc.cluster.local. 4 IN A 10.3.0.1 kubernetes.default.svc.cluster.local. 4 IN AAAA 2001:db8::1 SRV records  未命名的端口没有 SRV 记录</description></item><item><title>coredns 使用</title><link>https://www.ryken.cloud/5.-CoreDNS-%E4%BD%BF%E7%94%A8/</link><pubDate>Wed, 19 Jun 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/5.-CoreDNS-%E4%BD%BF%E7%94%A8/</guid><description>文档链接： Customizing DNS Service | Kubernetes</description></item><item><title>Calico over IP fabrics</title><link>https://www.ryken.cloud/Calico-over-IP-fabrics/</link><pubDate>Tue, 18 Jun 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Calico-over-IP-fabrics/</guid><description>官方文档链接：
Calico over IP fabrics | Calico Documentation 三种模型 The AS Per Rack model 每个 TOR 交换机（及其附属计算服务器）都是一个独特的自治系统 (AS)，并且它们通过叶/主干架构中的主干交换机提供的以太网交换平面或通过一组互连骨干交换机，每个骨干交换机也是一个唯一的AS。</description></item><item><title>其他资料-工具</title><link>https://www.ryken.cloud/%E5%85%B6%E4%BB%96%E8%B5%84%E6%96%99-%E5%B7%A5%E5%85%B7/</link><pubDate>Tue, 18 Jun 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%85%B6%E4%BB%96%E8%B5%84%E6%96%99-%E5%B7%A5%E5%85%B7/</guid><description> xdp-project/xdp-tools: Utilities and example programs for use with XDP</description></item><item><title>容易导致丢包的内核配置项</title><link>https://www.ryken.cloud/%E5%AE%B9%E6%98%93%E5%AF%BC%E8%87%B4%E4%B8%A2%E5%8C%85%E7%9A%84%E5%86%85%E6%A0%B8%E9%85%8D%E7%BD%AE%E9%A1%B9/</link><pubDate>Tue, 18 Jun 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%AE%B9%E6%98%93%E5%AF%BC%E8%87%B4%E4%B8%A2%E5%8C%85%E7%9A%84%E5%86%85%E6%A0%B8%E9%85%8D%E7%BD%AE%E9%A1%B9/</guid><description> [[arp proxy | arp_ignore]] &amp;mdash;- [[arp 相关内核参数]] [[rp_filter 问题 | rp_filter]]</description></item><item><title>常见问题</title><link>https://www.ryken.cloud/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</link><pubDate>Tue, 18 Jun 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</guid><description>部署之后网络不通 检查Calico IPPool网段是否与节点网段重叠 检查rp_filter, arp_ignore等参数是否配置正确 执行下iptables -t filter -F 查看是否是防火墙影响 检查是否iptables FORWARD默认规则是否是ACCEPT 检查IAAS是否放开安全组， 是否支持IPIP（azure就不支持IPIP） 部署之后Calico Node启动失败 检查是否节点配置多个网卡， 如果是那么修改IP_AUTODETECTION_METHOD https://docs.</description></item><item><title>网络数据路径</title><link>https://www.ryken.cloud/%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E8%B7%AF%E5%BE%84/</link><pubDate>Tue, 18 Jun 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E8%B7%AF%E5%BE%84/</guid><description>Cilium学习笔记
Cilium用到的钩子包括：
钩子 说明 XDP 网络路径上最早的、可以软件介入的点，在驱动接收到封包之后，具有最好的封包处理性能</description></item><item><title>2. XDP 介绍</title><link>https://www.ryken.cloud/2.-XDP-%E4%BB%8B%E7%BB%8D/</link><pubDate>Thu, 16 May 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/2.-XDP-%E4%BB%8B%E7%BB%8D/</guid><description>XDP - eXpress Data Path XDP 传入参数：
XDP暴露的钩子具有特定的输入上下文，它是单一输入参数。它的类型为 struct xdp_md，在内核头文件 bpf.h 中定义，具体字段如下所示：
1 2 3 4 5 6 7 8 9 10 struct xdp_md { __u32 data; __u32 data_end; __u32 data_meta; /* Below access go through struct xdp_rxq_info */ __u32 ingress_ifindex; /* rxq-&amp;gt;dev-&amp;gt;ifindex */ __u32 rx_queue_index; /* rxq-&amp;gt;queue_index */ __u32 egress_ifindex; /* txq-&amp;gt;dev-&amp;gt;ifindex */ }; data 和 data_end 字段分别是数据包开始和结束的指针，它们是用来获取和解析传来的数据 data_meta指针，初始阶段它是一个空闲的内存地址，供XDP程序与其他层交换数据包元数据时使用。 最后两个字段分别是接收数据包的接口和对应的RX队列的索引。当访问这两个值时，BPF代码会在内核内部重写，以访问实际持有这些值的内核结构struct xdp_rxq_info。 XDP action 类型：</description></item><item><title>5. 开发自己的 ebpf</title><link>https://www.ryken.cloud/5.-%E5%BC%80%E5%8F%91%E8%87%AA%E5%B7%B1%E7%9A%84-ebpf/</link><pubDate>Thu, 16 May 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/5.-%E5%BC%80%E5%8F%91%E8%87%AA%E5%B7%B1%E7%9A%84-ebpf/</guid><description>开发 ebpf 需要的工具链 apt install libelf-dev gcc-multilib clang llvm
bcc BCC全称为BPF Compiler Collection，该项目是一个python库， 包含了完整的编写、编译、和加载BPF程序的工具链，以及用于调试和诊断性能问题的工具。
项目地址： https://github.com/iovisor/bcc
libbpf 如果使用 libbpf 库来进行加载，需要我们再额外编写一部分用户空间代码，这和开发其它类型的 eBPF 程序的流程是相同的。</description></item><item><title>4. XDP、TC 比较</title><link>https://www.ryken.cloud/4.-XDPTC-%E6%AF%94%E8%BE%83/</link><pubDate>Mon, 13 May 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/4.-XDPTC-%E6%AF%94%E8%BE%83/</guid><description>这两个钩子都可以用于相同的应用场景，如DDoS缓解、隧道、处理链路层信息等。但是，由于XDP在任何套接字缓冲区（SKB）分配之前运行，所以它可以达到比TC上的程序更高的吞吐量值。然而，后者可以从通过 struct __sk_buff 提供的额外的解析数据中受益，并且可以执行 BPF 程序，对入站流量和出站流量都可以执行 BPF 程序，是 TX 链路上的能被操控的最一层。</description></item><item><title>bpftool 使用</title><link>https://www.ryken.cloud/bpftool-%E4%BD%BF%E7%94%A8/</link><pubDate>Mon, 13 May 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/bpftool-%E4%BD%BF%E7%94%A8/</guid><description>bcc/bpftrace/bpftool
其他 可以通过llvm-objdump这个工具来分析下这个可执行文件的反汇编指令信息：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 llvm-objdump -S xdp-drop.</description></item><item><title>使用 ebpf 的项目</title><link>https://www.ryken.cloud/%E4%BD%BF%E7%94%A8-ebpf-%E7%9A%84%E9%A1%B9%E7%9B%AE/</link><pubDate>Fri, 10 May 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E4%BD%BF%E7%94%A8-ebpf-%E7%9A%84%E9%A1%B9%E7%9B%AE/</guid><description>eBPF Applications Landscape
基础设施库：
https://github.com/libbpf/libbpf-rs https://github.com/aya-rs/aya kubernetes-sigs/blixt: Layer 4 Kubernetes load-balancer (github.com)</description></item><item><title>使用 libebpf</title><link>https://www.ryken.cloud/%E4%BD%BF%E7%94%A8-libebpf/</link><pubDate>Fri, 10 May 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E4%BD%BF%E7%94%A8-libebpf/</guid><description/></item><item><title>调试 BPF 程序</title><link>https://www.ryken.cloud/%E8%B0%83%E8%AF%95-BPF-%E7%A8%8B%E5%BA%8F/</link><pubDate>Wed, 08 May 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E8%B0%83%E8%AF%95-BPF-%E7%A8%8B%E5%BA%8F/</guid><description>I use these three methods:
bpf_printk - so far works best bpftool - to dump map entries bpfmon( https://github.com/CrowdStrike/bpfmon-example) - to get notifications when map entries are updated.</description></item><item><title/><link>https://www.ryken.cloud/felix-%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B/</link><pubDate>Tue, 07 May 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/felix-%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B/</guid><description>#calico-felix #calico-ebpf
入口处：felix/dataplane/linux/int_dataplane.go 的 NewIntDataplaneDriver() 函数，进行dataplane的初始化 首先会判断是否开启了BPF，如果是开启状态，则进行以下操作： 1）注册 map manager，该manager的作用是负责管理ebpf的map（map用于userspace和kernel之间进行数据的共享） 2）注册endpoint manager，该manager的作用是负责各种ep的管理，包括host、workload等 3）创建各种map，比如nat的frontendMap、backendMap、routeMap、conntrackMap等 4）开启kube-proxy，注意此kube-proxy并非kubernetes的kube-proxy，而是proxy的一个封装，负责和kubernetes通信，维护各种map中的信息 5）若BPFConnTimeEnabled开启，则安装connect_time_loadbalancer，即加载相关的eBPF程序 6）启动dataplane（这部分暂不涉及connect_time_loadbalancer，本文暂不分析）
calico 全部的组件以及其进程树详见：[[CloudNative/cni-network/calico/组件分析/组件]] felix 组件 [[felix]]</description></item><item><title>conntrack 疑难杂症</title><link>https://www.ryken.cloud/conntrack-%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/</link><pubDate>Tue, 07 May 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/conntrack-%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/</guid><description>dmesg -T 内核日志 conntrack -L # List conntrack or expectation table conntrack -S # Show statistics 网卡统计包 ip -s link show eth0 ethtool -S eth0 ifconfig eth0 cat /proc/net/netstat 连接太多导致 conntrack table 被打爆 现象 业务层（应用层）现象 存在随机、偶发的 ==新建连接== 超时（connect timeout）。 例如，如果业务用的是 Java，那对应的是 jdbc4.</description></item><item><title>容器网络疑难排查案例</title><link>https://www.ryken.cloud/%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E7%96%91%E9%9A%BE%E6%8E%92%E6%9F%A5%E6%A1%88%E4%BE%8B/</link><pubDate>Mon, 06 May 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E7%96%91%E9%9A%BE%E6%8E%92%E6%9F%A5%E6%A1%88%E4%BE%8B/</guid><description>问题一：calico特定场景下的网络性能问题 iptraf-ng命令观察网卡流量 ip linkx show devname sysctl -a查询网卡相关的系统参数 ethool查询网卡配置 ethtool -K vxlan.calico tx on修改参数 结论： calico默认关掉了 checksum 这个配置项 checksum和offload是关联的配置项，真正影响我们测试性能的应该是offload这个配置，添加以下环境变量后恢复</description></item><item><title>以systemd启动</title><link>https://www.ryken.cloud/%E4%BB%A5systemd%E5%90%AF%E5%8A%A8/</link><pubDate>Fri, 19 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E4%BB%A5systemd%E5%90%AF%E5%8A%A8/</guid><description>以 ubuntu 22.04 为例 首先正常安装 calico，并确保其运行状态正常
安装 runit/bird/ipset 1 apt-get install runit runit-systemd ipset -y 修改相关配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 1.</description></item><item><title/><link>https://www.ryken.cloud/Calico-Full-Mesh-BGP-%E6%8A%A5%E6%96%87/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Calico-Full-Mesh-BGP-%E6%8A%A5%E6%96%87/</guid><description>#bgp #calico-bgp
集群环境 节点 ip 地址 角色 node1 172.30.10.2 master+worker node2 172.</description></item><item><title/><link>https://www.ryken.cloud/calico-iperf/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/calico-iperf/</guid><description>calico 内部 node - node pod - pod （自身） pod - node（同） pod - node iperf3工具每100ms发一轮报文，每次在2、3ms内瞬间发完，iperf工具则均匀的发送报文，接口限速使用 iperf3 作为测试工具需要调整令牌桶参数以达到最佳效果。</description></item><item><title/><link>https://www.ryken.cloud/Calico-TOR-BGP-%E6%8A%A5%E6%96%87/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Calico-TOR-BGP-%E6%8A%A5%E6%96%87/</guid><description>#bgp #calico-bgp #calico
集群环境 节点 ip 地址 角色 node1 10.1.5.11 master+worker node2 10.</description></item><item><title/><link>https://www.ryken.cloud/calico-%E8%BF%90%E8%90%A5%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/calico-%E8%BF%90%E8%90%A5%E9%97%AE%E9%A2%98/</guid><description>#calico #issue
配置etcd calico 支持两种数据存储，一种是使用 kubernetes api 接口来对其 etcd 进行读写操作；一种直接连接 etcd 进行读写操作，同时 calico 支持配置 etcd tls 进行数据加密实现安全的存储，对于 etcd 相关的证书生成以及更新维护不在 calico 管理范围之内。 docs/generate-self-signed-certificates.</description></item><item><title/><link>https://www.ryken.cloud/felix/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/felix/</guid><description>felix 主要的工作组件：syncer, CalcGraph, dataplane
Syncer 协程负责监听 datastore 中的更新，并将更新的内容通过 channel 发送给 Validator 协程。Validator 完成校验后，将其发送给 Calc graph 协程。Calc graph 完成计算后，发送给dataplane协程。最后dataplane完成数据平面处理。 syncer, calicoctl 可以直接向 datastore 增删改查一系列 Resource。syncer 同步且监听这些Resource，当资源变动时，通过回调onUpdate 通知下游组件（比如CalcGraph）。 CalcGraph, syncer 传递的 datastore 数据通常不能直接使用，需要CalcGraph 做一些计算和归并再交给dataplane dataplane 负责对 node 做出处理。 dataplane 分为本地和远程两种形态，如果是本地运行，则通过channel 直接传输 proto model，如果是dataplane 远程独立运行，则执行grpc 调用； github.</description></item><item><title/><link>https://www.ryken.cloud/%E5%85%89%E5%A4%A7-calico-bgp-%E6%96%AD%E8%81%94%E5%8E%9F%E5%9B%A0/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%85%89%E5%A4%A7-calico-bgp-%E6%96%AD%E8%81%94%E5%8E%9F%E5%9B%A0/</guid><description>背景 + 分析 行内在进行 http 短连接性能测试时，calico 意外重启，而 calico 重启导致了节点与交换机 bgp 断连，触发行内交换机监控告警。 重启时查看之前容器日志发现并没有明显的错误日志，查看系统日志发现同一时间段 kubelet 探针超时失败，并且也有其他 pod 发生重启的日志。 由于是针对与网络的测试，所有分析并提出以下解决方案： 排查路由数量 对于路由聚合
交换机侧：先讨论交换机上可行性，但因为两会期间，行内封网无法进行交换机配置的改动，没有进行尝试 bird 配置：临时修改了 calico bird 配置（进入 docker merge 读写层修改 bird 配置文件，并手动创建/删除 ippool，让 confd 重新刷新配置并生效，注意重启 calico 后，bird 配置会复原），让其只导入集群相关的路由，将路由数量由5600多减少到 100 左右。 减少路由后测试，calico 仍然会触发重启，排除路由数量的因素。</description></item><item><title/><link>https://www.ryken.cloud/%E5%86%85%E6%A0%B8%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%86%85%E6%A0%B8%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0/</guid><description/></item><item><title/><link>https://www.ryken.cloud/%E7%BB%84%E4%BB%B6/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E7%BB%84%E4%BB%B6/</guid><description>calico-node calico-controller
健康检查
ready live calico-node 容器以runit 作为进程管理工具，运行多个进程
进程树 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 Jul28 ?</description></item><item><title/><link>https://www.ryken.cloud/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/</guid><description>#calico #calico-config
confd /etc/calico/conf/config
修改 mtu kubectl edit configmap/calico-config -n kube-system
问题：
能否修改 confd 的配置，实现修改 calico bird 参数的目的</description></item><item><title>1. 所有权</title><link>https://www.ryken.cloud/1.-%E6%89%80%E6%9C%89%E6%9D%83/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/1.-%E6%89%80%E6%9C%89%E6%9D%83/</guid><description>所有权 所有运行的程序都必须管理其使用计算机内存的方式。
一些语言中具有垃圾回收机制，在程序运行时不断地寻找不再使用的内存； 一些语言中，程序员必须亲自分配和释放内存。 Rust 则选择通过所有权系统管理内存（编译器在编译时会根据一系列的规则进行检查。在运行时，所有权系统的任何功能都不会减慢程序） 跟踪哪部分代码正在使用堆上的哪些数据，最大限度的减少堆上的重复数据的数量，以及清理堆上不再使用的数据确保不会耗尽空间，这些问题正是所有权系统要处理的。所有权的存在就是为了管理堆数据。
所有权让 rust 无需垃圾回收即可保障内存安全。
所有权规则
Rust 中的每一个值都有一个被称为其 所有者（owner）的变量。 值有且只有一个所有者。 当所有者（变量）离开作用域，这个值将被丢弃。 Rust 内存回收策略：内存在拥有它的变量离开作用域后就被自动释放。当变量离开作用域，Rust 为我们调用一个特殊的 drop函数，释放内存。</description></item><item><title>1.性能测试无法满足期望 - reuse</title><link>https://www.ryken.cloud/1.%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%97%A0%E6%B3%95%E6%BB%A1%E8%B6%B3%E6%9C%9F%E6%9C%9B-reuse/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/1.%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%97%A0%E6%B3%95%E6%BB%A1%E8%B6%B3%E6%9C%9F%E6%9C%9B-reuse/</guid><description>在高并发、短连接的场景下，kube-proxy ipvs存在rs删除失败或是延迟高的问题，社区也有不少Issue反馈，比如 kube-proxy ipvs conn_reuse_mode setting causes errors with high load from single client。文本对这些问题进行了梳理，试图介绍产生这些问题的内部原因。由于能力有限，其中涉及内核部分，只能浅尝辄止。
背景 端口重用 一切问题来源于端口重用。在TCP四次挥手中有个TIME_WAIT的状态，作为先发送FIN包的一端，在接收到对端发送的FIN包后进入TIME_WAIT，在经过2MSL后才会真正关闭连接。TIME_WAIT状态的存在，一来可以避免将之前连接的延迟报文，作为当前连接的报文处理；二是可以处理最后一个ACK丢失带来的问题。
而在短连接、高并发的场景下，会出现大量的TIME-WAIT连接，导致资源无法及时释放。Linux中内核参数net.ipv4.tcp_tw_reuse提供了一种减少TIME-WAIT连接的方式，可以将TIME-WAIT连接的端口分配给新的TCP连接，来复用端口。
1 2 3 4 5 tcp_tw_reuse - BOOLEAN Allow to reuse TIME-WAIT sockets for new connections when it is safe from protocol viewpoint.</description></item><item><title>2. kube-proxy 跨 vlan 访问</title><link>https://www.ryken.cloud/2.-kube-proxy-%E8%B7%A8-vlan-%E8%AE%BF%E9%97%AE/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/2.-kube-proxy-%E8%B7%A8-vlan-%E8%AE%BF%E9%97%AE/</guid><description>背景 使用 hybridnet 搭建的 vlan 环境在测试 svc 的连通性的时候发现了一个很疑惑的问题 实际搭建的环境如下： node22、node23、node24 三个节点均在 vlan 50；划分了 vlan53 和 vlan73 网络域后，会在 node22、node23 上创建相应的子接口。 位于node22、node23 上的 pod 在访问分布在 node24 的 pod 暴露的 svc 时，报错：</description></item><item><title>2. 引用与借用</title><link>https://www.ryken.cloud/2.-%E5%BC%95%E7%94%A8%E4%B8%8E%E5%80%9F%E7%94%A8/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/2.-%E5%BC%95%E7%94%A8%E4%B8%8E%E5%80%9F%E7%94%A8/</guid><description>不可变引用 calculate_length 函数，它以一个对象的引用作为参数而不是获取值的所有权
1 2 3 4 5 6 7 8 9 fn main(){lets1=String::from(&amp;#34;hello&amp;#34;);letlen=calculate_length(&amp;amp;s1);println!(&amp;#34;The length of &amp;#39;{}&amp;#39; is {}.&amp;#34;,s1,len);}fn calculate_length(s: &amp;amp;String)-&amp;gt; usize {s.</description></item><item><title>3. slice 类型</title><link>https://www.ryken.cloud/3.-slice-%E7%B1%BB%E5%9E%8B/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/3.-slice-%E7%B1%BB%E5%9E%8B/</guid><description>slice 允许你引用集合中一段连续的元素序列，而不用引用整个集合。slice 没有所有权
引出问题 题目：编写一个函数，该函数接收一个字符串，并返回在该字符串中找到的第一个单词。如果函数在该字符串中并未找到空格，则整个字符串就是一个单词，所以应该返回整个字符串。
将 string 转换为字节数组，返回字节索引值 1 2 3 4 5 6 7 8 9 10 fn first_word(s: &amp;amp;String)-&amp;gt; usize {letbytes=s.</description></item><item><title>calico ipam 过程</title><link>https://www.ryken.cloud/calico-ipam-%E8%BF%87%E7%A8%8B/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/calico-ipam-%E8%BF%87%E7%A8%8B/</guid><description>calico ipam 相关 CRD 资源 资源名 介绍 ippool 用于 ipam 分配的 ip 池 ipamblock block 中 ip 分配信息等 blockaffinities 由 ippool 分割的细粒度的 ip 块以及 block 与节点的亲和性绑定关系 ipamconfigs 用于配置 ipam 相关参数 ipamhandles 用于保存 pod 与 block 关系 ippool 表示 IP 地址的集合，Calico 从中分配 IP给 pod。 示例 yaml：</description></item><item><title>calico ipip 和 bgp 共存</title><link>https://www.ryken.cloud/calico-ipip-%E5%92%8C-bgp-%E5%85%B1%E5%AD%98/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/calico-ipip-%E5%92%8C-bgp-%E5%85%B1%E5%AD%98/</guid><description>calico 常用的有三种模式：ipip、vxlan 和 bgp，前两者属于 overlay 封装，无需关心底层网络；而 bgp 是 underlay 模式，如果集群外部的交换机和 calico 建立了 bgp 连接，calico bgp 会将集群内部的路由宣告出去，此时就需要关注底层网络、注意不要出现 ip 冲突的问题。
讨论集群内容器网络的封装 calico ippool 中通过以下两个字段来决定：该 ippool 所定义的网段以什么样的模式来封装。</description></item><item><title>calico 安装</title><link>https://www.ryken.cloud/calico-%E5%AE%89%E8%A3%85/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/calico-%E5%AE%89%E8%A3%85/</guid><description>manifests 安装 upgrade-ipam 用于升级 Calico CNI 插件的 IPAM 管理模块，以支持更高效和灵活的 IP 地址池的管理。 install-cni 安装 calico-cni 到指定目录 flexvol-driver 容器存储接口（CSI）驱动程序 在每个pod中运行的Felix和Dikastes容器之间启用安全连接。它挂载了一个共享卷，Felix将Unix域套接字插入其中 Dikastes是一个容器，它与Calico的Felix组件一起运行，用于在每个pod中实现应用层策略。它通过与Felix共享的Unix域套接字与Felix进行通信，以便在Envoy代理中执行Calico安全策略 https://www.</description></item><item><title>calico 网络策略</title><link>https://www.ryken.cloud/calico-%E7%BD%91%E7%BB%9C%E7%AD%96%E7%95%A5/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/calico-%E7%BD%91%E7%BB%9C%E7%AD%96%E7%95%A5/</guid><description>Kubernetes NetworkPolicy： [[networkPolicy - 网络策略]] namespace 级别的网络策略 网络策略应用于 labelSelector 选取出的 pod 网络策略可以指定允许从哪些 pods 来、到哪些 pods 去、namespace 或者 cidr 的流量 网络策略可以指定协议(TCP/UDP/SCTP)，并指定特定的端口 Calico NetworkPolicy 扩展了 kubernetes networkpolicy</description></item><item><title>calico 运营文档</title><link>https://www.ryken.cloud/calico-%E8%BF%90%E8%90%A5%E6%96%87%E6%A1%A3/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/calico-%E8%BF%90%E8%90%A5%E6%96%87%E6%A1%A3/</guid><description>新增 or 扩容 ippool 固定 ip ns 与 subnet 绑定 calico 限速 calico 的 tunnel 地址会自动分配 迁移 ippool 的容量准备 blockSize 应该如何取值 kubesphere 集成了cni 的 ippool 和 网络策略，ks 在 cni 基础之上封装了一层，用于屏蔽不同 cni 底层实现的，现阶段版本中底层中主要使用了 calico。</description></item><item><title>calico配置文件</title><link>https://www.ryken.cloud/calico%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/calico%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/</guid><description>cni 配置文件 1 kubectl get cm -n kube-system calico-config -o yaml 在安装 calico 时，configmap 中的特定参数会替换为 calico 定义的值，同时该 configmap 也会在 calico-daemonset 的 init 容器初始化时，被拷贝到 /etc/cni/net.</description></item><item><title>ipvs 相关的内核参数</title><link>https://www.ryken.cloud/ipvs-%E7%9B%B8%E5%85%B3%E7%9A%84%E5%86%85%E6%A0%B8%E5%8F%82%E6%95%B0/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/ipvs-%E7%9B%B8%E5%85%B3%E7%9A%84%E5%86%85%E6%A0%B8%E5%8F%82%E6%95%B0/</guid><description>ipvs 相关内核文档：
IPvs-sysctl — The Linux Kernel documentation 1. 参数 am_droprate 1 2 3 am_droprate - INTEGER default 10 It sets the always mode drop rate, which is used in the mode 3 of the drop_rate defense.</description></item><item><title>kubekey install k8s</title><link>https://www.ryken.cloud/kubekey-install-k8s/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/kubekey-install-k8s/</guid><description>下载 kubekey
1 2 export KKZONE=cn curl -sfL https://get-kk.kubesphere.io | VERSION=v2.3.0 sh - 生成配置文件
1 2 3 4 5 6 7 8 .</description></item><item><title>Service NodePort</title><link>https://www.ryken.cloud/Service-NodePort/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Service-NodePort/</guid><description>kubernetes version state v1.20 alpha v1.22 beta, the feature gate feature switch needs to be turned on at the same time v1.</description></item><item><title>typha 的测试方案</title><link>https://www.ryken.cloud/typha-%E7%9A%84%E6%B5%8B%E8%AF%95%E6%96%B9%E6%A1%88-old/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/typha-%E7%9A%84%E6%B5%8B%E8%AF%95%E6%96%B9%E6%A1%88-old/</guid><description>Typha 引入前后性能对比测试方案： 测试目标： 对比引入 Typha 前后 Calico 在大规模 Kubernetes 集群中的性能表现，特别强调 Typha 引入后解决的问题，即减少每个节点对数据存储的直接访问以增加规模。
测试环境： 大型 Kubernetes 集群 Calico 未使用 Typha 的情况（基准测试） Calico 使用 Typha 的情况 测试方案： 基准测试（未启用 Typha）：</description></item><item><title>typha 的测试方案</title><link>https://www.ryken.cloud/typha-%E7%9A%84%E6%B5%8B%E8%AF%95%E6%96%B9%E6%A1%88/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/typha-%E7%9A%84%E6%B5%8B%E8%AF%95%E6%96%B9%E6%A1%88/</guid><description>Typha 引入前后性能对比测试方案： 测试目标： 对比引入 Typha 前后 Calico 在大规模 Kubernetes 集群中的性能表现，特别强调 Typha 引入后解决的问题，即减少每个节点对数据存储的直接访问以增加规模。
测试环境： 大型 Kubernetes 集群 Calico 未使用 Typha 的情况 Calico 使用 Typha 的情况 测试方案： 开启 kubernetes 审计。 记录引入 Typha 前后，calico 访问 kubernetes 次数，同时记录 kubernetes apiserver 负载情况 测试步骤： 开启 kubernetes 审计 定义审计规则 1 2 3 4 5 6 apiVersion:audit.</description></item><item><title>typha 组件</title><link>https://www.ryken.cloud/typha-%E7%BB%84%E4%BB%B6/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/typha-%E7%BB%84%E4%BB%B6/</guid><description>主要任务： 通过减少每个节点对数据存储的影响来增加规模。 作为数据存储和 Felix 实例之间的守护进程运行。默认安装，但未配置。 Typha 代表所有客户端（例如 Felix 和 confd）维护单个数据存储连接。它缓存数据存储状态并删除重复事件，以便将它们分散到许多侦听器。由于一个 Typha 实例可以支持数百个 Felix 实例，因此它大大减少了数据存储上的负载。而且由于 Typha 可以过滤掉与 Felix 无关的更新，因此也降低了 Felix 的 CPU 使用率。在大规模（100+节点）Kubernetes集群中，这是至关重要的，因为API服务器生成的更新数量随着节点数量的增加而变化。</description></item><item><title>多网卡节点缺少路由</title><link>https://www.ryken.cloud/%E5%A4%9A%E7%BD%91%E5%8D%A1%E8%8A%82%E7%82%B9%E7%BC%BA%E5%B0%91%E8%B7%AF%E7%94%B1/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%A4%9A%E7%BD%91%E5%8D%A1%E8%8A%82%E7%82%B9%E7%BC%BA%E5%B0%91%E8%B7%AF%E7%94%B1/</guid><description>背景 多节点集群中 10.168.50.60 和 10.168.50.61 节点上的 pod 访问不通，且没有相关的路由；同样的在节点 10.168.50.60 上没有 calico 相关的路由，该节点路由情况如下： 正常节点路由如下： 且所有节点为多网卡： 排查解决 bgp 连接 节点上没有路由，多半是 bgp 出现了问题，查看各个节点的 bgp 状态之后发现，确实有一部分 bgp 没有建立连接，一直卡在 passive、passive on 状态。而该状态是为了避免节点间同时向对方连接导致的路由抖动，采用一方被动一方主动方式。</description></item><item><title>根据系统日志排查</title><link>https://www.ryken.cloud/%E6%A0%B9%E6%8D%AE%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%BF%97%E6%8E%92%E6%9F%A5/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E6%A0%B9%E6%8D%AE%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%BF%97%E6%8E%92%E6%9F%A5/</guid><description>calico 意外重启 位于 master2 的 calico-node 在 3d2h 前意外重启，现在使用 kubectl logs查看日志为现运行时的日志，没有参考价值。可以在日志组件中检索对应 pod且在对应时间段的日志；另外可以通过 kubectl logs -p xxx 获取到重启前的日志
本次排查在日志没有明显的报错，之后查看系统日志（注意系统日志默认保留时间为 7 天）</description></item><item><title>网络工具诊断</title><link>https://www.ryken.cloud/%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7%E8%AF%8A%E6%96%AD/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7%E8%AF%8A%E6%96%AD/</guid><description>定位问题 出现问题时先定位是哪一部分发生了问题，dns 解析、kube-proxy、cni、底层网络 [[网络排查]]
在 pod 内通过 service name 进行访问其他业务服务时，出现访问不了的问题的排查思路
排查 dns 进入容器中使用 ping 或者 nslookup 查看域名解析是否正常，如果解析需要排查 DNS组件，有关 DNS 调试参考 调试 DNS 问题 | Kubernetes；如果解析正常进一步检查2</description></item><item><title>通过事件、日志排查</title><link>https://www.ryken.cloud/%E9%80%9A%E8%BF%87%E4%BA%8B%E4%BB%B6%E6%97%A5%E5%BF%97%E6%8E%92%E6%9F%A5/</link><pubDate>Mon, 15 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E9%80%9A%E8%BF%87%E4%BA%8B%E4%BB%B6%E6%97%A5%E5%BF%97%E6%8E%92%E6%9F%A5/</guid><description>BIRD is not ready: 输入命令：kubectl describe pods calico-node-xxx -n kube-system
1 2 3 4 5 6 7 8 9 10 Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 36m default-scheduler Successfully assigned kube-system/calico-node-xxx to worker1 Normal Pulled 36m kubelet Container image &amp;#34;calico/node:v3.</description></item><item><title>配置 git 拉取</title><link>https://www.ryken.cloud/%E9%85%8D%E7%BD%AE-git-%E6%8B%89%E5%8F%96/</link><pubDate>Fri, 12 Apr 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E9%85%8D%E7%BD%AE-git-%E6%8B%89%E5%8F%96/</guid><description>拷贝 ssh 密钥信息到远程开发机上 chmod 600 ~/.ssh/id_rsa* 配置 git 邮箱、用户名、git拉取 git config --global --edit
1 2 3 4 5 6 [user]name = renyunkangemail = rykren1998@gmail.</description></item><item><title>git submodule</title><link>https://www.ryken.cloud/git-submodule/</link><pubDate>Tue, 05 Mar 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/git-submodule/</guid><description>下载了项目之后初始化子模块 git submodule update &amp;ndash;init &amp;ndash;recursive 添加子模块 git submodule add url path git submodule add -b dev https://github.com/xx/xx content 删除子模块 删除 submodule 缓存 git rm &amp;ndash;cached submodule_name 删除文件 rm -rf content/ - 删除项目目录下.</description></item><item><title>calicoctl ipam 清理异常</title><link>https://www.ryken.cloud/calicoctl-ipam-%E6%B8%85%E7%90%86%E5%BC%82%E5%B8%B8/</link><pubDate>Thu, 29 Feb 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/calicoctl-ipam-%E6%B8%85%E7%90%86%E5%BC%82%E5%B8%B8/</guid><description>calicoctl datastore migrate lock calicoctl ipam check -o report.json calicoctl ipam release &amp;ndash;from-report report.json calicoctl datastore migrate unlock</description></item><item><title>rp_filter 问题</title><link>https://www.ryken.cloud/rp_filter-%E9%97%AE%E9%A2%98/</link><pubDate>Thu, 29 Feb 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/rp_filter-%E9%97%AE%E9%A2%98/</guid><description>背景 calico ipip模式的 pod 与 bgp 模式的 pod，无法正常通信；节点收到回包之后将包给丢弃了，在 ubuntu 20 上行不通，但是在 ubuntu 22 上可行，(先把两边的 sysctl -a 拿出来，做下 diff，在 net 区块部分能看出来有差异) net.</description></item><item><title>移动光标</title><link>https://www.ryken.cloud/shell-%E5%B8%B8%E7%94%A8/</link><pubDate>Sat, 27 Jan 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/shell-%E5%B8%B8%E7%94%A8/</guid><description>移动光标 ctrl+a**: 移到行首（a是首字母）**
ctrl+e**: 移到行尾（end）**
ctrl+b: 前移一个字符(backward)
ctrl+f: 后移一个字符(forward)
alt+b: 前移一个单词</description></item><item><title>升级</title><link>https://www.ryken.cloud/%E5%8D%87%E7%BA%A7/</link><pubDate>Fri, 26 Jan 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%8D%87%E7%BA%A7/</guid><description>3.26.1 - 客户端TLS握手可能会无限期阻止服务器，导致拒绝服务 3.26.3 3.26.4 3.27.0</description></item><item><title>公有云 - ccm</title><link>https://www.ryken.cloud/%E5%85%AC%E6%9C%89%E4%BA%91-ccm/</link><pubDate>Thu, 25 Jan 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%85%AC%E6%9C%89%E4%BA%91-ccm/</guid><description>https://cwiki.yunify.com/pages/viewpage.action?pageId=23659614&amp;src=contextnavpagetreemode
https://cwiki.yunify.com/pages/viewpage.action?pageId=96318071&amp;src=contextnavpagetreemode
yunify/qingcloud-cloud-controller-manager: A kubernetes cloud-controller-manager for the qingcloud (github.com)
yunify/qingcloud-cloud-controller-manager: A kubernetes cloud-controller-manager for the qingcloud (github.</description></item><item><title>dlv 调试core文件</title><link>https://www.ryken.cloud/dlv-%E8%B0%83%E8%AF%95core%E6%96%87%E4%BB%B6/</link><pubDate>Sun, 21 Jan 2024 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/dlv-%E8%B0%83%E8%AF%95core%E6%96%87%E4%BB%B6/</guid><description>linux环境下 生成core文件 设置环境变量 export GOTRACEBACK=crash 解除ulimit系统资源限制，允许生成core文件 有关GOTRACEBACK参考官网： https://pkg.go.dev/runtime?utm_source=godoc 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package main import ( &amp;#34;fmt&amp;#34; &amp;#34;time&amp;#34; ) func main() { waitchan := make(chan struct{}) go func() { for i := 0; i &amp;lt; 10; i++ { fmt.</description></item><item><title>未命名</title><link>https://www.ryken.cloud/Antrea/</link><pubDate>Tue, 05 Dec 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Antrea/</guid><description/></item><item><title>未命名</title><link>https://www.ryken.cloud/cilium-%E8%B7%A8%E9%9B%86%E7%BE%A4%E9%80%9A%E4%BF%A1/</link><pubDate>Tue, 05 Dec 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/cilium-%E8%B7%A8%E9%9B%86%E7%BE%A4%E9%80%9A%E4%BF%A1/</guid><description/></item><item><title>常用 cni 插件</title><link>https://www.ryken.cloud/%E5%B8%B8%E7%94%A8-cni-%E6%8F%92%E4%BB%B6/</link><pubDate>Tue, 28 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%B8%B8%E7%94%A8-cni-%E6%8F%92%E4%BB%B6/</guid><description> Flannel：Flannel 是最常用的 k8s 网络插件之一，它使用了虚拟网络技术来实现容器之间的通信，支持多种网络后端，如 VXLAN、UDP 和 Host-GW。 Calico：Calico 是一种基于 BGP 的网络插件，它使用路由表来路由容器之间的流量，支持多种网络拓扑结构，并提供了安全性和网络策略功能。 Canal：Canal 是一个组合了 Flannel 和 Calico 的网络插件，它使用 Flannel 来提供容器之间的通信，同时使用 Calico 来提供网络策略和安全性功能。 Weave Net：Weave Net 是一种轻量级的网络插件，它使用虚拟网络技术来为容器提供 IP 地址，并支持多种网络后端，如 VXLAN、UDP 和 TCP/IP，同时还提供了网络策略和安全性功能。 Cilium：Cilium 是一种基于 eBPF (Extended Berkeley Packet Filter) 技术的网络插件，它使用 Linux 内核的动态插件来提供网络功能，如路由、负载均衡、安全性和网络策略等。 Contiv：Contiv 是一种基于 SDN 技术的网络插件，它提供了多种网络功能，如虚拟网络、网络隔离、负载均衡和安全策略等。 Antrea：Antrea 是一种基于 OVS (Open vSwitch) 技术的网络插件，它提供了容器之间的通信、网络策略和安全性等功能，还支持多种网络拓扑结构。 openshift-sdn ovn-kubernetes kube-ovn</description></item><item><title>1. vector + map</title><link>https://www.ryken.cloud/1.-vector-+-map/</link><pubDate>Fri, 24 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/1.-vector-+-map/</guid><description>Vector 字符串 Map</description></item><item><title>iptables 转发 service 流量未命名</title><link>https://www.ryken.cloud/iptables-%E8%BD%AC%E5%8F%91-service-%E6%B5%81%E9%87%8F/</link><pubDate>Fri, 24 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/iptables-%E8%BD%AC%E5%8F%91-service-%E6%B5%81%E9%87%8F/</guid><description/></item><item><title>ipvs 转发 service 流量</title><link>https://www.ryken.cloud/ipvs-%E8%BD%AC%E5%8F%91-service-%E6%B5%81%E9%87%8F/</link><pubDate>Fri, 24 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/ipvs-%E8%BD%AC%E5%8F%91-service-%E6%B5%81%E9%87%8F/</guid><description>为什么引入了 ipvs 是否完全替代了 iptables 有哪些与 iptables 相关的配置参数 1 2 3 // Generate the masquerade mark to use for SNAT rules.</description></item><item><title>kube-proxy 处理</title><link>https://www.ryken.cloud/kube-proxy-%E5%A4%84%E7%90%86/</link><pubDate>Fri, 24 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/kube-proxy-%E5%A4%84%E7%90%86/</guid><description>user space iptables ipvs 目的： 将 service ip 转发到后端 pod ip 上 node -&amp;gt; svc ip -&amp;gt; pod ip</description></item><item><title>iptables 规则</title><link>https://www.ryken.cloud/iptables-%E8%A7%84%E5%88%99/</link><pubDate>Wed, 22 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/iptables-%E8%A7%84%E5%88%99/</guid><description>规则由匹配条件和处理动作组成。 匹配条件 匹配条件分为基本匹配条件与扩展匹配条件 基本匹配条件： 源地址Source IP，目标地址 Destination IP，可以作为基本匹配条件。 扩展匹配条件： 除了上述的条件可以用于匹配，还有很多其他的条件可以用于匹配，这些条件泛称为扩展条件，这些扩展条件其实也是netfilter中的一部分，只是以模块的形式存在，如果想要使用这些条件，则需要依赖对应的扩展模块。 源端口Source Port, 目标端口Destination Port，可以作为扩展匹配条件 处理动作 处理动作在iptables中被称为target（这样说并不准确，我们暂且这样称呼），动作也可以分为基本动作和扩展动作。 此处列出一些常用的动作
ACCEPT：允许数据包通过。 DROP：直接丢弃数据包，不给任何回应信息，这时候客户端会感觉自己的请求泥牛入海了，过了超时时间才会有反应。 REJECT：拒绝数据包通过，必要时会给数据发送端一个响应的信息，客户端刚请求就会收到拒绝的信息。 SNAT：源地址转换，解决内网用户用同一个公网地址上网的问题。 MASQUERADE：是SNAT的一种特殊形式，适用于动态的、临时会变的ip上。 DNAT：目标地址转换。 REDIRECT：在本机做端口映射。 LOG：在/var/log/messages文件中记录日志信息，然后将数据包传递给下一条规则，也就是说除了记录以外不对数据包做任何其他操作，仍然让下一条规则去匹配。 MARK：为匹配的数据包设置标记，可以用于后续规则的匹配和处理。 NOTRACK：排除匹配的数据包不被连接跟踪系统跟踪。 RETURN：返回到调用链的上一个规则，用于在子链中执行完特定操作后返回。</description></item><item><title>iptables 转发</title><link>https://www.ryken.cloud/iptables-%E8%BD%AC%E5%8F%91/</link><pubDate>Wed, 22 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/iptables-%E8%BD%AC%E5%8F%91/</guid><description>端口转发 将本机的8080端口转发至其他主机，主机IP：192.168.1.12，目标主机IP和端口：192.168.1.13:8088，规则如下
1 2 3 iptables -t nat -A PREROUTING -p tcp -m tcp --dport 8080 -j DNAT --to-destination 192.</description></item><item><title>runtime</title><link>https://www.ryken.cloud/runtime/</link><pubDate>Wed, 22 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/runtime/</guid><description>crio
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 1.</description></item><item><title>2. use 引入作用域</title><link>https://www.ryken.cloud/2.-use-%E5%BC%95%E5%85%A5%E4%BD%9C%E7%94%A8%E5%9F%9F/</link><pubDate>Tue, 21 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/2.-use-%E5%BC%95%E5%85%A5%E4%BD%9C%E7%94%A8%E5%9F%9F/</guid><description>使用 use 将路径引入作用域 1 2 3 4 5 6 7 8 9 10 11 12 13 mod front_of_house{pubmod hosting{pubfn add_to_waitlist(){}}}usefront_of_house::hosting;pubfn eat_at_restaurant(){hosting::add_to_waitlist();hosting::add_to_waitlist();hosting::add_to_waitlist();} 1 2 3 4 5 6 usestd::collections::HashMap;fn main(){letmutmap=HashMap::new();map.</description></item><item><title>本地仓库与远程仓库链接</title><link>https://www.ryken.cloud/%E6%9C%AC%E5%9C%B0%E4%BB%93%E5%BA%93%E4%B8%8E%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93%E9%93%BE%E6%8E%A5/</link><pubDate>Tue, 21 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E6%9C%AC%E5%9C%B0%E4%BB%93%E5%BA%93%E4%B8%8E%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93%E9%93%BE%E6%8E%A5/</guid><description>设置远程仓库地址 git remote add origin https://gitee.com/Stark-Gs/copter-4.0.7.git
拉取远程代码 git pull origin master &amp;ndash;allow-unrelated-histories
提交到远程仓库 git push origin master</description></item><item><title>1. 包+crate</title><link>https://www.ryken.cloud/1.-%E5%8C%85+crate/</link><pubDate>Tue, 14 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/1.-%E5%8C%85+crate/</guid><description>包 + Crate 包：提供一系列功能的一个或者多个 crate。一个包中会包含有一个 Cargo.toml 文件，用于阐述如何构建这些 crate。
crate：一个二进制项或者库。crate root 是一个源文件，Rust 编译器以它为起始点，并构成crate 的根模块
包和 crate 关系：
包中至多只能包含一个库 crate 包中可以包含任意多个二进制 crate。 包中至少包含一个 crate，无论是库的还是二进制的 1 2 3 4 5 6 7 ~#: cargo new hello_world ~#: tree hello_world/ hello_world/ ├── Cargo.</description></item><item><title>3. 拆分模块到不同文件中</title><link>https://www.ryken.cloud/3.-%E6%8B%86%E5%88%86%E6%A8%A1%E5%9D%97%E5%88%B0%E4%B8%8D%E5%90%8C%E6%96%87%E4%BB%B6%E4%B8%AD/</link><pubDate>Tue, 14 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/3.-%E6%8B%86%E5%88%86%E6%A8%A1%E5%9D%97%E5%88%B0%E4%B8%8D%E5%90%8C%E6%96%87%E4%BB%B6%E4%B8%AD/</guid><description>初文件： src/lib.rs
1 2 3 4 5 6 7 8 9 10 11 12 mod front_of_house{mod hosting{fn add_to_waitlist(){}fn seat_at_table(){}}mod serving{fn take_order(){}fn server_order(){}fn take_payment(){}}} 第一步拆分：src/lib.</description></item><item><title>6. 字符-string</title><link>https://www.ryken.cloud/6.-%E5%AD%97%E7%AC%A6-string/</link><pubDate>Tue, 14 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/6.-%E5%AD%97%E7%AC%A6-string/</guid><description>字符串字面值：字符串值被硬编码进程序里。字符串字面值是很方便的，不过他们并不适合使用文本的每一种场景。原因之一就是他们是不可变的 String 类型：被分配到堆上，所以能够存储在编译时未知大小的文本。
1 2 3 4 lets=&amp;#34;hello&amp;#34;;letmuts=String::from(&amp;#34;hello&amp;#34;);s.push_str(&amp;#34;, world!&amp;#34;);// push_str() 在字符串后追加字面值 println!(&amp;#34;{}&amp;#34;,s);// 将打印 `hello, world!` slice 允许你引用集合中一段连续的元素序列，而不用引用整个集合。slice 没有所有权 字符串字面值就是 slice，字符串字面值被储存在二进制文件中。 s 的类型是 &amp;amp;str：它是一个指向二进制程序特定位置的 slice。&amp;amp;str 是一个不可变引用。</description></item><item><title>4. 结构体</title><link>https://www.ryken.cloud/4.-%E7%BB%93%E6%9E%84%E4%BD%93/</link><pubDate>Wed, 08 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/4.-%E7%BB%93%E6%9E%84%E4%BD%93/</guid><description>定义结构体 和元组一样，结构体的每一部分可以是不同类型。但不同于元组，结构体需要命名各部分数据以便能清楚的表明其值的意义。有了名字，就不需要依赖顺序来指定或访问实例中的值。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 struct User{username: String,email: String,sign_in_count: u64,active: bool,}fn main(){lettup=(500,6.</description></item><item><title>5. 枚举与match</title><link>https://www.ryken.cloud/5.-%E6%9E%9A%E4%B8%BE%E4%B8%8Ematch/</link><pubDate>Wed, 08 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/5.-%E6%9E%9A%E4%B8%BE%E4%B8%8Ematch/</guid><description>枚举 1 2 3 4 5 6 7 enum IpAddrKind{V4,V6,}// 创建实例，位于其标识符的命名空间中，并使用两个冒号分开 letfour=IpAddrKind::V4;letsix=IpAddrKind::V6; 1. 将数据放进枚举成员
1 2 3 4 5 6 enum IpAddr{V4(String),V6(String),}lethome=IpAddr::V4(String::from(&amp;#34;127.</description></item><item><title>nodeIPAM 问题</title><link>https://www.ryken.cloud/nodeIPAM-%E9%97%AE%E9%A2%98/</link><pubDate>Wed, 08 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/nodeIPAM-%E9%97%AE%E9%A2%98/</guid><description> 对于 controller-manager 无法修改 cluster-cidr 即 podCIDR Can&amp;rsquo;t change kube-controller-manager cluster cidr · Issue #75461 · kubernetes/kubernetes (github.com)</description></item><item><title/><link>https://www.ryken.cloud/%E7%96%91%E9%97%AE/</link><pubDate>Fri, 03 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E7%96%91%E9%97%AE/</guid><description> 生命周期 - 结构体使用 &amp;amp;str 成员 trait 类单元结构体 - unit 类型</description></item><item><title>3. 函数</title><link>https://www.ryken.cloud/3.-%E5%87%BD%E6%95%B0/</link><pubDate>Thu, 02 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/3.-%E5%87%BD%E6%95%B0/</guid><description>在函数签名中，必须 声明每个参数的类型。返回值要在箭头（-&amp;gt;）后声明它的类型 使用 return 关键字和指定值，可从函数中提前返回；但大部分函数隐式的返回最后的表达式。
表达式：表达式会计算出一些值，表达式可以是语句的一部分。函数调用是一个表达式。宏调用是一个表达式。 语句：语句并不返回值。 1 2 3 4 5 6 7 8 9 10 11 12 fn main(){letx=plus_one(5);println!</description></item><item><title>1. helloworld</title><link>https://www.ryken.cloud/1.-helloworld/</link><pubDate>Wed, 01 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/1.-helloworld/</guid><description>HelloWorld 1 2 3 fn main(){println!(&amp;#34;Hello, world!&amp;#34;);} rust 是预编译静态类型语言，将编译和运行分为两个独立的步骤； rustc 编译源文件 rustfmt 的自动格式化代码工具 println! 调用了 Rust 宏；符号 !</description></item><item><title>1. 变量与可变性</title><link>https://www.ryken.cloud/1.-%E5%8F%98%E9%87%8F%E4%B8%8E%E5%8F%AF%E5%8F%98%E6%80%A7/</link><pubDate>Wed, 01 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/1.-%E5%8F%98%E9%87%8F%E4%B8%8E%E5%8F%AF%E5%8F%98%E6%80%A7/</guid><description>变量、基本类型、函数、注释和控制流
Rust 变量 Rust 变量不可变性的原因及方法，何时不使用不可变性
变量不可变的原因 在尝试改变预设为不可变的值时，产生编译时错误是很重要的，因为这种情况可能导致 bug。如果一部分代码假设一个值永远也不会改变，而另一部分代码改变了这个值，第一部分代码就有可能以不可预料的方式运行。不得不承认这种 bug 的起因难以跟踪，尤其是第二部分代码只是 有时 会改变值。
Rust 编译器保证，如果声明一个值不会变，它就真的不会变。这意味着当阅读和编写代码时，不需要追踪一个值如何和在哪可能会被改变，从而使得代码易于推导。
变量可变与不可变 变量默认是不可改变的，当变量不可变时，一旦值被绑定一个名称上，你就不能改变这个值。 但是仍然可以使用可变变量，变量名之前加 mut 来使其可变。除了允许改变值之外，mut 向读者表明了其他代码将会改变这个变量值的意图。 何时不使用不可变性 很多地方需要权衡取舍。 如使用大型数据结构时，适当地使用可变变量，可能比复制和返回新分配的实例更快。对于较小的数据结构，总是创建新实例，采用更偏向函数式的编程风格，可能会使代码更易理解，为可读性而牺牲性能或许是值得的。</description></item><item><title>2. 数据类型</title><link>https://www.ryken.cloud/2.-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</link><pubDate>Wed, 01 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/2.-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</guid><description>Rust 是 静态类型（statically typed）语言，即在编译时就必须知道所有变量的类型。根据值及其使用方式，编译器通常可以推断出我们想要用的类型。当多种类型均有可能时，必须增加类型注解。
1 letguess: u32 =&amp;#34;42&amp;#34;.parse().expect(&amp;#34;Not a number!&amp;#34;); 两类数据类型子集：标量（scalar）和复合（compound）
标量类型 整型 浮点型 布尔型 字符类型 整型 长度 有符号 无符号 8-bit i8 u8 16-bit i16 u16 32-bit i32 u32 64-bit i64 u64 128-bit i128 u128 arch isize usize isize 和 usize 类型依赖运行程序的计算机架构：64 位架构上它们是 64 位的， 32 位架构上它们是 32 位的。isize 或 usize 主要作为某些集合的索引。 Rust 数字类型默认是 i32：它通常是最快的，甚至在 64 位系统上也是。 整数溢出：</description></item><item><title>2. 猜数游戏</title><link>https://www.ryken.cloud/2.-%E7%8C%9C%E6%95%B0%E6%B8%B8%E6%88%8F/</link><pubDate>Wed, 01 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/2.-%E7%8C%9C%E6%95%B0%E6%B8%B8%E6%88%8F/</guid><description>读取标准输入的数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 usestd::io;/* 默认情况下，Rust 将 prelude 模块中少量的类型引入到每个程序的作用域中。 如果需要的类型不在 prelude 中，你必须使用 use 语句显式地将其引入作用域 */fn main(){letmutguess=String::new();/* 1.</description></item><item><title>rust 编码规范</title><link>https://www.ryken.cloud/rust-%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83/</link><pubDate>Wed, 01 Nov 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/rust-%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83/</guid><description>常量的命名规范：使用下划线分隔的大写字母单词，并且可以在数字字面值中插入下划线来提升可读性。
1 2 3 fn main(){constMAX_POINTS: u32 =100_000;} Rust 代码中的函数和变量名使用 snake case 规范风格。在 snake case 中，所有字母都是小写并使用下划线分隔单词。</description></item><item><title>Backblaze + Cloudflare + PicGo 图床搭建</title><link>https://www.ryken.cloud/Backblaze-+-Cloudflare-+-PicGo-%E5%9B%BE%E5%BA%8A%E6%90%AD%E5%BB%BA/</link><pubDate>Mon, 30 Oct 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Backblaze-+-Cloudflare-+-PicGo-%E5%9B%BE%E5%BA%8A%E6%90%AD%E5%BB%BA/</guid><description>目标实现自定义域名的图床
使用 Cloudflare + Backblaze B2+PicGo的搭建免费图床 使用PicGo+CF(Cloudflare)+B2(Backblaze)作为博客图床</description></item><item><title>问题1：paused deployment</title><link>https://www.ryken.cloud/%E9%97%AE%E9%A2%981paused-deployment/</link><pubDate>Mon, 30 Oct 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E9%97%AE%E9%A2%981paused-deployment/</guid><description>暂停已经发布的 deployment，此时针对 PodTemplateSpec 的更新不会触发新的上线，重启时也会报：can&amp;rsquo;t restart paused deployment (run rollout resume first)
1 2 kubectl rollout pause deployment busybox-deployment deployment.extensions/busybox-deployment paused 当 resume deploy 资源之后，便会恢复</description></item><item><title>ipvs strictARP 参数</title><link>https://www.ryken.cloud/ipvs-strictARP-%E5%8F%82%E6%95%B0/</link><pubDate>Tue, 24 Oct 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/ipvs-strictARP-%E5%8F%82%E6%95%B0/</guid><description>[[arp 相关内核参数]] 设置为 true 时
net/ipv4/conf/all/arp_ignore =&amp;gt; 1 net/ipv4/conf/all/arp_announce =&amp;gt; 2</description></item><item><title>升级 calico + calico bgp filter 配置</title><link>https://www.ryken.cloud/%E5%8D%87%E7%BA%A7-calico-+-calico-bgp-filter-%E9%85%8D%E7%BD%AE/</link><pubDate>Tue, 24 Oct 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%8D%87%E7%BA%A7-calico-+-calico-bgp-filter-%E9%85%8D%E7%BD%AE/</guid><description>升级 calico 官方文档： Upgrade Calico on Kubernetes | Calico Documentation (tigera.io)
对于 kk 安装的集群，默认使用 calico manifest 安装，因此依照官方文档的使用 manifest 的方案升级：  https://docs.</description></item><item><title>go 工作空间</title><link>https://www.ryken.cloud/go-%E5%B7%A5%E4%BD%9C%E7%A9%BA%E9%97%B4/</link><pubDate>Sat, 21 Oct 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/go-%E5%B7%A5%E4%BD%9C%E7%A9%BA%E9%97%B4/</guid><description>go work 工作空间正确的使用方式
初始化 go workspace go work init 使用项目 go work use [-r] [项目1 项目2 .</description></item><item><title>kube-proxy 原理</title><link>https://www.ryken.cloud/kube-proxy-%E5%8E%9F%E7%90%86/</link><pubDate>Sat, 21 Oct 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/kube-proxy-%E5%8E%9F%E7%90%86/</guid><description>kube-proxy 如何实现流量转发
1 2 3 root@node22:~# ps -elf | grep kube-proxy 4 S root 39828 39784 0 80 0 - 188257 futex_ 10:04 ?</description></item><item><title>hybridnet 测试方案</title><link>https://www.ryken.cloud/hybridnet-%E6%B5%8B%E8%AF%95%E6%96%B9%E6%A1%88/</link><pubDate>Tue, 17 Oct 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/hybridnet-%E6%B5%8B%E8%AF%95%E6%96%B9%E6%A1%88/</guid><description>需要验证网络插件的功能以及 kube-proxy 为 iptables 以及 ipvs 模式与网络插件的兼容性。
提前规划：
node cidr 集群可用的 vlan cidr 根据文档使用 kk 进行部署环境
kk 使用 hybridnet 插件安装集群 验证 ipvs 时，修改相应 kk 的配置：</description></item><item><title>自定义环境变量</title><link>https://www.ryken.cloud/%E8%87%AA%E5%AE%9A%E4%B9%89%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/</link><pubDate>Thu, 28 Sep 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E8%87%AA%E5%AE%9A%E4%B9%89%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/</guid><description>光大不想要 default-ipv4-ippool，他们想把所有的 ippool 命名都统一一下，现在有一个方法：可以通过设置 calico-node 跳过 default ippool 的创建
1 2 3 NO_DEFAULT_POOLS=&amp;#34;true&amp;#34;CALICO_IPV4POOL_CIDR=&amp;#34;&amp;#34;CALICO_IPV6POOL_CIDR=&amp;#34;&amp;#34; 通过设置可以修改默认 ippool 的 nodeSelector CALICO_IPV4POOL_NODE_SELECTOR</description></item><item><title>hybridnet 安装建议</title><link>https://www.ryken.cloud/hybridnet-%E5%AE%89%E8%A3%85%E5%BB%BA%E8%AE%AE/</link><pubDate>Wed, 27 Sep 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/hybridnet-%E5%AE%89%E8%A3%85%E5%BB%BA%E8%AE%AE/</guid><description>对于集群中不建议使用 10 11 21 22 的 vlan 网段，可以使用其他的 vlan，可以避免一些问题
假设 10.11.22.2 使用了 native vlan ww，hybridnet 会创建 22 子接口，导致无法与网关通信，无法创建负载 全部使用子接口 - 暂时没有问题</description></item><item><title>calico bandwidth 适配</title><link>https://www.ryken.cloud/calico-bandwidth-%E9%80%82%E9%85%8D/</link><pubDate>Wed, 13 Sep 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/calico-bandwidth-%E9%80%82%E9%85%8D/</guid><description>需求以及修改方式见：[[bandwidth 带宽限制]]
对于 bandwidth 编译之后，根据 [[github release]] 将编译生成的文件上传到 github release
重新编译 cni-plugin 镜像，将其中下载的 cni plugin 更换为自己维护的 cni 仓库 release 包</description></item><item><title>ipvs</title><link>https://www.ryken.cloud/ipvs/</link><pubDate>Wed, 13 Sep 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/ipvs/</guid><description>LVS - Linux Virtual Server 的简称，kubernetes 中主要包含 ipvs + ipvsadm。 官方链接： The Linux Virtual Server Project - Linux Server Cluster for Load Balancing</description></item><item><title>networkPolicy - 网络策略</title><link>https://www.ryken.cloud/networkPolicy-%E7%BD%91%E7%BB%9C%E7%AD%96%E7%95%A5/</link><pubDate>Wed, 13 Sep 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/networkPolicy-%E7%BD%91%E7%BB%9C%E7%AD%96%E7%95%A5/</guid><description>网络策略 | Kubernetes
https://kubernetes.io/docs/concepts/services-networking/network-policies/
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 apiVersion:networking.</description></item><item><title>github release</title><link>https://www.ryken.cloud/github-release/</link><pubDate>Thu, 07 Sep 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/github-release/</guid><description>指导文档：
发布 assets - GitHub 文档 Release CNI Plugins v1.3.0 · renyunkang/plugins (github.com) apt-get install gridsite-clients</description></item><item><title>kubernetes document</title><link>https://www.ryken.cloud/kubernetes-document/</link><pubDate>Thu, 07 Sep 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/kubernetes-document/</guid><description>官方文档 repo：
Kubernetes website and documentation repo grc images - Container Registry</description></item><item><title>安装 calico</title><link>https://www.ryken.cloud/%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</link><pubDate>Thu, 07 Sep 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</guid><description>官网 About Calico (tigera.io)
安装 calico calicoctl 使用calicoctl 可以使用calico 的更多的功能，calicoctl 用于管理 Calico 策略和配置，以及查看详细的集群状态。
API groups 所有 Kubernetes 资源都属于一个 API 组。 API 组由资源的 apiVersion 指定。Calico 使用 projectcalico.</description></item><item><title>kubekey 安装高可用集群</title><link>https://www.ryken.cloud/kubekey-%E5%AE%89%E8%A3%85%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/</link><pubDate>Fri, 01 Sep 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/kubekey-%E5%AE%89%E8%A3%85%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/</guid><description>k8s 的HA 用kubekey的话支持三种： 1. 外置 lb 2. 内置 haproxy （每个worker节点） 3. 内置 kube-vip （每个master节点）
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 apiVersion:kubekey.</description></item><item><title>k3s + rancher 安装</title><link>https://www.ryken.cloud/k3s-+-rancher-%E5%AE%89%E8%A3%85/</link><pubDate>Fri, 25 Aug 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/k3s-+-rancher-%E5%AE%89%E8%A3%85/</guid><description>文档链接：
安装在docker： https://oldj.net/article/2022/04/17/install-k3s-and-rancher/ 安装到k3s 中： https://blog.lv5.moe/p/use-k3s-to-build-homelab-based-on-kubernetes rancher 官方文档： https://ranchermanager.docs.rancher.com/zh/ https://ranchermanager.docs.rancher.com/v2.5/pages-for-subheaders/load-balancer-and-ingress-controller 安装 k3s：[[k3s 多节点安装]] 安装 rancher：
使用 helm 安装</description></item><item><title>网卡命名规则</title><link>https://www.ryken.cloud/%E7%BD%91%E5%8D%A1%E5%91%BD%E5%90%8D%E8%A7%84%E5%88%99/</link><pubDate>Thu, 10 Aug 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E7%BD%91%E5%8D%A1%E5%91%BD%E5%90%8D%E8%A7%84%E5%88%99/</guid><description>GRUB_CMDLINE_LINUX_DEFAULT 有2个参数，决定网卡名字怎么显示：
biosdevname=1: em1 板载网卡 p3p4 pci网卡 net.ifnames=1 eno1 板载网卡 enp51s0f1 pci网卡 ens1 能热插拔的网卡 组合的情况</description></item><item><title>calico 中的 proxy-arp</title><link>https://www.ryken.cloud/calico-%E4%B8%AD%E7%9A%84-proxy-arp/</link><pubDate>Wed, 02 Aug 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/calico-%E4%B8%AD%E7%9A%84-proxy-arp/</guid><description> /proc/sys/net/ipv4/conf/DEV/rp_filter =&amp;gt; 1：开启反向路径过滤，确认数据包来源，对于普通容器，IP基本无法伪装，但是如果是VM（Calico也支持VM），很容易伪装IP地址，所以为了安全打开这个选项。 /proc/sys/net/ipv4/conf/DEV/route_localnet =&amp;gt; 1：允许路由到本地。 /proc/sys/net/ipv4/neigh/DEV/proxy_delay =&amp;gt; 0：默认情况下，主机为了减少ARP风暴的可能，会延迟一段时间回复ARP包，这个选项关闭这个延迟。 /proc/sys/net/ipv4/conf/DEV/forwarding =&amp;gt; 1：允许转发数据包（如果不允许转发的话，那数据包就出不去主机了）。 上面是IPv4的情况，如果是IPv6的网络，则会设置：
/proc/sys/net/ipv6/conf/DEV/proxy_ndp =&amp;gt; 1：这个和proxy_arp是一样的。 /proc/sys/net/ipv4/conf/DEV/forwarding =&amp;gt; 1：同IPv4。</description></item><item><title>网络问题</title><link>https://www.ryken.cloud/%E7%BD%91%E7%BB%9C%E6%8E%92%E6%9F%A5/</link><pubDate>Fri, 28 Jul 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E7%BD%91%E7%BB%9C%E6%8E%92%E6%9F%A5/</guid><description>网络问题定位 dns 解析 svc-pod 转发不通(使用svcname 访问) 使用 svcip 可以访问 检查 dns 组件问题 使用 svcip 也不能访问 进一步检查 kube-proxy kube-proxy svc-pod 转发不通(直接使用 svc ip访问) 直接访问后端 pod-ip 可通 进一步检查 kube-proxy 规则问题 直接访问后端 pod-ip 不通 进一步检查 cni 问题 注意：不要使用 ping 命令测试 svcip icmp 是否连通，应该测试 svc 的四层转发是否连通 cni 跨节点pod-pod不通，pod-node不通 1.</description></item><item><title>动手实现 hybridnet - 原理</title><link>https://www.ryken.cloud/%E5%8A%A8%E6%89%8B%E5%AE%9E%E7%8E%B0-hybridnet-%E5%8E%9F%E7%90%86/</link><pubDate>Thu, 27 Jul 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%8A%A8%E6%89%8B%E5%AE%9E%E7%8E%B0-hybridnet-%E5%8E%9F%E7%90%86/</guid><description>默认路由表
1 2 3 4 ~# ip rule 0: from all lookup local 32766: from all lookup main 32767: from all lookup default 1 2 3 4 5 6 7 8 9 ~# ip rule 0: from all lookup local 1: from all lookup 39999 2: from all lookup 40000 3: from all fwmark 0x20/0x20 lookup 40001 4: from 172.</description></item><item><title>动手实现 hybridnet - 实践</title><link>https://www.ryken.cloud/%E5%8A%A8%E6%89%8B%E5%AE%9E%E7%8E%B0-hybridnet-%E5%AE%9E%E8%B7%B5/</link><pubDate>Thu, 27 Jul 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%8A%A8%E6%89%8B%E5%AE%9E%E7%8E%B0-hybridnet-%E5%AE%9E%E8%B7%B5/</guid><description>[[vlan 配置]] [[网卡 vlan]] [[手动创建 netns + 跨主机通信]] [[动手实现 hybirdnet.svg]]
规划的网段：
overlay：10.233.100.0/24 vlan： 10.10.11.0/24 10.10.20.0/24 添加 vlan 子接口</description></item><item><title>journalctl</title><link>https://www.ryken.cloud/journalctl/</link><pubDate>Fri, 21 Jul 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/journalctl/</guid><description>需更改设置,如上次系统崩溃，需要查看日志时，就要看上一次的启动日志。 journalctl -b -1
查看指定时间的日志 journalctl &amp;ndash;since=&amp;ldquo;2012-10-3018:17:16&amp;rdquo; journalctl &amp;ndash;since &amp;ldquo;20 minago&amp;rdquo; journalctl &amp;ndash;since yesterday journalctl &amp;ndash;since&amp;quot;2015-01-10&amp;quot; &amp;ndash;until &amp;ldquo;2015-01-11 03:00&amp;rdquo; journalctl &amp;ndash;since 09:00 &amp;ndash;until&amp;quot;1 hour ago&amp;quot; journalctl &amp;ndash;since&amp;quot;15:15&amp;quot; &amp;ndash;until now</description></item><item><title>hybridnet 自定义资源解释</title><link>https://www.ryken.cloud/hybridnet-%E8%87%AA%E5%AE%9A%E4%B9%89%E8%B5%84%E6%BA%90%E8%A7%A3%E9%87%8A/</link><pubDate>Sun, 16 Jul 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/hybridnet-%E8%87%AA%E5%AE%9A%E4%B9%89%E8%B5%84%E6%BA%90%E8%A7%A3%E9%87%8A/</guid><description>[[hybridnet 网络插件]]
资源 解释 networks 网络域 subnets 节点可用的网段资源 ipinstances ip 分配情况（只读） nodeinfoes 节点情况 vxlan 信息 每个 Network 至少需要有一个 Subnet 才能真正被使用 目前还不支持一个节点属于多个 Underlay Network，但是支持一个节点属于多个不同 type（比如 Overlay、Underlay）的 Network network network.</description></item><item><title>安装</title><link>https://www.ryken.cloud/%E5%AE%89%E8%A3%85/</link><pubDate>Sun, 16 Jul 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%AE%89%E8%A3%85/</guid><description>helm repo add hybridnet https://alibaba.github.io/hybridnet/ helm repo update helm install hybridnet hybridnet/hybridnet -n kube-system &amp;ndash;set init.cidr=10.233.64.0/18
kubectl label node hybridnet-worker hybridnet-worker2 hybridnet-worker8 hybridnet-control-plane node-role.</description></item><item><title>安装 bcc 工具包</title><link>https://www.ryken.cloud/%E5%AE%89%E8%A3%85-bcc-%E5%B7%A5%E5%85%B7%E5%8C%85/</link><pubDate>Sun, 16 Jul 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%AE%89%E8%A3%85-bcc-%E5%B7%A5%E5%85%B7%E5%8C%85/</guid><description>eunomia-bpf 是一个开源的 eBPF 动态加载运行时和开发工具链，它的目的是简化 eBPF 程序的开发、构建、分发、运行。它基于 libbpf 的 CO-RE 轻量级开发框架，支持通过用户态 WASM 虚拟机控制 eBPF 程序的加载和执行，并将预编译的 eBPF 程序打包为通用的 JSON 或 WASM 模块进行分发。</description></item><item><title>calico non-root + non-privileged 运行</title><link>https://www.ryken.cloud/calico-non-root-+-non-privileged-%E8%BF%90%E8%A1%8C/</link><pubDate>Fri, 02 Jun 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/calico-non-root-+-non-privileged-%E8%BF%90%E8%A1%8C/</guid><description>参照 operator 修改方式进行修改 privilege 运行是由于 Bidirectional 挂载必须为 privilege 模式
1 2 3 - mountPath:/sys/fs/mountPropagation:Bidirectionalname:sysfs 1 The DaemonSet &amp;#34;calico-node&amp;#34; is invalid: spec.</description></item><item><title>ip 地址</title><link>https://www.ryken.cloud/ip-%E5%9C%B0%E5%9D%80/</link><pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/ip-%E5%9C%B0%E5%9D%80/</guid><description>IPv4 地址块 CIDR 范围 地址数 效用域 用途 0.0.0.0/8 0.0.0.0 – 0.255.255.255 16,777,216 软件 用于广播信息到当前主机 10.</description></item><item><title>About me</title><link>https://www.ryken.cloud/About-me/</link><pubDate>Wed, 24 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/About-me/</guid><description> My Github MyKnowledgeGarden (ryken.cloud) MyEmail: rykren1998@gmail</description></item><item><title>搭建数字花园</title><link>https://www.ryken.cloud/%E6%90%AD%E5%BB%BA%E6%95%B0%E5%AD%97%E8%8A%B1%E5%9B%AD/</link><pubDate>Wed, 24 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E6%90%AD%E5%BB%BA%E6%95%B0%E5%AD%97%E8%8A%B1%E5%9B%AD/</guid><description>发布的方案： obsidian 目前最完美的免费发布方案 - 渐进式教程 (oldwinter.top)
参考发布的花园 + 搭建方案：
quartz + obsidian-export(添加.export-ignore)+github jackyzha0/quartz: 🌱 host your own second brain and digital garden for free (github.</description></item><item><title>multipass</title><link>https://www.ryken.cloud/multipass/</link><pubDate>Tue, 23 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/multipass/</guid><description>官方github： https://github.com/canonical/multipass windows 环境下的安装以及使用： https://multipass.run/docs/installing-on-windows
windows 支持以下两种模式：
Hyper-V：（只能是windows Pro 或者 windows 企业版） VirtualBox：依赖 VirtualBox 切换模式：
multipass set local.</description></item><item><title>calico 应急方案</title><link>https://www.ryken.cloud/calico-%E5%BA%94%E6%80%A5%E6%96%B9%E6%A1%88/</link><pubDate>Wed, 10 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/calico-%E5%BA%94%E6%80%A5%E6%96%B9%E6%A1%88/</guid><description>确认出现问题的具体部分和错误现象 确认问题出现的时间、场景，了解系统的运行环境、版本信息、系统配置等，以便明确问题的范围和分析。 确认错误现象是否具有可重现性，是否存在规律性与周期性，有助于问题进一步排查和分析。 检查 Calico 日志[[CloudNative/cni-network/calico/日志/日志|日志]] 查看 calico describe 以及日志。[[通过事件、日志排查]] 根据错误提示或警告信息，查找相关的解决方案或错误排除方法。 如果日志中没有明显错误或警告信息，可以将日志级别调整为 DEBUG，查看更为详细的日志信息，进一步分析问题原因。 calico没有明显错误日志记录时，可以查看系统日志，并参考系统资源情况来分析问题原因。[[根据系统日志排查]] 进行网络诊断 [[网络工具诊断]] 使用 ping、traceroute、tcpdump 等网络诊断工具，检查网络连通性和网络通信状态(pod-pod/pod-node/pod-svc/node-svc/node-gateway、pod-gateway)，确认是否存在网络问题，并从 gateway→node→svc→pod 一层一层更细化的定位问题根源。 如果问题根源涉及 pod，可以从 ipam、bgp 路由角度分析 如果涉及 svc，可以从 kube-proxy、iptables 角度分析 如果涉及 node，可以从物理网络、gateway 角度分析 对比不同机器上的性能指标以及网络状况，确定出错的机器是否存在特殊网络问题。 检查 Calico 配置 [[calico配置文件]] 确认 Calico 的配置文件是否正确，是否缺失或错误配置。包括 cni configmap、bgp、bgppeer、felix等相关配置 检查系统资源使用情况 查看系统 CPU、内存、磁盘等资源的使用情况，如果存在资源不足或超载现象，可以考虑优化或扩容。 确认 Calico 的网络带宽使用情况，分析网络流量的分布和情况，确认是否出现了网络流量瓶颈。 逐一排查可能的原因 如果是网络通信问题，可以检查网络拓扑，路由器、交换机、防火墙等设备的配置，确认是否存在配置错误或故障。 如果是性能瓶颈问题，可以进行性能测试和优化，如使用性能工具、调整配置参数等。 如果是系统崩溃问题，可以通过故障日志、内存转储文件等进行分析定位。 进行测试环境部署和测试 如果出现问题的环境比较复杂，可以考虑在测试环境中进行部署和测试，以排除环境配置和部署工具问题。 更新和升级 Calico 版本 如果发现 Calico 的问题存在于旧版本中，可以尝试升级到最新版本。 Upgrade Calico on Kubernetes 寻求社区帮助 如果以上方法无法解决问题，可以联系 Calico 的社区成员，提供详细的问题描述和相关信息，以便社区成员进行协助和解决。 可以在社区论坛或邮件列表上留言，或直接向社区成员联系，提供相关问题信息，交流问题解决方案。 Issues · projectcalico/calico Discuss Calico https://calicousers.</description></item><item><title>网卡 vlan</title><link>https://www.ryken.cloud/%E7%BD%91%E5%8D%A1-vlan/</link><pubDate>Wed, 10 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E7%BD%91%E5%8D%A1-vlan/</guid><description>添加 vlan 子接口 使用 ip 命令 ip link add link enp125s0f0 name enp125s0f0.100 type vlan id 100 使用 vconfig 命令 相关模块 lsmod |grep -i 8021q 相关工具包 apt-get install vlan or yum install vconfig modprobe 8021q 添加 vlan vconfig add enp8s0f1 100 在enp8s0f1接口上配置两个VLAN vconfig set_flag enp8s0f1.</description></item><item><title/><link>https://www.ryken.cloud/2.-%E7%BC%96%E8%AF%91%E5%92%8C%E9%93%BE%E6%8E%A5/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/2.-%E7%BC%96%E8%AF%91%E5%92%8C%E9%93%BE%E6%8E%A5/</guid><description>预编译、编译、汇编、链接
1 2 3 4 5 6 7 // hello.c #include &amp;lt;stdio.h&amp;gt;int main() { printf(&amp;#34;hello world\n&amp;#34;); return 0; } | $ gcc hello.</description></item><item><title/><link>https://www.ryken.cloud/3.-%E5%B7%A5%E5%85%B7%E9%93%BE/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/3.-%E5%B7%A5%E5%85%B7%E9%93%BE/</guid><description>安装
工具 go build
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 usage: go build [-o output] [build flags] [packages] # 根据他们的依赖来编译import路径中的包，但是不install结果 Build compiles the packages named by the import paths, along with their dependencies, but it does not install the results.</description></item><item><title/><link>https://www.ryken.cloud/3.-%E7%9B%AE%E6%A0%87%E6%96%87%E4%BB%B6/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/3.-%E7%9B%AE%E6%A0%87%E6%96%87%E4%BB%B6/</guid><description>编译器编译源码之后的生成的文件叫做目标文件
2. 3. ELF文件结构描述 文件头 段表 重定位表 字符串表 4. 链接的接口 - 符号</description></item><item><title/><link>https://www.ryken.cloud/3.1-%E7%9B%AE%E6%A0%87%E6%96%87%E4%BB%B6%E7%9A%84%E6%A0%BC%E5%BC%8F/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/3.1-%E7%9B%AE%E6%A0%87%E6%96%87%E4%BB%B6%E7%9A%84%E6%A0%BC%E5%BC%8F/</guid><description>目标文件的格式 现在PC平台流行的可执行文件格式只要是PE(Windows Portable Executable)和ELF(Linux Executable Linkable Format)。它们都是COFF(Common file format)的变种。COFF的主要贡献是在目标文件中引入了段的机制，不同的目标文件可以拥有不同数量以及不同类型的段，另外还定义了调试数据格式。目标文件就是源代码编译之后没有进行链接的中间文件，它同可执行文件的内容结构很相似，所以一般与可执行文件一起采用一种格式存储。 不光可执行文件按照可执行文件格式存储，动态链接库以及静态链接库都是按照可执行文件的格式进行存储，Windows下统称为PE-COFF文件格式，Linux下统称为ELF文件。 静态链接库稍有不同，静态链接库把很多目标文件捆绑在一起形成一个文件，再加上一些索引。我们可以把它理解为一个包含很多目标文件的文件包。 ELF文件标准将系统中ELF格式的文件归为以下4类：
ELF文件类型 说明 实例 可重定向文件【Relocatable File】 这类文件包含了代码和数据，可以被用来连链接成可执行文件或共享目标文件，静态链接库也可以归为这一类 Linux的.</description></item><item><title/><link>https://www.ryken.cloud/3.2-%E7%9B%AE%E6%A0%87%E6%96%87%E4%BB%B6%E7%9A%84%E5%86%85%E5%AE%B9/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/3.2-%E7%9B%AE%E6%A0%87%E6%96%87%E4%BB%B6%E7%9A%84%E5%86%85%E5%AE%B9/</guid><description>目标文件的内容 目标文件中含有编译后的机器指令代码、数据以及链接时所需要的一些信息，比如符号表、调试信息、字符串等。一般目标文件将这些信息按照不同的属性，以“节/段”的形式存储。
段名 名称 内容 代码段 .code或者.text 源代码编译后的机器指令 数据段 .data 全局变量和局部静态变量 .</description></item><item><title/><link>https://www.ryken.cloud/3.3-ELF%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84%E6%8F%8F%E8%BF%B0/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/3.3-ELF%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84%E6%8F%8F%E8%BF%B0/</guid><description>ELF基本结构 ELF文件头：包含了描述整个文件的基本属性(ELF文件版本、目标机器型号、程序入口地址等) 各个段（代码段、数据段、bss段） 段表：描述了ELF文件包含的所有段的信息(段名、段的长度、在文件中的偏移、读写权限、段的其他属性) ELF辅助结构：字符串表、符号表等 文件头 readelf 命令查看ELF文件：readelf -h hello.o
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ELF Header | ELF Header: ELF魔数 | Magic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 文件机器字节长度 | Class: ELF64 数据存储方式 | Data: 2&amp;#39;s complement, little endian 版本 | Version: 1 (current) 运行平台 | OS/ABI: UNIX - System V ABI版本 | ABI Version: 0 ELF重定位类型 | Type: REL (Relocatable file) 硬件平台 | Machine: Advanced Micro Devices X86-64 硬件平台版本 | Version: 0x1 入口地址 | Entry point address: 0x0 程序头入口 | Start of program headers: 0 (bytes into file) 段表的位置 | Start of section headers: 1176 (bytes into file) ———— | Flags: 0x0 文件头长度 | Size of this header: 64 (bytes) 程序头长度 | Size of program headers: 0 (bytes) 程序头数量 | Number of program headers: 0 段表的长度 | Size of section headers: 64 (bytes) 段数量 | Number of section headers: 14 | Section header string table index: 13 ELF文件头中定义了ELF魔数、文件机器字节长度、数据存储方式、版本、运行平台、ABI版本、ELF重定位类型、硬件平台、硬件平台版本、入口地址、程序头入口和长度、段表的位置和长度、段的数量等。 ELF魔数：16个字节，用于标识ELF文件的平台属性。如ELF字长、字节序、ELF文件版本。 ELF文件的魔数：7f 45 4c 46；a.</description></item><item><title/><link>https://www.ryken.cloud/3.4-%E9%93%BE%E6%8E%A5%E7%9A%84%E6%8E%A5%E5%8F%A3-%E7%AC%A6%E5%8F%B7/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/3.4-%E9%93%BE%E6%8E%A5%E7%9A%84%E6%8E%A5%E5%8F%A3-%E7%AC%A6%E5%8F%B7/</guid><description>链接的本质就是将不同的目标文件之间相互粘在一起，想要粘合就必须要有固定的规则才行。在链接中，目标文件之间相互拼合实际上是目标文件之间对地址的引用，即对函数和变量的地址的引用，如A使用B中的函数func，即A中定义了函数func、B引用了func。链接中，我们将函数和变量统称为改符号，函数名或者变量名就是符号名。 整个链接的过程正是基于符号才能正确完成，链接的过程中很关键的一部分就是符号的管理，每一个目标文件都会有一个相应的符号表，这个表里面记录目标文件中所用到的所有符号，每个定义的符号有一个对应的值叫做符号值。对于变量核函数来说，符号值就是它们的地址，我们将符号表中的所有符号进行分类：
定义在本目标文件的全局符号，可以被其他目标文件引用 在本目标文件中引用的全局符号，却没有定义在本目标文件，这一般叫外部符号。 段名，这种符号往往由编译器产生，它的值就是该段的起始地址 局部符号，这类符号往往只在编译单元内部可见，比如static的变量。调试器可以使用这些符号来分析程序或奔溃时的核心转储文件。这些局部符号对于链接过程没有作用，链接器往往会忽略它们 行号信息，即目标文件指令与源代码中代码行的对应关系，这是可选的 我们最关心的是全局符号，即以上分类的第一类和第二类，因为链接的过程只关心全局符号的相互粘合，局部符号、段名、行号等都是次要的，因为他们对于其他目标文件来说是不可见的。 查看符号表命令：nm hello.o
1 2 3 4 5 6 7 8 9 root@orange:/home/orange/program/test# nm hello.</description></item><item><title/><link>https://www.ryken.cloud/4.-%E9%9D%99%E6%80%81%E9%93%BE%E6%8E%A5/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/4.-%E9%9D%99%E6%80%81%E9%93%BE%E6%8E%A5/</guid><description>本章小结：</description></item><item><title/><link>https://www.ryken.cloud/9.1-%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/9.1-%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/</guid><description>单元测试/性能测试/代码覆盖率等一起保障了代码总是在可控范围内。单元测试用来测试包或者程序的一部分代码或者一组代码的函数。
单元测试分类
正向测试：在正常执行的情况下，保证代码不产生错误的测试。
反向测试：保证代码不仅会产生错误，而且是预期的错误
基础测定：只使用一组参数和结果来测试一段代码
表组测试：使用多组参数和结果来进行测试
mock测试：模仿测试代码需要用到的外部资源，比如：数据库或网络服务器，有助于让测试在没有所需要的外部资源可用的时候，模拟这些资源的行为使得测试正常进行。
testing 工具链和标准库自带的单元测试框架，可以使测试工作变得相对容易，提供了从测试框架到报告测试的输出和状态的各种测试功能的支持。</description></item><item><title/><link>https://www.ryken.cloud/9.2-%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/9.2-%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/</guid><description>性能测试函数以benchmark为前缀，同样保存在&amp;quot;*_test.go&amp;quot;文件中 go test -bench. 测试工具默认不会执行性能测试，须使用bench参数，他逐步调整B.N值，反复执行测试函数，直到能获得准确的测试结果。
如果希望只执行性能测试，run=NONE忽略所有的单元测试用例。 默认以并发方式执行测试，但可用cpu参数设定多个并发限制来观察结果。 benchtime用于设定最小测试时间，增加循环次数，用于解决某些耗时的目标默认循环次数过少，取平均值不足以精确计量性能。
timer 如果在测试函数中要执行一些额外的操作，应该临时停止定时器工作
memory 性能测试关心的不仅仅是执行时间，还包括在堆上的内存分配。内存分配和内存回收的相关操作也应计入到消耗成本 go test -bench . -benchmem -gcflags &amp;ldquo;-N -l&amp;rdquo; # 禁用内联和优化，便于观察结果 可以将测试函数设置为总输出内存分配信息，无论是否使用benchmem参数 B.</description></item><item><title/><link>https://www.ryken.cloud/9.3-%E4%BB%A3%E7%A0%81%E8%A6%86%E7%9B%96%E7%8E%87/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/9.3-%E4%BB%A3%E7%A0%81%E8%A6%86%E7%9B%96%E7%8E%87/</guid><description>单元测试与性能测试关注代码质量，代码覆盖率度量测试自身完整和有效性的一种手段 通过覆盖值，可以分析出测试代码的编写质量；检测其是否提供了足够的测试条件，是否执行了足够的函数/语句/分支/代码行，以此量化测试本身，让白盒测试起到应有的质量保证。 代码覆盖率也常被用来发现死代码（永远不会被执行的代码）
1 2 3 4 5 6 7 8 9 10 11 12 13 14 func deadCode(a,b int) { num := a+b if num &amp;gt; 3 { log.</description></item><item><title/><link>https://www.ryken.cloud/9.4-%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/9.4-%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/</guid><description>引发性能问题：执行时间过长/内存占用过多/意外阻塞 等 通过捕获监控相关执行状态数据，便可定位引发问题的原因，从而优化改进。
在测试时输出并保存相关数据，进行初期评估 在运行阶段通过web接口获取实时数据，分析一段时间内的健康状况 除此之外，可以使用自定义计数器（expvar）提供更多与逻辑相关的参考数据 go test -run -bench . -memprofile mem.out -cpuprofile cpu.out net/http</description></item><item><title/><link>https://www.ryken.cloud/c++%E7%B1%BB%E5%B0%81%E8%A3%85/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/c++%E7%B1%BB%E5%B0%81%E8%A3%85/</guid><description>CGO是C语言和Go语言之间的桥梁，原则上无法直接支持C++的类。CGO不支持C++语法的根本原因是C++至今为止还没有一个二进制接口规范(ABI)。一个C++类的构造函数在编译为目标文件时如何生成链接符号名称、方法在不同平台甚至是C++的不同版本之间都是不一样的。但是C++是兼容C语言，所以我们可以通过增加一组C语言函数接口作为C++类和CGO之间的桥梁，这样就可以间接地实现C++和Go之间的互联。当然，因为CGO只支持C语言中值类型的数据类型，所以我们是无法直接使用C++的引用参数等特性的。
c++类到Go语言对象 【声明接口】先从用户的角度思考需要什么样的接口，提供一个纯c语言的接口 【纯C实现接口】基于C++的类定义这些C语言包装函数，并用纯c函数接口封装C++类 【将纯C接口转为Go函数】如果包中有C++11的语法，要通过#cgo CXXFLAGS: -std=c++11打开C++11 【进一步将Go函数封装为Go对象】基于GO函数封装为Go语法的Go对象 Go语言对象到C++类 【声明接口】先从用户的角度思考需要什么样的接口，提供一个纯c语言的接口 【导出C接口】基于Go语言封装Go对象，导出C接口 【封装C++对象】有了C接口，进一步进行C++的封装为对象 将Go对象导出为C接口，然后基于C接口再包装为C++对象以便于使用</description></item><item><title/><link>https://www.ryken.cloud/CGO%E5%85%A5%E9%97%A8/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/CGO%E5%85%A5%E9%97%A8/</guid><description>使用系统库输出helloworld 1 2 3 4 5 6 7 8 package main //#include &amp;lt;stdio.h&amp;gt; import &amp;#34;C&amp;#34; func main() { C.</description></item><item><title/><link>https://www.ryken.cloud/CGO%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/CGO%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/</guid><description>CGO是架接Go语言和C语言的桥梁，它使二者在二进制接口层面实现了互通，但是我们要注意因两种语言的内存模型的差异而可能引起的问题。如果在CGO处理的跨语言函数调用时涉及到了指针的传递，则可能会出现Go语言和C语言共享某一段内存的场景。我们知道C语言的内存在分配之后就是稳定的，但是Go语言因为函数栈的动态伸缩可能导致栈中内存地址的移动(这是Go和C内存模型的最大差异)。如果C语言持有的是移动之前的Go指针，那么以旧指针访问Go对象时会导致程序崩溃。
GO访问C内存 C语言空间的内存是稳定的，只要不是被人为提前释放，那么在Go语言空间可以放心大胆地使用。 因为Go语言实现的限制，我们无法在Go语言中创建大于2GB内存的切片（具体请参考makeslice实现代码）。不过借助cgo技术，我们可以在C语言环境创建大于2GB的内存，然后转为Go语言的切片使用：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package main /* #include &amp;lt;stdlib.</description></item><item><title/><link>https://www.ryken.cloud/CGO%E7%BC%96%E7%A8%8B/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/CGO%E7%BC%96%E7%A8%8B/</guid><description>笔记来源： https://www.cntofu.com/book/73/ch2-cgo/readme.md Go语言函数调用C语言函数以复用C语言资源这一目的而出现的（因为C语言还会涉及回调函数，自然也会涉及到从C语言函数调用Go语言函数）。 要使用CGO特性，需要安装C／C构建工具链，在macOS和Linux下是要安装和GCC，在windows下是需要安装MinGW工具。同时需要保证环境变量CGO_ENABLED被设置为1，这表示CGO是被启用的状态。在本地构建时CGO_ENABLED默认是启用的，当交叉构建时CGO默认是禁止的。
通过import &amp;quot;C&amp;quot;语句启用CGO特性。紧跟在这行语句前面的注释是一种特殊语法，里面包含的是正常的C语言代码。当确保CGO启用的情况下，还可以在当前目录中包含C/C++对应的源文件。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package main /* #include &amp;lt;stdio.</description></item><item><title/><link>https://www.ryken.cloud/dlv-%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/dlv-%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85/</guid><description>dlv官网： https://github.com/derekparker/delve 下载安装详看： https://github.com/derekparker/delve/blob/master/Documentation/installation/linux/install.md 官方安装文档介绍 **Installation on Linux，**有两种方法在linux上安装dlv。 第一种使用go get：
| export GOPROXY=https://goproxy.cn
go get github.</description></item><item><title/><link>https://www.ryken.cloud/dlv-%E8%B0%83%E8%AF%95%E4%BD%BF%E7%94%A8/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/dlv-%E8%B0%83%E8%AF%95%E4%BD%BF%E7%94%A8/</guid><description>工程目录如下： | ├── github.com/me/foo ├── cmd │ └── foo │ └── main.go ├── pkg │ └── baz │ ├── bar.go</description></item><item><title/><link>https://www.ryken.cloud/gdb%E8%B0%83%E8%AF%95go%E4%BB%A3%E7%A0%81/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/gdb%E8%B0%83%E8%AF%95go%E4%BB%A3%E7%A0%81/</guid><description>官方使用gdb：Debugging Go Code with GDB https://golang.org/doc/gdb
linux 下载安装gdb apt-get install gdb
gdb调试go代码时，gdb版本要≥7.5 同时禁用编译器的优化使得方便调试：go build -gcflags=all=&amp;quot;-N -l&amp;quot;
gdb调试常用命令 r：run，执行程序</description></item><item><title/><link>https://www.ryken.cloud/go-context/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/go-context/</guid><description>context控制调用函数的超时返回
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func main() { .</description></item><item><title/><link>https://www.ryken.cloud/go-Convey%E6%B5%8B%E8%AF%95/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/go-Convey%E6%B5%8B%E8%AF%95/</guid><description>go convey在开启了一个协程，并在其中进行断言，触发panic
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 //panic: Convey operation made without context on goroutine stack.</description></item><item><title/><link>https://www.ryken.cloud/go-defer/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/go-defer/</guid><description>defer应用场景 GO defer会在当前函数返回前执行传入的函数，经常被用于关闭文件描述符、关闭数据库连接以及解锁资源，在函数调用结束后完成一些收尾工作。
常见问题：
defer 关键字的调用时机以及多次调用 defer 时执行顺序是如何确定的； defer 关键字使用传值的方式传递参数时会进行预计算，导致不符合预期的结果； 1. 执行顺序 1 2 3 4 5 6 7 8 9 10 11 12 func defer_call() { defer func() { fmt.</description></item><item><title/><link>https://www.ryken.cloud/go-mock-%E6%B5%8B%E8%AF%95/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/go-mock-%E6%B5%8B%E8%AF%95/</guid><description>1 2 3 4 === RUN Testxxx Testxxx: box_test.go:239: missing call(s) to *xxxmock.Mockxxx.xxx(is anything, is anything, is anything) xxx/xxx/xxx/box_test.go:202 Testxxx: box_test.</description></item><item><title/><link>https://www.ryken.cloud/go-newmake/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/go-newmake/</guid><description>Go语言中new和make是内建的两个函数，主要用来分配内存。 在Go语言中对于值类型的声明不需要分配内存空间，是因为它们在声明的时候已经默认分配好了内存空间。而对于引用类型的变量，我们在使用的时候不仅要声明它，还要为它分配内存空间，否则我们的值就没办法存储。
new 根据传入的类型分配一片内存空间并返回指向这片内存空间的指针。使用new函数得到的是一个类型的指针，并且该指针对应的值为该类型的零值。new的函数签名如下：
1 func new(Type) *Type make make也是用于内存分配的，区别于new，它只用于slice、map以及chan的内存创建。我们在代码中往往都会使用如下所示的语句初始化这三类基本类型，这三个语句分别返回了不同类型的数据结构：
1 2 3 4 5 6 7 8 slice := make([]int, 0, 100) hash := make(map[int]bool, 10) hash := make(map[int]bool) ch := make(chan int, 5) // slice 是一个包含 data、cap 和 len 的结构体 reflect.</description></item><item><title/><link>https://www.ryken.cloud/go-%E6%89%93%E5%8C%85%E5%92%8C%E5%B7%A5%E5%85%B7%E9%93%BE/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/go-%E6%89%93%E5%8C%85%E5%92%8C%E5%B7%A5%E5%85%B7%E9%93%BE/</guid><description>go mod
1 2 3 4 5 6 7 8 9 10 verifying git.ghostcloud.cn/newben/log@v0.0.2: checksum mismatch downloaded: h1:5bclc0fb8Q3FSzheOP1AhqYNSDvZu4i7021j5YEa3zQ= go.sum: h1:FUGx1ZtSCxsGW/BzbMrGp9XN6eKkigN3J4i1q5kughc= SECURITY ERROR This download does NOT match an earlier download recorded in go.</description></item><item><title/><link>https://www.ryken.cloud/Go-%E8%AF%AD%E8%A8%80%E7%AC%94%E8%AF%95%E9%9D%A2%E8%AF%95%E9%A2%98%E6%B1%87%E6%80%BB/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Go-%E8%AF%AD%E8%A8%80%E7%AC%94%E8%AF%95%E9%9D%A2%E8%AF%95%E9%A2%98%E6%B1%87%E6%80%BB/</guid><description>init函数先于main函数运行 编译器检测Client是否实现了io.Closer interface所定义的函数 1 var _ io.Closer = (*Client)(nil) go处理超时：使用 time.After() 结合 select+chan 完成。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // called 管道用于超时处理，send管道用于阻塞等待sendResponse func (server *Server) handleRequest(cc codec.</description></item><item><title/><link>https://www.ryken.cloud/GoAccess-%E5%8F%AF%E8%A7%86%E5%8C%96%E7%9B%91%E6%8E%A7access%E6%97%A5%E5%BF%97/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/GoAccess-%E5%8F%AF%E8%A7%86%E5%8C%96%E7%9B%91%E6%8E%A7access%E6%97%A5%E5%BF%97/</guid><description>下载安装： https://goaccess.io/download 快速开始： https://goaccess.io/get-started
在上游服务的nginx中添加 :
1 2 3 4 access_log logs/renyunkang-test.access.log main; location /report.html { alias /usr/local/openresty/nginx/html/report.html; } goaccess /usr/local/openresty/nginx/logs/renyunkang-test.</description></item><item><title/><link>https://www.ryken.cloud/golang-%E6%B5%8B%E8%AF%95/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/golang-%E6%B5%8B%E8%AF%95/</guid><description>go test -v -run 测试函数名字
Go Test 单元测试简明教程 Go Mock (gomock)简明教程链接 go测试工具goconvey的使用 GoConvey测试框架使用指南 goconvey - 课时 1：优雅的单元测试</description></item><item><title/><link>https://www.ryken.cloud/golang-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/golang-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/</guid><description>总览 File → Settings → Build,Execution… → Deployment 添加自己的远程主机的地址，以及Mapping代码上传到远程的存放目录 在工程名按下快捷键ctrl+alt+shrift+x，将代码上传到远程 在下方终端中ssh到终端，编译 进入编译出二进制路径，开始dlv调试 dlv &amp;ndash;listen=:2345 &amp;ndash;headless=true &amp;ndash;api-version=2 exec .</description></item><item><title/><link>https://www.ryken.cloud/golang%E5%85%B6%E4%BB%96%E7%9B%B8%E5%85%B3%E5%BA%93/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/golang%E5%85%B6%E4%BB%96%E7%9B%B8%E5%85%B3%E5%BA%93/</guid><description>go-ping:
https://github.com/go-ping/ping https://www.cnblogs.com/wlw-x/p/14169607.html</description></item><item><title/><link>https://www.ryken.cloud/golang%E5%9F%BA%E7%A1%80/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/golang%E5%9F%BA%E7%A1%80/</guid><description>reflect 反射 - 获取某个结构体的所有方法 通过反射实现结构体与服务的映射关系
interface与reflect
interface
类型转换 https://books.studygolang.com/advanced-go-programming-book/ch2-cgo/ch2-03-cgo-types.html
Go解决现代编程难题 快速的开发/编译速度 内置并发机制，无须特定的线程库 类型系统简单高效，专注代码复用 自带垃圾回收器，无须自己管理内存 go 包管理</description></item><item><title/><link>https://www.ryken.cloud/golang%E6%A0%87%E5%87%86%E5%BA%93/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/golang%E6%A0%87%E5%87%86%E5%BA%93/</guid><description>Packages ： https://golang.org/pkg/</description></item><item><title/><link>https://www.ryken.cloud/https%E7%9B%B8%E5%85%B3%E5%AE%89%E5%85%A8%E6%80%A7/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/https%E7%9B%B8%E5%85%B3%E5%AE%89%E5%85%A8%E6%80%A7/</guid><description>验证证书的颁发证书者是不是有效的 证书类型
域名验证 domain validated DV证书 组织验证 organization validated OV证书 扩展验证 extend validated EV证书 安装certbot apt-get install -y python3-certbot-nginx</description></item><item><title/><link>https://www.ryken.cloud/http%E8%AF%B7%E6%B1%82/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/http%E8%AF%B7%E6%B1%82/</guid><description>http post body请求 1 2 3 4 5 6 7 ### POST http://10.0.2.179:81/apis/license/update Accept: application/json Authorization: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MjQ1Mjc3MTAsImlhdCI6MTYyNDUxNjkxMCwiaXNzIjoiY29yZXNlcnZlciIsInN1YiI6ImFkbWluIn0.yJs1iwR9NwFg2PLEKFv6WygiLTuU4xhLA3ne7mVuVOM Content-Type: application/json; charset=utf-8; {&amp;#34;license&amp;#34;:&amp;#34;AWFiY2RlZnAAshsmL9Ef9yuqW&amp;#34;} http get url请求 1 2 3 4 ### GET http://10.</description></item><item><title/><link>https://www.ryken.cloud/kubernetes%E4%B8%AD%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E4%B8%8E%E6%9C%AF%E8%AF%AD/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/kubernetes%E4%B8%AD%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E4%B8%8E%E6%9C%AF%E8%AF%AD/</guid><description>Kubernetes中的大部分概念如Node、Pod、Replication Controller、Service等都可以被看作一种资源对象，几乎所有资源对象都可以通过kubectl工具（或者API编程调用）执行增、删、改、查等操作并将其保存在etcd中持久化存储。从个角度来看，Kubernetes其实是一个高度自动化的资源控制系统，它通过跟踪对比etcd库里保存的“资源期望状态”与当前环境中的“实际资源状态”的差异来实现自动控制和自动纠错的高级功能。 声明资源时的一个关键属性：apiVersion。 Kubernetes平台采用了“核心+外围扩展”的设计思路，在保持平台核心稳定的同时具备持续演进升级的优势。Kubernetes大部分常见的核心资源对象都归属于v1这个核心API，比如Node、Pod、Service、Endpoints、Namespace、RC、PersistentVolume等。在版本迭代过程中，Kubernetes先后扩展了extensions/v1beta1、apps/v1beta1、apps/v1beta2等API组，而在1.9版本之后引入了apps/v1这个正式的扩展API组，正式淘汰（deprecated）了extensions/v1beta1、apps/v1beta1、apps/v1beta2这三个API组。</description></item><item><title/><link>https://www.ryken.cloud/map%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/map%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/</guid><description>go map的底层机制 操作go map时需要注意什么 map有两种取元素的方法
1 2 value := my_map[&amp;#34;key&amp;#34;] value,exists := my_map[&amp;#34;key&amp;#34;] map的键可以是任何相等性操作符支持的类型， 如整数、浮点数、复数、字符串、指针、接口（只要其动态类型支持相等性判断）、结构以及数组。
无法对 map 的 key 或 value 进行取址 map中的元素并不是一个变量，而是一个值。因此，我们不能对map的元素进行取址操作，不能直接进行修改。 修改map中对应value的值时，若value对应的类型不是指针时，不能直接进行修改，需要取一个临时变量进行赋值或者修改为指针类型</description></item><item><title/><link>https://www.ryken.cloud/MasterNode/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/MasterNode/</guid><description>Master Kubernetes里的Master指的是集群控制节点，在每个Kubernetes集群里都需要有一个Master来负责整个集群的管理和控制，基本上Kubernetes的所有控制命令都发给它，它负责具体的执行过程，我们后面执行的所有命令基本都是在Master上运行的。Master通常会占据一个独立的服务器。
在Master上运行着以下关键进程：
Kubernetes API Server（kube-apiserver）：提供了HTTP Rest接口的关键服务进程，是Kubernetes里所有资源的增、删、改、查等操作的唯一入口，也是集群控制的入口进程。 Kubernetes Controller Manager（kube-controller-manager）：Kubernetes里所有资源对象的自动化控制中心，可以将其理解为资源对象的“大总管”。 Kubernetes Scheduler（kube-scheduler）：负责资源调度（Pod调度）的进程，相当于公交公司的“调度室”。 另外，在Master上通常还需要部署etcd服务，因为Kubernetes里的所有资源对象的数据都被保存在etcd中。
Node Node是Kubernetes集群中的工作负载节点，每个Node都会被Master分配一些工作负载（Docker容器），当某个Node宕机时，其上的工作负载会被Master自动转移到其他节点上。 在每个Node上都运行着以下关键进程。
kubelet：负责Pod对应容器创建、启停等任务，同时与Master密切协作，实现集群管理的基本功能。 kube-proxy：实现Kubernetes Service的通信与负载均衡机制的重要组件。 Docker Engine（docker）：Docker引擎，负责本机的容器创建和管理工作。 Node可以在运行期间动态增加到Kubernetes集群中，在默认情况下kubelet会向Master注册自己，这也是Kubernetes推荐的Node管理方式。一旦Node被纳入集群管理范围，kubelet进程就会定时向Master汇报自身信息，例如操作系统、Docker版本、机器的CPU和内存情况，以及当前有哪些Pod在运行等，这样Master就可以获知每个Node的资源使用情况，并实现高效均衡的资源调度策略。而某个Node在超过指定时间不上报信息时，会被Master判定为“失联”，Node的状态被标记为不可用（Not Ready），随后Master会触发“工作负载大转移”的自动流程。 kubectl describe node node_name 查看某个node的信息。</description></item><item><title/><link>https://www.ryken.cloud/math%E5%BA%93/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/math%E5%BA%93/</guid><description>浮点数保留N位小数 1 2 3 4 5 6 7 8 9 // 2代表精度，这种方式会有小数点后无效的0的情况 strconv.FormatFloat(123.123 &amp;#39;f&amp;#39;, 2, 64) // 效果同上 fmt.</description></item><item><title/><link>https://www.ryken.cloud/net%E5%BA%93/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/net%E5%BA%93/</guid><description/></item><item><title/><link>https://www.ryken.cloud/nginx-%E5%86%85%E9%83%A8%E6%B5%81%E7%A8%8B/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/nginx-%E5%86%85%E9%83%A8%E6%B5%81%E7%A8%8B/</guid><description>1. reload 流程 第三步master进程可能引入了新的监听端口，子进程会继承父进程所有已经打开的端口。 master收到quit信号会优雅的关闭子进程。 调用reload之后，master会使用新的配置文件启动新的worker进程，旧的worker进程关闭监听句柄，并在处理完当前的连接请求之后结束进程，如果客户端请求一直被阻塞长时间等待处理不了，nginx有对应的nginx配置项 worker-timeout-shutdown，指定时间之后进程会被强制退出。 2. 热升级的流程 升级 备份nginx可执行文件 向nginx master发送信号进行热部署 kill -USR2 pid，此时会启动一个新的nginx master 若向老的nginx matser发送优雅关闭的请求kill -WINCH pid，老的worker进行会优雅退出，但是老的master 还在运行，即允许在使用新版本出现问题时做版本回退 若向老的nginx matser发送优雅关闭的请求kill -QUIT pid，老的master也会优雅退出 回退 向老的nginx master发送HUP信号【reload命令】，向新的nginx master发送QUIT优雅退出信号</description></item><item><title/><link>https://www.ryken.cloud/nginx-%E5%91%BD%E4%BB%A4%E8%A1%8C/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/nginx-%E5%91%BD%E4%BB%A4%E8%A1%8C/</guid><description>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 root@orange:/opt/nginx/conf# nginx -?</description></item><item><title/><link>https://www.ryken.cloud/nginx-%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95%E4%BB%A5%E5%8F%8A%E5%AE%89%E8%A3%85/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/nginx-%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95%E4%BB%A5%E5%8F%8A%E5%AE%89%E8%A3%85/</guid><description>官方地址： https://nginx.org/ 通过编译安装才会将强大的第三方模块引入nginx 文件结构
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 root@orange:~/nginx-1.</description></item><item><title/><link>https://www.ryken.cloud/nginx-%E6%9E%B6%E6%9E%84/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/nginx-%E6%9E%B6%E6%9E%84/</guid><description>抛出问题 为什么nginx使用master-worker的进程架构模型 为什么worker进程数量要与cpu的核数相匹配 多个worker之间共享数据时，为什么在TLS/限流/限速的共享方式不同 nginx 请求的处理流程 使用了非阻塞的事件驱动模型，因此使用状态机进行正确的识别和处理请求，nginx用作反向代理和静态资源服务器。 nginx用作静态资源当内存不足以缓存所有信息时，一些sendFile或者AIO会退化为阻塞的磁盘调用因此使用了线程池。 nginx用作反向代理时使用特定的协议将请求代理出去。 nginx进程结构 单进程结构 - 用于开发调式 多进程结构 - 用于实际的生产环境，nginx可以利用多核的特性 使用多进程模型而非多线程模型，保证了高可用性和高可靠性。如果使用多线程的模型，线程之间共享同一个地址空间，如果nginx导入的第三方模块引发一个地址空间导致的段错误时，整个nginx进程就会挂掉，而多进程模型就不会有这样的问题。</description></item><item><title/><link>https://www.ryken.cloud/nginx-%E7%AE%80%E4%BB%8B/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/nginx-%E7%AE%80%E4%BB%8B/</guid><description>主流的web 服务器有：Nginx、Apache、Tomcat，可以搭建网站或者反向代理服务器。
1. Nginx主要的应用场景 web请求先经过nginx，再到我们的应用服务，再到后面的数据库服务mysql、redis等，因为我们的应用开发效率高，所以其运行效率就会低，其QPS、TPS、并发受限，因此将很多的这样的一个应用服务组成一个集群提高高可用性，一旦形成集群就要求nginx具有反向代理功能，考虑容灾和动态扩容要求反向代理具备负载均衡 在整个链路当中，nginx处于企业内网的边缘节点，随着网络链路的增长用户体验的时延会增加，因此将一段时间不变的动态内容缓冲到nginx中直接向用户提供访问 访问一些jss、图片等静态资源时，无需由应用服务来访问，由系统上放置的本地文件资源直接由nginx提供访问就可以 数据库服务业务场景简单，其QPS/TPS好于应用服务程序，因此由nginx直接访问数据库服务 &amp;ndash; API服务 强大的业务处理能力 2. Nginx 出现的原因 Apache处理一个连接对应一个进程，导致进程间切换代价高，同时当连接数多时，无法开启那么多的进程。 在多核的架构下 摩尔定律失效了【芯片中的晶体管和电阻器的数量每年会翻番】 3.</description></item><item><title/><link>https://www.ryken.cloud/nginx-%E9%85%8D%E7%BD%AE%E4%B8%80%E4%B8%AA%E5%85%B7%E6%9C%89%E7%BC%93%E5%86%B2%E5%8A%9F%E8%83%BD%E7%9A%84%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/nginx-%E9%85%8D%E7%BD%AE%E4%B8%80%E4%B8%AA%E5%85%B7%E6%9C%89%E7%BC%93%E5%86%B2%E5%8A%9F%E8%83%BD%E7%9A%84%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8/</guid><description>使用之前的作为一个上游服务再搭建一个反向代理服务器
安装openresty： https://openresty.org/cn/linux-packages.html，openresty默认的工作路径：/usr/local/openresty/nginx 可以将请求按照负载均衡算法反向代理给多台上游服务器工作，这样就实现了水平扩展，在用户无感知的情况下增加服务器来提高处理性能，而当上游服务器出现问题时，nginx会将自动的将请求由出现灾难的服务器转交给正常的服务器。
设置缓冲功能
设置缓冲存放的路径，设置cache的名称，开辟的共享内存，key要放置在共享内存中， 设置指定url使用的共享内存 同一个url 可能对不同的用户展示的内容是不同的，因此将用户设置到key中 设置哪些响应不返回 上游服务器通常是不提供公网访问的，因此将之前的静态服务器作为上游服务，将server中的listen 8080修改为listen 127.0.0.1:8080;
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 root@orange:~/nginx/nginx-test# cat /usr/local/openresty/nginx/conf/nginx.</description></item><item><title/><link>https://www.ryken.cloud/nginx-%E9%85%8D%E7%BD%AE%E4%B8%80%E4%B8%AA%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E6%9C%8D%E5%8A%A1%E5%99%A8/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/nginx-%E9%85%8D%E7%BD%AE%E4%B8%80%E4%B8%AA%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E6%9C%8D%E5%8A%A1%E5%99%A8/</guid><description>配置文件 location：后面为/ 表示所有请求 指定url的后缀与文件目录后缀一一对应： root：会将url中的路径带到文件路径中来 alias：（通常使用）[
]( https://blog.csdn.net/z920954494/article/details/52132125) gzip：启动gzip压缩 gzip_min_length：压缩的最小字节数 gzip_comp_level：压缩等级 gzip_types：针对某些类型的文件进行压缩
1 2 3 4 gzip on; gzip_min_length 1; # 小于1字节的不再压缩 gzip_comp_level 2; gzip_types text/plain application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png; autoindex：当访问的url以/结尾时可以对应到这个目录中的文件结构 set $limit_rate设置nginx向客户浏览器发送响应的速度，limit_rate是core moudle中的内置变量，单位字节 &amp;ndash; 限制带宽</description></item><item><title/><link>https://www.ryken.cloud/nginx-%E9%85%8D%E7%BD%AE%E8%AF%AD%E6%B3%95/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/nginx-%E9%85%8D%E7%BD%AE%E8%AF%AD%E6%B3%95/</guid><description>配置文件通用语法 有的指令块有名字，有的指令块没有名字，这取决于提供指令块的nginx子模块决定。 http配置的指令块
server：对应的一个或一组域名 http：里面的所有的指令都是由http模块去解析/执行 upstream：上游服务 location：url表达式</description></item><item><title/><link>https://www.ryken.cloud/pprof/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/pprof/</guid><description>下载cpu profile，默认从当前开始收集30s的cpu使用情况，需要等待30sgo tool pprof http://localhost:6060/debug/pprof/profile # 30-second CPU profilego tool pprof http://localhost:6060/debug/pprof/profile?seconds=120 # wait 120s# 下载heap profilego tool pprof http://localhost:6060/debug/pprof/heap # heap profile# 下载goroutine profilego tool pprof http://localhost:6060/debug/pprof/goroutine # goroutine profile# 下载block profilego tool pprof http://localhost:6060/debug/pprof/block # goroutine blocking profile# 下载mutex profilego tool pprof http://localhost:6060/debug/pprof/mutex go tool pprof http://localhost:6060/debug/pprof/heap Fetching profile over HTTP from http://localhost:6060/debug/pprof/heapSaved profile in /home/ubuntu/pprof/pprof.</description></item><item><title/><link>https://www.ryken.cloud/reflect%E5%BA%93/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/reflect%E5%BA%93/</guid><description>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 func Copy(dst, src Value) int func DeepEqual(x, y interface{}) bool func Swapper(slice interface{}) func(i, j int) type ChanDir func (d ChanDir) String() string type Kind func (k Kind) String() string type MapIter func (it *MapIter) Key() Value func (it *MapIter) Next() bool func (it *MapIter) Value() Value type Method type SelectCase type SelectDir type SliceHeader type StringHeader type StructField type StructTag func (tag StructTag) Get(key string) string func (tag StructTag) Lookup(key string) (value string, ok bool) type Type func ArrayOf(count int, elem Type) Type func ChanOf(dir ChanDir, t Type) Type func FuncOf(in, out []Type, variadic bool) Type func MapOf(key, elem Type) Type func PtrTo(t Type) Type func SliceOf(t Type) Type func StructOf(fields []StructField) Type func TypeOf(i interface{}) Type type Value func Append(s Value, x .</description></item><item><title/><link>https://www.ryken.cloud/slice%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/slice%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/</guid><description>slice的底层机制 切片之后共享一块空间【指针】，需要触发cap不足才会去扩容
1 2 3 4 5 type slice struct { array unsafe.Pointer len int cap int } 1.</description></item><item><title/><link>https://www.ryken.cloud/sync.map-%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/sync.map-%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/</guid><description>sync.map底层实现 sync.map 采用读写分离技术，用空间换时间 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 type Map struct { mu Mutex read atomic.</description></item><item><title/><link>https://www.ryken.cloud/sync.Map/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/sync.Map/</guid><description>amended 为 fase，说明 dirty 为空，那直接返回 空和 false amended 为 true，说明 dirty 中可能存在我们要找的 key。 read.amended为true代表dirty map中含有read.map中没有的元素
store 如果 dirty为空 read中有直接改，修改成功 read中有但是read没有修改成功 read 对应key的value为空，确定dirty不为空，插入到dirty中 read 对应key的value不为空，更新entry</description></item><item><title/><link>https://www.ryken.cloud/sync.Mutex%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/sync.Mutex%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/</guid><description>用一张图说明go中的Mutex的演变 初期使用一个flag标记，是否有人在持有锁。 考虑goroutine的唤醒机制性能低下的问题，让申请获取锁的goroutine自旋获取锁，如果固定次数获取不到之后，继续阻塞等待. 让新来的和刚刚唤醒的goroutine继续进行自旋一段时间来获取锁 多给了新人和唤醒的goroutine机会，会导致一些goroutine一直拿不到锁，因此加入了饥饿模式 Mutex底层实现 源码位置：src/sync/mutex.go，Mutex也是简单的实现了Lock和Unlock方法
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 type Locker interface { Lock() Unlock() } type Mutex struct { state int32 sema uint32 } const ( mutexLocked = 1 &amp;lt;&amp;lt; iota // mutex is locked mutexWoken mutexStarving // 从state字段中分出一个饥饿标记 mutexWaiterShift = iota starvationThresholdNs = 1e6 ) // mutexLocked，mutexWoken，mutexStarving，mutexWaiterShift 的值分别是1，2，4，3。 // starvationThresholdNs = 1e6 表示1ms内如果被唤醒的协程还没有抢到锁，就进入饥饿状态，可以直接获取锁。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 func (m *Mutex) Lock() { // Fast path: grab unlocked mutex.</description></item><item><title/><link>https://www.ryken.cloud/sync.RWMutex%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/sync.RWMutex%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/</guid><description>底层实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 type RWMutex struct { w Mutex // held if there are pending writers writerSem uint32 // semaphore for writers to wait for completing readers readerSem uint32 // semaphore for readers to wait for completing writers readerCount int32 // number of pending readers readerWait int32 // number of departing readers } const rwmutexMaxReaders = 1 &amp;lt;&amp;lt; 30 func (rw *RWMutex) RLock() {.</description></item><item><title/><link>https://www.ryken.cloud/sync.WaitGroup%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/sync.WaitGroup%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/</guid><description>WaitGroup底层实现原理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 type WaitGroup struct { noCopy noCopy state1 [3]uint32 } // noCopy 是 golang 源码中检测禁止拷贝的技术，在不考虑内存对齐和并发的因素下可以将其看为如下结构 type WaitGroup struct { counter int32 waiter uint32 sema uint32 } // count：代表目前尚未完成的个数 // waiter：代表目前已经调用waitGroup.</description></item><item><title/><link>https://www.ryken.cloud/sync_atomic/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/sync_atomic/</guid><description>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 func AddInt32(addr *int32, delta int32) (new int32) func AddInt64(addr *int64, delta int64) (new int64) func AddUint32(addr *uint32, delta uint32) (new uint32) func AddUint64(addr *uint64, delta uint64) (new uint64) func AddUintptr(addr *uintptr, delta uintptr) (new uintptr) func CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool) func CompareAndSwapInt64(addr *int64, old, new int64) (swapped bool) func CompareAndSwapPointer(addr *unsafe.</description></item><item><title/><link>https://www.ryken.cloud/sync%E5%BA%93/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/sync%E5%BA%93/</guid><description>类型与方法总览 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 type Cond func NewCond(l Locker) *Cond func (c *Cond) Broadcast() func (c *Cond) Signal() func (c *Cond) Wait() type Locker type Map func (m *Map) Delete(key interface{}) func (m *Map) Load(key interface{}) (value interface{}, ok bool) func (m *Map) LoadAndDelete(key interface{}) (value interface{}, loaded bool) func (m *Map) LoadOrStore(key, value interface{}) (actual interface{}, loaded bool) func (m *Map) Range(f func(key, value interface{}) bool) func (m *Map) Store(key, value interface{}) type Mutex func (m *Mutex) Lock() func (m *Mutex) Unlock() type Once func (o *Once) Do(f func()) type Pool func (p *Pool) Get() interface{} func (p *Pool) Put(x interface{}) type RWMutex func (rw *RWMutex) Lock() func (rw *RWMutex) RLock() func (rw *RWMutex) RLocker() Locker func (rw *RWMutex) RUnlock() func (rw *RWMutex) Unlock() type WaitGroup func (wg *WaitGroup) Add(delta int) func (wg *WaitGroup) Done() func (wg *WaitGroup) Wait() WaitGroup实现协程间同步 WaitGroup对象内部有一个计数器，最初从0开始，有三个方法来控制计数器的数量</description></item><item><title/><link>https://www.ryken.cloud/%E4%B9%90%E8%A7%82%E9%94%81%E6%82%B2%E8%A7%82%E9%94%81%E8%87%AA%E6%97%8B%E9%94%81/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E4%B9%90%E8%A7%82%E9%94%81%E6%82%B2%E8%A7%82%E9%94%81%E8%87%AA%E6%97%8B%E9%94%81/</guid><description>乐观锁和悲观锁并不是一种真实存在的锁，而是一种设计思想。
悲观锁总认为最坏的情况可能会出现，认为数据很可能会被其他人所修改，所以悲观锁在持有数据的时候总会把资源/数据 锁住，这样其他线程想要请求这个资源的时候就会阻塞，直到等到悲观锁把资源释放为止。 乐观锁的思想与悲观锁的思想相反，它总认为资源和数据不会被别人所修改，所以读取不会上锁，但是乐观锁在进行写入操作的时候会判断当前数据是否被修改过 CAS或版本号机制。 自旋锁：只有获取了锁的线程才能对资源进行访问，由于同一时刻只能有一个线程获取到锁。没有获取到锁的线程就一直循环等待判断该资源是否已经释放锁，这种锁叫做自旋锁，它不用将线程阻塞起来，还有一种处理方式就是把自己阻塞起来，等待重新调度请求，这种叫做互斥锁。</description></item><item><title/><link>https://www.ryken.cloud/%E4%BD%BF%E7%94%A8%E9%9D%99%E6%80%81%E5%BA%93%E5%92%8C%E5%8A%A8%E6%80%81%E5%BA%93/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E4%BD%BF%E7%94%A8%E9%9D%99%E6%80%81%E5%BA%93%E5%92%8C%E5%8A%A8%E6%80%81%E5%BA%93/</guid><description>CGO在使用C/C++资源的时候一般有三种形式：直接使用源码、链接静态库、链接动态库。直接使用源码就是在import &amp;quot;C&amp;quot;之前的注释部分包含C代码，或者在当前包中包含C/C++源文件。链接静态库和动态库的方式比较类似，都是通过在LDFLAGS选项指定要链接的库方式链接。
gcc生成静态库/动态库 | ar -rc libxxx.a xxx.o（正确方法） ar -rc libxxx.a xxx1.c （可以生成静态库；运行可执行程序会报错：could not read symbols:Archive has no index;run ranlib to add one）</description></item><item><title/><link>https://www.ryken.cloud/%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8/</guid><description>CGO技术不仅可以在Go语言中调用C语言函数，也可以将Go语言函数导出为C语言函数
go调用C函数 启用CGO特性后，CGO会构造一个虚拟的C包。通过这个虚拟的C包可以调用C语言函数。
C函数的返回值 C语言不支持返回多个结果，因此&amp;lt;errno.h&amp;gt;标准库提供了一个errno宏用于返回错误状态。我们可以近似地将errno看着一个线程安全的全局变量，可以用于记录最近一次错误的状态码。 CGO也针对&amp;lt;errno.h&amp;gt;标准库的errno宏做的特殊支持：在CGO调用C函数时如果有两个返回值，那么第二个返回值将对应errno错误状态。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /* #include &amp;lt;errno.</description></item><item><title/><link>https://www.ryken.cloud/%E5%9C%A8%E5%AE%B9%E5%99%A8%E5%86%85%E8%8E%B7%E5%8F%96Pod%E4%BF%A1%E6%81%AF/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%9C%A8%E5%AE%B9%E5%99%A8%E5%86%85%E8%8E%B7%E5%8F%96Pod%E4%BF%A1%E6%81%AF/</guid><description>每个Pod在被成功创建出来之后，都会被系统分配唯一的名字、IP地址，并且处于某个Namespace中，那么我们如何在Pod的容器内获取Pod的这些重要信息呢？答案就是使用Downward API。
Downward API有什么价值 在某些集群中，集群中的每个节点都需要将自身的标识（ID）及进程绑定的IP地址等信息事先写入配置文件中，进程在启动时会读取这些信息，然后将这些信息发布到某个类似服务注册中心的地方，以实现集群节点的自动发现功能。此时Downward API就可以派上用场了，具体做法是先编写一个预启动脚本或Init Container，通过环境变量或文件方式获取Pod自身的名称、IP地址等信息，然后将这些信息写入主程序的配置文件中，最后启动主程序。
Downward API可以通过以下两种方式将Pod信息注入容器内部。
环境变量：用于单个变量，可以将Pod信息和Container信息注入容器内部。 Volume挂载：将数组类信息生成为文件并挂载到容器内部。 环境变量注入容器内部【pod信息+container信息】 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 apiVersion:v1kind:Podmetadata:name:dapi-test-podspec:containers:- name:test-containerimage:busyboxcommand:[&amp;#34;/bin/sh&amp;#34;,&amp;#34;-c&amp;#34;,&amp;#34;env&amp;#34;]env:- name:MY_POD_NAMEvalueFrom:fieldRef:fieldPath:metadata.</description></item><item><title/><link>https://www.ryken.cloud/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/</guid><description>Q1 = 和 := 的区别？ := 声明+赋值； = 仅赋值 简短声明模式的限制：
定义变量同时显示初始化 不能提供数据类型 只能在函数内部使用 1 2 3 4 var foo int foo = 10 // 等价于 foo := 10 编译执行下面代码的结果 1 2 3 4 5 6 7 8 9 10 package main var( size :=1024 max_size = size*2 ) func main() { println(size,max_size) } // syntax error: unexpected := Q2 常量 常量不同于变量，变量在运行时分配内存，常量通常在被编译器在预处理阶段直接展开，作为指令数据直接使用。</description></item><item><title/><link>https://www.ryken.cloud/%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%BC%A0%E5%85%A5%E4%BC%A0%E5%87%BA%E5%8F%82%E6%95%B0/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%BC%A0%E5%85%A5%E4%BC%A0%E5%87%BA%E5%8F%82%E6%95%B0/</guid><description>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 //#include &amp;lt;string.</description></item><item><title/><link>https://www.ryken.cloud/%E5%B0%81%E8%A3%85qsort/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%B0%81%E8%A3%85qsort/</guid><description>qsort快速排序函数有&amp;lt;stdlib.h&amp;gt;标准库提供，函数的声明如下：
1 2 3 4 void qsort( void* base, size_t num, size_t size, int (*cmp)(const void*, const void*) ); 其中base参数是要排序数组的首个元素的地址，num是数组中元素的个数，size是数组中每个元素的大小。最关键是cmp比较函数，用于对数组中任意两个元素进行排序。cmp排序函数的两个指针参数分别是要比较的两个元素的地址，如果第一个参数对应元素大于第二个参数对应的元素将返回结果大于0，如果两个元素相等则返回0，如果第一个元素小于第二个元素则返回结果小于0。</description></item><item><title/><link>https://www.ryken.cloud/%E5%BE%85%E5%8A%9E%E4%BA%8B%E9%A1%B9/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%BE%85%E5%8A%9E%E4%BA%8B%E9%A1%B9/</guid><description>总结interface与reflect &amp;ndash; go类型 sync/atomic golang相关的面试题 7days相关的总结 &amp;ndash; rpc值类型与指针类型处理有些许差异 反射映射为服务并完成函数的调用的实现比较巧妙 类型 组合</description></item><item><title/><link>https://www.ryken.cloud/%E6%97%A0%E6%A0%87%E9%A2%98/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E6%97%A0%E6%A0%87%E9%A2%98/</guid><description>内存 tcmalloc - 大小对象分级、多核缓冲
gc策略： 标记-清扫 === 内存碎片 标记-压缩 === 计算位置、forward指针，实现复杂 半空间复制</description></item><item><title/><link>https://www.ryken.cloud/%E6%97%B6%E9%97%B4%E6%93%8D%E4%BD%9C/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E6%97%B6%E9%97%B4%E6%93%8D%E4%BD%9C/</guid><description>计算2个时间差 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package main import ( &amp;#34;fmt&amp;#34; &amp;#34;time&amp;#34; ) func main() { //Add方法和Sub方法是相反的，获取t0和t1的时间距离d是使用Sub //将t0加d获取t1就是使用Add方法 k := time.</description></item><item><title/><link>https://www.ryken.cloud/%E6%9E%84%E5%BB%BA%E7%BA%A6%E6%9D%9F%E9%97%AE%E9%A2%98/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E6%9E%84%E5%BB%BA%E7%BA%A6%E6%9D%9F%E9%97%AE%E9%A2%98/</guid><description>go构建约束问题，Build constraints exclude all Go files in ？ 我的情况是使用了CGO，但是编译的时候没有加上CGO_ENABLED=1 有的情况下，也有可能是GOOS环境的问题 // +build linux,amd64,go1.15,!cgo</description></item><item><title/><link>https://www.ryken.cloud/%E6%A8%A1%E5%9D%97%E7%AE%80%E4%BB%8B/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E6%A8%A1%E5%9D%97%E7%AE%80%E4%BB%8B/</guid><description> 初识nginx nginx架构基础 nginx的数据结构和进程模型 详解http模块 nginx如何处理http请求 常用的实例、变量 反向代理与负载均衡 nginx的系统层优化 从源码视角深入使用nginx与OpenResty</description></item><item><title/><link>https://www.ryken.cloud/%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/</guid><description>C中的类型 在Go语言中访问C语言的符号时，一般是通过虚拟的“C”包访问。Go语言中数值类型和C语言数据类型基本上是相似的，它们的对应关系表如下：
C语言类型 CGO类型 Go语言类型 char C.char byte singed char C.</description></item><item><title/><link>https://www.ryken.cloud/%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86-configMap/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86-configMap/</guid><description>从Kubernetes 1.2开始提供了一种统一的应用配置管理方案—ConfigMap。ConfigMap以一个或多个key:value的形式保存在Kubernetes系统中供应用使用，既可以用于表示一个变量的值（例如apploglevel=info），也可以用于表示一个完整配置文件的内容。
configMap的使用场景 生成为容器内的环境变量。 设置容器启动命令的启动参数（需设置为环境变量）。 以Volume的形式挂载为容器内部的文件或目录。 创建configMap kubectl通过yaml配置文件创建 kubectl create -f cm-appvars.yaml
将应用所需要的变量定义为configMap 将配置文件定义为configmap 1 2 3 4 5 6 7 apiVersion:v1kind:ConfigMapmetadata:name:cm-appvarsdata:apploglevel:infoappdatadir:/var/data 1 2 3 4 5 6 7 8 9 10 11 12 13 14 apiVersion:v1kind:ConfigMapmetadata:name:cm-appconfigfilesdata:key-serverxml:|&amp;lt;?</description></item><item><title/><link>https://www.ryken.cloud/%E9%9D%99%E6%80%81Pod/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E9%9D%99%E6%80%81Pod/</guid><description>特性 静态Pod是由kubelet进行管理的仅存在于特定Node上的Pod。它们不能通过API Server进行管理，无法与ReplicationController、Deployment或者DaemonSet进行关联，并且kubelet无法对它们进行健康检查。静态Pod总是由kubelet创建的，并且总在kubelet所在的Node上运行。
创建方式：配置文件创建和http方式创建 配置文件创建： 设置kubelet的启动参数“&amp;ndash;config”，指定kubelet需要监控的配置文件所在的目录，kubelet会定期扫描该目录，并根据该目录下的.yaml或.json文件进行创建操作。
假设配置目录为/etc/kubelet.d/，配置启动参数为&amp;ndash;config=/etc/kubelet.d/，然后重启kubelet服务。
1 2 3 4 5 6 7 8 9 10 11 12 13 apiVersion:v1kind:Podmetadata:name:static-weblabels:name:static-webspec:containers:- name:static-webimages:nginxports:- name:webcontainerPort:80 由于静态Pod无法通过API Server直接管理，所以在Master上尝试删除这个Pod时，会使其变成Pending状态，且不会被删除。删除该Pod的操作只能是到其所在Node上将其定义文件从指定的(/etc/kubelet.</description></item><item><title>1-11</title><link>https://www.ryken.cloud/1-11/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/1-11/</guid><description>原文链接： https://studygolang.com/articles/10065 https://studygolang.com/articles/11003 https://studygolang.com/articles/10746 https://studygolang.com/articles/10994
1. defer执行顺序 1 2 3 4 5 6 7 8 9 10 11 12 func defer_call() { defer func() { fmt.</description></item><item><title>epoll的LT模式与ET模式</title><link>https://www.ryken.cloud/epoll%E7%9A%84LT%E6%A8%A1%E5%BC%8F%E4%B8%8EET%E6%A8%A1%E5%BC%8F/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/epoll%E7%9A%84LT%E6%A8%A1%E5%BC%8F%E4%B8%8EET%E6%A8%A1%E5%BC%8F/</guid><description>epoll的LT模式与ET模式哪个效率更高
LT和ET的区别： LT对于存在未读完的数据，下一次调用epoll_wait还会触发， ET无论是否读完，只触发一次，直到下一次EPOLLIN事件到来
LT的优点：易于编码，未读完的数据下次还能继续读，不易遗漏 ET的缺点：难以编码，需要一次读完，有时会遗漏
LT的缺点：在并发量高的时候，epoll_wait返回的就绪队列比较大，遍历比较耗时。因此LT适用于并发量小的情况 ET的优点：并发量大的时候，就绪队列要比LT小得多，效率更高
应用 使用ET的例子：nginx 使用LT的例子：redis 选取参考（nginx选用ET）
看连接的空闲程度，连接的空闲程度很高就用ET，所以按照场景，http的客户端idel情况很高，用ET，如果是rpg的游戏服务器，用LT，ET差不多</description></item><item><title>git proxy</title><link>https://www.ryken.cloud/git-proxy/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/git-proxy/</guid><description>git 设置和取消代理 (github.com)
windows git 设置代理 简单方法： 设置环境变量
http_proxy: 127.0.0.1:1080 https_proxy: 127.0.0.1:1080 windows git 相关的配置文件：C:\Users\renyunkang\.gitconfig
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 [user] email = rykren1998@gmail.</description></item><item><title>git 文档</title><link>https://www.ryken.cloud/git-%E6%96%87%E6%A1%A3/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/git-%E6%96%87%E6%A1%A3/</guid><description> **feat：**提交新功能 fix：修复了bug docs：只修改了文档 style：调整代码格式，未修改代码逻辑（比如修改空格、格式化、缺少分号等） refactor：代码重构，既没修复bug也没有添加新功能 perf：性能优化，提高性能的代码更改 test：添加或修改代码测试 chore：对构建流程或辅助工具和依赖库（如文档生成等）的更改</description></item><item><title>ssh 首次连接自动化输入 yes</title><link>https://www.ryken.cloud/ssh-%E9%A6%96%E6%AC%A1%E8%BF%9E%E6%8E%A5%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BE%93%E5%85%A5-yes/</link><pubDate>Sat, 06 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/ssh-%E9%A6%96%E6%AC%A1%E8%BF%9E%E6%8E%A5%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BE%93%E5%85%A5-yes/</guid><description>sshpass -p PASSWORD ssh -o StrictHostKeyChecking=no root@${ip1}'echo 1' 避免交互输入密码 sshpass -p PASSWORD scp xx xx@xxx:/xx</description></item><item><title>4. OFN Gateway</title><link>https://www.ryken.cloud/4.-OFN-Gateway/</link><pubDate>Mon, 01 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/4.-OFN-Gateway/</guid><description/></item><item><title>arp proxy</title><link>https://www.ryken.cloud/arp-proxy/</link><pubDate>Mon, 01 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/arp-proxy/</guid><description>1 2 3 4 sudo bash -c &amp;#39;echo 1 &amp;gt; /proc/sys/net/ipv4/ip_forward&amp;#39; cat /proc/sys/net/ipv4/conf/eth1/proxy_arp sudo sysctl -p 添加默认路由</description></item><item><title>centos 配置网络文件</title><link>https://www.ryken.cloud/centos-%E9%85%8D%E7%BD%AE%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6/</link><pubDate>Mon, 01 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/centos-%E9%85%8D%E7%BD%AE%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6/</guid><description>1 2 3 4 5 6 7 8 9 10 11 12 13 14 cat /etc/sysconfig/network-scripts/ifcfg-eth0 # Created by cloud-init on instance boot automatically, do not edit.</description></item><item><title>Q&amp;A</title><link>https://www.ryken.cloud/QA/</link><pubDate>Mon, 01 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/QA/</guid><description>what is gateway service? 假设您正在使用 Kourier 作为 Knative 的网络层? 修改配置使用节点的 ip 作为 external-ip 使用。 how to do?</description></item><item><title>vlan 配置</title><link>https://www.ryken.cloud/vlan-%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 May 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/vlan-%E9%85%8D%E7%BD%AE/</guid><description>[[hybridnet 网络插件]]
1 2 3 4 5 6 7 set interfaces ethernet eth1 vif 100 description &amp;#39;VLAN 100&amp;#39; set interfaces ethernet eth1 vif 100 address &amp;#39;192.</description></item><item><title>calico metrics</title><link>https://www.ryken.cloud/calico-metrics/</link><pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/calico-metrics/</guid><description> Prometheus statistics (tigera.io)
指标 描述 felix_active_local_endpoints 该主机上活动的 endpoints 数量 felix_active_local_policies 该主机上活跃的策略数 felix_active_local_selectors 该主机上额活跃 selectors 数 felix_calc_graph_output_events calculation graph 产生的事件数 felix_calc_graph_update_time_seconds 为每个 datastore更新 calculation graph 调用 OnUpdate的秒 felix_calc_graph_updates_processed calculation graph 处理的 datestore 更新次数 felix_cluster_num_host_endpoints 集群层面 host endpoints 的总数 felix_cluster_num_hosts 集群中的 Calico hosts 总数 felix_cluster_num_workload_endpoints 集群层负载 endpoints 总数 felix_exec_time_micros fork/exec 子进程花费的时间 felix_int_dataplane_addr_msg_batch_size 批处理的接口地址报文数。 较高的值表示我们正在做更多的批处理以试图跟上 felix_int_dataplane_apply_time_seconds 应用数据面更新花费的时间 felix_int_dataplane_failures 数据面更新失败以及重试次数 felix_int_dataplane_iface_msg_batch_size 批处理的接口状态消息数。 较高的值表示我们正在做更多的批处理以试图跟上 felix_int_dataplane_messages 按照类型分类的消息数 felix_int_dataplane_msg_batch_size 批处理的消息数。 较高的值表示我们正在做更多的批处理以试图跟上 felix_ipset_calls ipset 命令执行数 felix_ipset_errors ipset 命令失败数 felix_ipset_lines_executed ipset 执行操作数 felix_ipsets_calico active Calico IP sets 数量 felix_ipsets_total active IP sets 总数 felix_iptables_chains active iptables chains 数量 felix_iptables_lines_executed iptables 规则执行更新数 felix_iptables_restore_calls iptables-restore 调用次数 felix_iptables_restore_errors iptables-restore 错误数 felix_iptables_rules active iptables 规则数 felix_iptables_save_calls iptables-save 调用次数 felix_iptables_save_errors iptables-save 错误数 felix_resync_state 当前 datastore 状态 felix_resyncs_started felix 开始重新同步datastore的次数 felix_route_table_list_seconds 在同步期间列出所有接口所花费的时间 felix_route_table_per_iface_sync_seconds 同步每个接口所花费的时间 felix_log_errors 错误日志数 felix_logs_dropped 由于输出流被阻塞而丢弃的日志数 使用 prometheus 收集监控：[[监控 - monitor]] 使用可视化查看：[[grafana 可视化]]</description></item><item><title>DNS</title><link>https://www.ryken.cloud/DNS/</link><pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/DNS/</guid><description>亚马逊 DNS - routeD5? 可以实现跨地域级别的通信，一个地域内可以使用 bgp 去打通 Amazon Route 53</description></item><item><title>DNS 记录</title><link>https://www.ryken.cloud/DNS-%E8%AE%B0%E5%BD%95/</link><pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/DNS-%E8%AE%B0%E5%BD%95/</guid><description>使用青云的公有云，有时主机重启之后对应的dns记录会消失，手动修改 /etc/resolv.conf 后重启会被覆盖，因此可以使用以下方法解决：
使用默认的 resolved 管理 DNS 记录 使用resolvconf 管理 DNS 记录 使用 resolved 修改 /etc/systemd/resolved.conf 文件，在其中添加dns信息，例如： DNS=8.</description></item><item><title>kube-controller-manager</title><link>https://www.ryken.cloud/kube-controller-manager/</link><pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/kube-controller-manager/</guid><description>Calico kube-controller-manager 是 Deployment。它包含以下控制器：
policy controller：监视网络策略和 calico 策略，它会把Kubernetes的network policies同步到 datastore 中。 namespace controller：监视命名空间和 calico 配置文件，它会把Kubernetes的namespace label变化同步到 datastore 中。 serviceaccount controller：监视服务帐户和 calico 配置文件，它会把Kubernetes的service account变化同步到 datastore 中。 workloadendpoint controller：监视pod标签的更改并更新Calico工作负载中的endpoints配置，它会把Kubernetes的pod label变化同步到 datastore 中。 node controller：监视删除Kubernetes nodes节点的操作并从Calico中也删除相应的数据。</description></item><item><title>kubernetes</title><link>https://www.ryken.cloud/kubernetes/</link><pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/kubernetes/</guid><description>[[kubeadm install k8s]] [[kubekey install k8s]] [[webhook]] [[runtime]]</description></item><item><title>kubernetes service</title><link>https://www.ryken.cloud/kubernetes-service/</link><pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/kubernetes-service/</guid><description>服务（Service） | Kubernetes
externalName service： Kubernetes Tips - Part 1 (akomljen.com)</description></item><item><title>linux 网络配置</title><link>https://www.ryken.cloud/linux-%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/</link><pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/linux-%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/</guid><description>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 root@node1:~# cat /etc/network/interfaces source /etc/network/interfaces.</description></item><item><title>Prometheus Blockbox Exporter</title><link>https://www.ryken.cloud/Prometheus-Blockbox-Exporter/</link><pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Prometheus-Blockbox-Exporter/</guid><description>Blackbox Exporter 是 Prometheus 社区提供的 官方黑盒监控解决方案,其允许用户通过: http\HTTPS\DNS\TCP\ICMP\gRPC的方式对网络进行探测.
安装部署
docker 安装
1 docker run --rm -p 9115:9115 --name blackbox_exporter -v $(pwd):/config quay.</description></item><item><title>监控 - monitor</title><link>https://www.ryken.cloud/%E7%9B%91%E6%8E%A7-monitor/</link><pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E7%9B%91%E6%8E%A7-monitor/</guid><description>Monitor Calico component metrics (tigera.io)
Configure Calico to enable the metrics reporting. Create the namespace and service account that Prometheus will need.</description></item><item><title>网络监控工具</title><link>https://www.ryken.cloud/%E7%BD%91%E7%BB%9C%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7/</link><pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E7%BD%91%E7%BB%9C%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7/</guid><description>google/cadvisor: Analyzes resource usage and performance characteristics of running containers. (github.com) 网络资源的使用率
yingyan003/netChecker: netChecker是一个检查k8s集群网络连通性的工具。测试对象是pod-&amp;gt;pod，pod-&amp;gt;node，pod-&amp;gt;svc的网络状况 (github.</description></item><item><title>路由反射器的反射规则</title><link>https://www.ryken.cloud/%E8%B7%AF%E7%94%B1%E5%8F%8D%E5%B0%84%E5%99%A8%E7%9A%84%E5%8F%8D%E5%B0%84%E8%A7%84%E5%88%99/</link><pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E8%B7%AF%E7%94%B1%E5%8F%8D%E5%B0%84%E5%99%A8%E7%9A%84%E5%8F%8D%E5%B0%84%E8%A7%84%E5%88%99/</guid><description>路由反射器的反射规则：
1、反射器接收到EBGP邻居通告的BGP路由时候：当路由反射器接收到来自EBGP邻居通告的BGP路由，会把此路由同时通告给同一cluster内的client邻居，也通告给cluster之外的其他IBGP邻居。而路由中携带的Cluster list和Originator属性只发送给cluster内的client邻居。
2、反射器接收到cluster内的IBGP邻居发送来的路由时候：当路由反射器接收到同一cluster内的IBGP邻居发送来的BGP路由时候，反射器把该路由通告给cluster内其他所有client邻居，也通告给cluster外的其他IBGP邻居，这个通告的路由包括了Originator 属性和修改后的Cluster ID属性。如果该反射器存在EBGP邻居的话，反射器同时把该路由通告给所有的EBGP邻居，但不携带任何反射器相关属性。
3、反射器接收到cluster外的其他IBGP邻居发送的BGP路由时候：当反射器接收到cluster以外的其他IBGP邻居发送的路由时候，反射器会把该路由通告给自己cluster内所有的client邻居，添加合适的属性。如果该RR存在EBGP邻居的话，则RR同时也把该路由通告给自己所有的EBGP邻居，但不携带反射器相关属性。</description></item><item><title>运行时链接</title><link>https://www.ryken.cloud/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%93%BE%E6%8E%A5/</link><pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%93%BE%E6%8E%A5/</guid><description>链接 现代连接器在处理动态库时将链接时路径（Link-time path）和运行时路径（Run-time path）分开，用户可以通过-L指定连接时库的路径，通过-R（或-rpath）指定程序运行时库的路径，大大提高了库应用的灵活性。
LIBRARY_PATH环境变量用于在程序编译期间查找动态链接库时指定查找共享库的路径 LD_LIBRARY_PATH环境变量用于在程序加载运行期间查找动态链接库时指定除了系统默认路径之外的其他路径，注意，LD_LIBRARY_PATH中指定的路径会在系统默认路径之前进行查找。
world.c
1 2 3 4 5 #include&amp;lt;stdio.h&amp;gt;void world(void) { printf(&amp;#34;world.\n&amp;#34;); } hello.</description></item><item><title/><link>https://www.ryken.cloud/hybridnet.excalidraw/</link><pubDate>Fri, 21 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/hybridnet.excalidraw/</guid><description>==⚠ Switch to EXCALIDRAW VIEW in the MORE OPTIONS menu of this document. ⚠==
Text Elements leaf1 ^sDROrzpl
server1 ^eqxCtLQ4</description></item><item><title>images-repository</title><link>https://www.ryken.cloud/images-repository/</link><pubDate>Thu, 13 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/images-repository/</guid><description>Moby = open source development Docker CE = free product release based on Moby Docker EE = commercial product release based on Docker CE.</description></item><item><title>felix env</title><link>https://www.ryken.cloud/felix-env/</link><pubDate>Mon, 10 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/felix-env/</guid><description>日志：
FELIX_EARLYLOGSEVERITYSCREEN FELIX_LOGSEVERITYSCREEN go 垃圾回收
GOGC BPF 模式
KUBERNETES_SERVICE_HOST KUBERNETES_SERVICE_PORT 循环加载配置 - 直到 data store ready</description></item><item><title>FrequentlyUsed</title><link>https://www.ryken.cloud/FrequentlyUsed/</link><pubDate>Mon, 10 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/FrequentlyUsed/</guid><description>set [[build record]] [[shell 常用]] [[ssh]]</description></item><item><title>启动 startup</title><link>https://www.ryken.cloud/%E5%90%AF%E5%8A%A8-startup/</link><pubDate>Mon, 10 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%90%AF%E5%8A%A8-startup/</guid><description>startup 启动流程：
检测 ip 地址和 bgp 使用的网络 使用环境中提供的或自动检测到的 IP/AS 信息配置节点资源 创建默认的 ippool</description></item><item><title/><link>https://www.ryken.cloud/4.1-%E7%A9%BA%E9%97%B4%E4%B8%8E%E5%9C%B0%E5%9D%80%E5%88%86%E9%85%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/4.1-%E7%A9%BA%E9%97%B4%E4%B8%8E%E5%9C%B0%E5%9D%80%E5%88%86%E9%85%8D/</guid><description/></item><item><title/><link>https://www.ryken.cloud/4.2-%E7%AC%A6%E5%8F%B7%E8%A7%A3%E6%9E%90%E4%B8%8E%E9%87%8D%E5%AE%9A%E4%BD%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/4.2-%E7%AC%A6%E5%8F%B7%E8%A7%A3%E6%9E%90%E4%B8%8E%E9%87%8D%E5%AE%9A%E4%BD%8D/</guid><description/></item><item><title/><link>https://www.ryken.cloud/4.3-COMMON%E5%9D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/4.3-COMMON%E5%9D%97/</guid><description/></item><item><title/><link>https://www.ryken.cloud/4.4-C++%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/4.4-C++%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/</guid><description/></item><item><title/><link>https://www.ryken.cloud/4.5-%E9%9D%99%E6%80%81%E5%BA%93%E9%93%BE%E6%8E%A5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/4.5-%E9%9D%99%E6%80%81%E5%BA%93%E9%93%BE%E6%8E%A5/</guid><description/></item><item><title/><link>https://www.ryken.cloud/4.6-%E9%93%BE%E6%8E%A5%E8%BF%87%E7%A8%8B%E6%8E%A7%E5%88%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/4.6-%E9%93%BE%E6%8E%A5%E8%BF%87%E7%A8%8B%E6%8E%A7%E5%88%B6/</guid><description/></item><item><title/><link>https://www.ryken.cloud/4.7-BFD%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/4.7-BFD%E5%BA%93/</guid><description/></item><item><title/><link>https://www.ryken.cloud/BGP-%E6%8A%A5%E6%96%87/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/BGP-%E6%8A%A5%E6%96%87/</guid><description>#bgp #bird bird文档 labs / BIRD Internet Routing Daemon · GitLab (nic.cz)
bgp 报文类型
type 报文类型 用途 1 Open 建立 BGP 连接 2 Update 用于通告路由 3 Notification 用于处理 BGP 进程中的各种错误 4 Keepalive 用于保持 BGP 连接 5 Refresh 用于动态的请求 BGP 路由发布者重新发布 Update 报文，进行路由更新 配置 tor 为 Route Reflector 以及选取集群中一个节点作为 Route Reflector 的区别 RR是一种用于提高BGP网络中路由传播效率的技术。在 BGP 网络中，每个节点通常需要向其邻居节点发送完整的路由表，这可能会导致网络带宽消耗和延迟增加。通过使用 RR，节点可以将路由信息发送到 RR 节点，RR 节点然后将其转发给其他节点，从而减少了网络流量和节点负担。</description></item><item><title/><link>https://www.ryken.cloud/BGP-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA.excalidraw/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/BGP-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA.excalidraw/</guid><description>==⚠ Switch to EXCALIDRAW VIEW in the MORE OPTIONS menu of this document. ⚠==
Text Elements spine1 ^ysTSUxD3
spine2 ^NLhMxLIF</description></item><item><title/><link>https://www.ryken.cloud/BIRD-%E6%96%87%E6%A1%A3-+-%E9%A1%B9%E7%9B%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/BIRD-%E6%96%87%E6%A1%A3-+-%E9%A1%B9%E7%9B%AE/</guid><description>#bird
文档： The BIRD Internet Routing Daemon Project (network.cz) 项目地址： Files · master · labs / BIRD Internet Routing Daemon · GitLab (nic.</description></item><item><title/><link>https://www.ryken.cloud/cEOS-%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/cEOS-%E9%85%8D%E7%BD%AE/</guid><description>#containerlab #cEOS #交换机
锐捷交换机
enable configure show running-config
vlan 10~12 interface vlan 10 ip address 10.10.10.1 255.255.255.0
interface Ethernet 2 switchport mode trunk switchport trunk native vlan 10 switchport trunk allowed vlan remove 1-4094 Switchport trunk allow vlan add 10,11,12</description></item><item><title/><link>https://www.ryken.cloud/confd-%E7%BB%84%E4%BB%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/confd-%E7%BB%84%E4%BB%B6/</guid><description>开源的、轻量级的配置管理工具。监控Calico数据存储对BGP配置和全局默认的日志变更，如AS号、日志级别和IPAM信息。
Confd根据存储中的数据更新，动态生成BIRD配置文件。当配置文件发生变化时，confd会触发BIRD加载新的文件。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 function apply_communities (){{{- $prefix_advertisements_key := &amp;#34;&amp;#34;}}{{- $node_prefix_advertisements_key := printf &amp;#34;/host/%s/prefix_advertisements/ip_v4&amp;#34; (getenv &amp;#34;NODENAME&amp;#34;)}}{{- if exists $node_prefix_advertisements_key}}{{- $prefix_advertisements_key = $node_prefix_advertisements_key}}{{- else if exists &amp;#34;/global/prefix_advertisements/ip_v4&amp;#34;}}{{- $prefix_advertisements_key = &amp;#34;/global/prefix_advertisements/ip_v4&amp;#34;}}{{- end}}{{- if ne &amp;#34;&amp;#34; $prefix_advertisements_key}}{{- range gets $prefix_advertisements_key}}{{- $arr:= jsonArray .</description></item><item><title/><link>https://www.ryken.cloud/ebpf-%E6%8E%92%E6%9F%A5%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/ebpf-%E6%8E%92%E6%9F%A5%E5%B7%A5%E5%85%B7/</guid><description>排查工具：ftrace / bcc trace 问题排查利器：Linux 原生跟踪工具 Ftrace 必知必会 | 深入浅出 eBPF</description></item><item><title/><link>https://www.ryken.cloud/encoding_gob/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/encoding_gob/</guid><description/></item><item><title/><link>https://www.ryken.cloud/encoding_json/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/encoding_json/</guid><description/></item><item><title/><link>https://www.ryken.cloud/encoding%E5%BA%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/encoding%E5%BA%93/</guid><description/></item><item><title/><link>https://www.ryken.cloud/Flannel-%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Flannel-%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6/</guid><description>#flannel #cni</description></item><item><title/><link>https://www.ryken.cloud/go-interface/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/go-interface/</guid><description/></item><item><title/><link>https://www.ryken.cloud/go-%E5%B9%B6%E5%8F%91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/go-%E5%B9%B6%E5%8F%91/</guid><description/></item><item><title/><link>https://www.ryken.cloud/go-%E7%B1%BB%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/go-%E7%B1%BB%E5%9E%8B/</guid><description>值类型给编译器提供规模和表示两部分 当声明变量时，这个变量对应的值总是会被初始化。这个值要么用指定的值初始化，要么用零值（即变量类型的默认值）做初始化。对数值类型来说，零值是 0；对字符串来说，零值是空字符串；对布尔类型，零值是 false。对这个例子里的结构，结构里每个字段都会用零值初始化。
1 2 3 4 5 6 7 8 9 10 11 package main type Duration int64 func main() { var dur Duration dur = int64(1000) } // # command-line-arguments // .</description></item><item><title/><link>https://www.ryken.cloud/go-%E8%B0%83%E5%BA%A6%E5%99%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/go-%E8%B0%83%E5%BA%A6%E5%99%A8/</guid><description/></item><item><title/><link>https://www.ryken.cloud/helm-Tools/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/helm-Tools/</guid><description>#helm
1. 官网地址 https://helm.sh/
2. 在ubuntu上安装 1 2 3 4 5 curl https://baltocdn.com/helm/signing.asc | sudo apt-key add - sudo apt-get install apt-transport-https --yes echo &amp;#34;deb https://baltocdn.</description></item><item><title/><link>https://www.ryken.cloud/icmp-tcp-dns-%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/icmp-tcp-dns-%E9%85%8D%E7%BD%AE/</guid><description>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 ---apiVersion:v1kind:Namespacemetadata:name:monitoring-systemlabels:app:monitoring---apiVersion:v1kind:ConfigMapmetadata:name:blackbox-confignamespace:monitoring-systemdata:blackbox.</description></item><item><title/><link>https://www.ryken.cloud/install-KubeOVN/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/install-KubeOVN/</guid><description>#kube-ovn #kubekey #install
overlay 安装 使用 kubekey 安装 1 2 3 4 5 6 7 8 9 10 11 apiVersion:kubekey.</description></item><item><title/><link>https://www.ryken.cloud/k9s-Tools/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/k9s-Tools/</guid><description>#k9s
release url: Releases · derailed/k9s (github.com)
安装
配置： derailed/k9s: 🐶 Kubernetes CLI To Manage Your Clusters In Style! (github.com) ~/.</description></item><item><title/><link>https://www.ryken.cloud/Kind-Tools/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Kind-Tools/</guid><description>#kind #install
文档： https://kind.sigs.k8s.io/docs/user/quick-start
安装二进制 1 2 3 curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.16.0/kind-linux-amd64 chmod +x ./kind sudo mv .</description></item><item><title/><link>https://www.ryken.cloud/kube-ovn-ipam/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/kube-ovn-ipam/</guid><description>#ipam #kube-ovn
ip 分配 随机分配 对于工作负载的 ip 分配策略
优先使用负载指定的：ovn.kubernetes.io/logical_switch: subnet 如果负载没有指定使用，使用 namespace 绑定的 subnet 如果 namespace 没有绑定 subnet，使用安装默认的 ovn-default 静态分配 静态分配即在 pod 的 annotations 中添加对应的注解：如果 mac 地址为空，会随机申请出一个 mac 地址。</description></item><item><title/><link>https://www.ryken.cloud/kube-ovn-networkpolicy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/kube-ovn-networkpolicy/</guid><description>#network-policy #kube-ovn
标准的 NetworkPolicy kube-ovn 支持标准的 NetworkPolicy，但是无法作用于 node 上的策略
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 apiVersion:networking.</description></item><item><title/><link>https://www.ryken.cloud/kube-ovn/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/kube-ovn/</guid><description>#kube-ovn #cni
文档链接： Kube-OVN 文档 发布版本： Releases · kubeovn/kube-ovn (github.com)
kube-ovn 1.9 版本自定义资源
自定义资源 说明 备注 vpcs 自定义vpc vpc-nat-gateways vpc 出口网关 subnets 子网/ippool 地址池 provider-networks underlay 网卡提供者 vlans vlan 信息 ips ip 分配记录 htbqoses pod 网络限速 security-groups 安全组信息 kube-ovn 1.</description></item><item><title/><link>https://www.ryken.cloud/kubectl-ko/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/kubectl-ko/</guid><description>#kube-ovn #kubectl
有时候安装完成 kube-ovn 之后，kubectl ko 插件无法使用</description></item><item><title/><link>https://www.ryken.cloud/markdown-style/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/markdown-style/</guid><description>#markdown
Extended Syntax | Markdown Guide</description></item><item><title/><link>https://www.ryken.cloud/net_http/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/net_http/</guid><description/></item><item><title/><link>https://www.ryken.cloud/net_http_cgi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/net_http_cgi/</guid><description/></item><item><title/><link>https://www.ryken.cloud/net_http_cookiejar/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/net_http_cookiejar/</guid><description/></item><item><title/><link>https://www.ryken.cloud/net_rpc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/net_rpc/</guid><description/></item><item><title/><link>https://www.ryken.cloud/netlab/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/netlab/</guid><description>#netlab
项目地址： ipspace/netlab: Making virtual networking labs suck less (github.com)
文档地址： VLANs — Network Simulation Tools documentation (netsim-tools.readthedocs.io)
别人的一个 demo： netlab Simple VLAN Example « ipSpace.</description></item><item><title/><link>https://www.ryken.cloud/network-tools/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/network-tools/</guid><description>#nsenter
nsenter -u -n -t $pid bash
nsenter --uts --net --target 3326 --ipc --mount --pid
网卡队列设置为1 + 网卡终端绑定至 CPU0 [Linux 性能调优] 网卡中断与CPU的绑定问题 - 巴蛮子 - 博客园 (cnblogs.</description></item><item><title/><link>https://www.ryken.cloud/Node-IPAM-LB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/Node-IPAM-LB/</guid><description/></item><item><title/><link>https://www.ryken.cloud/ss-%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/ss-%E5%91%BD%E4%BB%A4/</guid><description>#network #tool
ss 命令用于显示socket状态. 他可以显示PACKET sockets, TCP sockets, UDP sockets, DCCP sockets, RAW sockets, Unix domain sockets等等统计. 它比其他工具展示等多tcp和state信息. 它是一个非常实用、快速、有效的跟踪IP连接和sockets的新工具.
功能类似：netstat</description></item><item><title/><link>https://www.ryken.cloud/tc-tbf/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/tc-tbf/</guid><description>tbf - token bucket Filter 令牌桶过滤器
tbf sfq 无类算法 流量控制 TBF 队列控制 SFQ 随机公平队列
分类算法：PRIO/CBQ/HTB 对多种数据流区别对待
PRIO：分类优先算法 (从左至右优先发包), 队列规定并不进行整形，它仅仅根据配置的过滤器把流量进一步细分 CBQ：工作机制是确认链路的闲置时间足够长，以达到降低链路实际带宽的目的 HTB：分层的令牌桶一个分类的令牌桶过滤器 linux 流量控制：</description></item><item><title/><link>https://www.ryken.cloud/tcpdump/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/tcpdump/</guid><description>tcpdump -i any -w mycap.pacp</description></item><item><title/><link>https://www.ryken.cloud/termshark/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/termshark/</guid><description>#wireshark #tcpdump #termshark
安装： Releases · gcla/termshark (github.com)</description></item><item><title/><link>https://www.ryken.cloud/use-kube-ovn/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/use-kube-ovn/</guid><description>#kube-ovn #cni #how-to-use
核心资源 subnet
示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 apiVersion:kubeovn.</description></item><item><title/><link>https://www.ryken.cloud/vyos-OSPF-%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/vyos-OSPF-%E9%85%8D%E7%BD%AE/</guid><description>#vyos #路由器
1 2 3 4 5 6 set interfaces loopback lo address 9.9.9.9/32 set protocols ospf parameters router-id 8.</description></item><item><title/><link>https://www.ryken.cloud/wireshark-%E6%8A%93%E5%8C%85%E8%BF%87%E6%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/wireshark-%E6%8A%93%E5%8C%85%E8%BF%87%E6%BB%A4/</guid><description>#wireshark
功能 表达式 筛选特定 ip ip.addr == xxx</description></item><item><title/><link>https://www.ryken.cloud/%E4%BA%A4%E6%8D%A2%E6%9C%BA%E7%9B%B8%E5%85%B3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E4%BA%A4%E6%8D%A2%E6%9C%BA%E7%9B%B8%E5%85%B3/</guid><description>#containerlab #交换机
Nokia SR Linux
1 2 3 4 5 # access CLI docker exec -it &amp;lt;name&amp;gt; sr_cli # access bash docker exec -it &amp;lt;name&amp;gt; bash Arista cEOS</description></item><item><title/><link>https://www.ryken.cloud/%E4%BD%BF%E7%94%A8code-generator%E7%94%9F%E6%88%90crd%E7%9A%84clientsetinformerlisters/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E4%BD%BF%E7%94%A8code-generator%E7%94%9F%E6%88%90crd%E7%9A%84clientsetinformerlisters/</guid><description>#code-generator #informer #kubernetes #kubebuilder
参考链接： 使用code-generator生成crd的clientset、informer、listers - 赶路人的博客 (xieys.club)</description></item><item><title/><link>https://www.ryken.cloud/%E5%88%9D%E5%A7%8Bnginx/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%88%9D%E5%A7%8Bnginx/</guid><description/></item><item><title/><link>https://www.ryken.cloud/%E5%89%96%E6%9E%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E5%89%96%E6%9E%90/</guid><description>Calico eBPF Data Plane Deep-Dive (tigera.io)
nodeport 流量到来之后如何处理的
host ip update ？
kube-proxy ： 用于处理高级的问题，如重启、配置等</description></item><item><title/><link>https://www.ryken.cloud/%E6%8E%92%E6%9F%A5-calico-ebpf/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E6%8E%92%E6%9F%A5-calico-ebpf/</guid><description>#calico #ebpf
配置 kube-proxy
1 2 3 4 5 kubectl patch ds -n kube-system kube-proxy -p &amp;#39;{&amp;#34;spec&amp;#34;:{&amp;#34;template&amp;#34;:{&amp;#34;spec&amp;#34;:{&amp;#34;nodeSelector&amp;#34;:{&amp;#34;non-calico&amp;#34;: &amp;#34;true&amp;#34;}}}}}&amp;#39; kubectl patch felixconfiguration default --type merge --patch=&amp;#39;{&amp;#34;spec&amp;#34;: {&amp;#34;bpfEnabled&amp;#34;: true}}&amp;#39; # 如果无法禁用 kube-proxy ，配置 Felix kubectl patch felixconfiguration default --type merge --patch=&amp;#39;{&amp;#34;spec&amp;#34;: {&amp;#34;bpfKubeProxyIptablesCleanupEnabled&amp;#34;: false}}&amp;#39; 取消设置 - 回滚</description></item><item><title/><link>https://www.ryken.cloud/%E6%97%B6%E5%8C%BA-%E5%90%8C%E6%AD%A5%E6%97%B6%E9%97%B4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E6%97%B6%E5%8C%BA-%E5%90%8C%E6%AD%A5%E6%97%B6%E9%97%B4/</guid><description>查看系统时区 timedatectl
修改系统时区 1 2 3 4 timedatectl list-timezones | grep -i shang Asia/Shanghai timedatectl set-timezone Asia/Shanghai 软连接修改时区 1 2 3 4 5 ```shell root@node1:~#ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime root@node1:~# ls -l /etc/localtime lrwxrwxrwx 1 root root 33 May 20 2022 /etc/localtime -&amp;gt; /usr/share/zoneinfo/Asia/Shanghai</description></item><item><title/><link>https://www.ryken.cloud/%E6%9C%AA%E5%91%BD%E5%90%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E6%9C%AA%E5%91%BD%E5%90%8D/</guid><description>#loadbalance
| 名称 | 解释 | 层级|= |&amp;ndash;|&amp;ndash;|&amp;ndash;| |DLB | DNS 负载均衡 | 七层 | | ALB | Application 负载均衡 | 七层 | | NLB | Network 负载均衡 | 四层 |</description></item><item><title/><link>https://www.ryken.cloud/%E6%9E%B6%E6%9E%84.excalidraw/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E6%9E%B6%E6%9E%84.excalidraw/</guid><description>==⚠ Switch to EXCALIDRAW VIEW in the MORE OPTIONS menu of this document. ⚠==
Text Elements Kube-loxilb ^doQa7FVc
loxilb ^FoxFTTiM</description></item><item><title/><link>https://www.ryken.cloud/%E6%9F%A5%E7%9C%8B-CPU%E5%86%85%E5%AD%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E6%9F%A5%E7%9C%8B-CPU%E5%86%85%E5%AD%98/</guid><description>查看 cpu 信息： cat /proc/cpuinfo
1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 总核数 = 物理CPU个数 X 每颗物理CPU的核数 # 总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数 # 查看物理CPU个数 cat /proc/cpuinfo| grep &amp;#34;physical id&amp;#34;| sort| uniq| wc -l # 查看每个物理CPU中core的个数(即核数) cat /proc/cpuinfo| grep &amp;#34;cpu cores&amp;#34;| uniq # 查看逻辑CPU的个数 cat /proc/cpuinfo| grep &amp;#34;processor&amp;#34;| wc -l # 查看CPU信息（型号） cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c 查看 mem 信息： cat /proc/meminfo</description></item><item><title/><link>https://www.ryken.cloud/%E7%BB%84%E7%BD%91.excalidraw/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E7%BB%84%E7%BD%91.excalidraw/</guid><description>==⚠ Switch to EXCALIDRAW VIEW in the MORE OPTIONS menu of this document. ⚠==
Excalidraw Data Text Elements 45.120.216.46 ^ZNmnY1tc</description></item><item><title/><link>https://www.ryken.cloud/%E8%87%AA%E5%8A%A8%E8%A1%A5%E5%85%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E8%87%AA%E5%8A%A8%E8%A1%A5%E5%85%A8/</guid><description>#kubernetes #tools
安装 bash-completion 应用 kubectl 的 completion 1 2 source &amp;lt;(kubectl completion bash) echo &amp;#34;source &amp;lt;(kubectl completion bash)&amp;#34; &amp;gt;&amp;gt; ~/.</description></item><item><title/><link>https://www.ryken.cloud/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/</guid><description>#kube-ovn
kube-ovn 实现跨主机通信的原理 在 泰山服务器、华为鲲鹏920cpu 的 arm
kubectl ko 命令不起作用 脚本会根据 pod 使用的镜像来筛选出对应的 pod 然后执行对应的命令，因此当命令无法使用时，尝试修改一下脚本中的 REGISTRY
组件</description></item><item><title/><link>https://www.ryken.cloud/%E9%85%8D%E7%BD%AE-TOR/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E9%85%8D%E7%BD%AE-TOR/</guid><description>#calico #tor
配置其他节点连接到 RR 节点 1 2 3 4 5 6 7 apiVersion:projectcalico.org/v3kind:BGPPeermetadata:name:testspec:nodeSelector:all()peerSelector:has(routeReflector) 禁止 BGP FullMesh 1 2 3 4 5 6 7 8 apiVersion:projectcalico.</description></item><item><title/><link>https://www.ryken.cloud/%E9%97%AE%E9%A2%98/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/%E9%97%AE%E9%A2%98/</guid><description>为什么引入网卡多队列。引入网卡多队列解决了什么问题，带来了什么其他问题 队列绑核 整个收/发包的流程是什么样的 1.网卡多队列 &amp;ndash; 收包多队列 +发包多队列 通常情况下, 每张网卡有一个队列(queue), 所有收到的包从这个队列入, 内核从这个队列里取数据处理. 该队列其实是ring buffer(环形队列), 内核如果取数据不及时, 则会存在丢包的情况.
一个CPU处理一个队列的数据, 这个叫中断. 默认是cpu0(第一个CPU)处理. 一旦流量特别大, 这个CPU负载很高, 性能存在瓶颈.</description></item><item><title>ipset</title><link>https://www.ryken.cloud/ipset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/ipset/</guid><description>iptables中使用ipset 在iptables中使用ipset，只要加上-m set &amp;ndash;match-set即可
目的ip使用ipset（ipset集合为bbb） iptables -I INPUT -s 192.168.100.36 -m set --match-set bbb dst -j DROP
源ip使用ipset（ipset集合为aaa） iptables -I INPUT -m set --match-set aaa src -d 192.</description></item><item><title>iptables 匹配条件</title><link>https://www.ryken.cloud/iptables-%E5%8C%B9%E9%85%8D%E6%9D%A1%E4%BB%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/iptables-%E5%8C%B9%E9%85%8D%E6%9D%A1%E4%BB%B6/</guid><description>当规则中同时存在多个匹配条件时，多个条件之间默认存在”与”的关系，即报文必须同时满足所有条件，才能被规则匹配。
基本匹配条件 -s用于匹配报文的源地址,可以同时指定多个源地址，每个IP之间用逗号隔开，也可以指定为一个网段。 1 2 3 iptables -t filter -I INPUT -s 192.168.1.111,192.168.1.118 -j DROP iptables -t filter -I INPUT -s 192.</description></item><item><title>iptables 原理</title><link>https://www.ryken.cloud/iptables-%E5%8E%9F%E7%90%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/iptables-%E5%8E%9F%E7%90%86/</guid><description>在青云环境下进行测试openelb时发现了该问题，但是可能其他环境也存在这个问题，**集群中某一个节点无法发送和接收udp包，**由于集群中所使用的cni插件flannel默认为vxlan模式，vxlan使用了overlay的udpd封装，因此导致一个节点无法与集群中其他节点通信但是可以通过其他的tcp、http连接通信。
在排查过程中怀疑，iptables被修改了，过滤了udp的协议包，因此使用iptables进行了排查，重新看了一下iptables
各个表的功能如下
filter表：负责过滤功能，防火墙；内核模块：iptables_filter nat表：network address translation，网络地址转换功能；内核模块：iptable_nat mangle表：拆解报文，做出修改，并重新封装 的功能；iptable_mangle raw表：关闭nat表上启用的连接追踪机制；iptable_raw 按道理这里只涉及到filter表，filter表在数据流入时，只会经过INPUT链，查看规则
1 2 3 4 5 6 7 8 9 10 11 12 13 root@i-vszzg2k0:~ iptables --line-number -nvL INPUT -t filter Chain INPUT (policy ACCEPT 12966 packets, 3234K bytes) num pkts bytes target prot opt in out source destination 1 200K 151M KUBE-NODEPORTS all -- * * 0.</description></item><item><title>iptables 命令增删改查</title><link>https://www.ryken.cloud/iptables-%E5%91%BD%E4%BB%A4%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/iptables-%E5%91%BD%E4%BB%A4%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/</guid><description>iptables预定了4张表，分别是raw表、mangle表、nat表、filter表，不同的表拥有不同的功能。 filter负责过滤功能，比如允许哪些IP地址访问，拒绝哪些IP地址访问，允许访问哪些端口，禁止访问哪些端口，filter表会根据我们定义的规则进行过滤，filter表应该是最常用到的表了。
iptable查看命令 iptables -L：显示所有的规则（默认为filter表） 绿色标注的规则是Centos6启动iptables以后默认设置的规则，蓝色标注部分为链，INPUT链、FORWARD链、OUTPUT链，每条链中都有自己的规则。
iptables -t nat -L：显示nat表中的所有规则（使用-t 选定表）
iptables -t filter -L INPUT：显示filter表中的所有INPUT规则
1 2 3 4 5 6 7 8 9 10 root@ubuntu:/home/mind/Program/test# iptables -t filter -L INPUT Chain INPUT (policy ACCEPT) target prot opt source destination ACCEPT all -- anywhere anywhere ACCEPT all -- anywhere anywhere state RELATED,ESTABLISHED ACCEPT tcp -- anywhere anywhere tcp dpt:ssh ACCEPT tcp -- anywhere anywhere tcp dpt:http ACCEPT tcp -- anywhere anywhere tcp dpt:https DROP tcp -- anywhere anywhere tcp dpt:mysql ACCEPT icmp -- anywhere anywhere icmp echo-request iptables -t filter -vL INPUT：加上-v 显示更详细的信息</description></item><item><title>iptables 软件防火墙</title><link>https://www.ryken.cloud/iptables-%E8%BD%AF%E4%BB%B6%E9%98%B2%E7%81%AB%E5%A2%99/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/iptables-%E8%BD%AF%E4%BB%B6%E9%98%B2%E7%81%AB%E5%A2%99/</guid><description>iptables基础 iptables一个命令行工具，位于用户空间，用这个工具操作防火墙真正的安全框架netfilter。 用户通过iptables这个代理，将用户的安全设定执行到netfilter中
netfilter是linux平台下的包过滤防火墙，完成封包过滤、封包重定向和网络地址转换（NAT）等功能。
用户使用iptables命令添加、修改和删除对应的规则，iptables按照这些规则去执行对应的操作。规则储存在内核空间的信息包过滤表中，规则指定了源地址、目的地址、传输协议（如TCP、UDP、ICMP）和服务类型（如HTTP、FTP和SMTP）等以及iptable对于这些规则的处理策略（如放行accept、拒绝reject和丢弃drop）。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 root@ubuntu:/home/mind/Program/test# iptables -t nat -nL Chain PREROUTING (policy ACCEPT) target prot opt source destination DOCKER all -- 0.</description></item><item><title>IPTables负载均衡</title><link>https://www.ryken.cloud/iptables%E5%92%8Cipvs%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.ryken.cloud/iptables%E5%92%8Cipvs%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/</guid><description>IPTables负载均衡 环境准备，准备nginx镜像，一个为正常访问的欢迎界面，一个修改为其他的界面，此处我修改为了50x.html 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 root@orange:~# docker run --rm -d --privileged=true nginx-test:1.</description></item></channel></rss>